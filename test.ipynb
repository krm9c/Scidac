{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "from torch.nn  import functional as F\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as cm\n",
    "sns.color_palette(\"bright\")\n",
    "\n",
    "def to_np(x):\n",
    "    return x.detach().cpu().numpy()\n",
    "\n",
    "def ode_solve(z0, t0, t1, f):\n",
    "    \"\"\"\n",
    "    Simplest Euler ODE initial value solver\n",
    "    \"\"\"\n",
    "    h_max = 0.01\n",
    "    n_steps = math.ceil((abs(t1 - t0)/h_max).max().item())\n",
    "    h = (t1 - t0)/n_steps\n",
    "    t = t0\n",
    "    z = z0\n",
    "    for i_step in range(n_steps):\n",
    "        z = z + h * f(z, t)\n",
    "        t = t + h\n",
    "    return z\n",
    "\n",
    "\n",
    "\n",
    "## Let us now figure out how to get a model.\n",
    "class ODEF(nn.Module):\n",
    "    def forward_with_grad(self, z, t, grad_outputs):\n",
    "        \"\"\"Compute f and a df/dz, a df/dp, a df/dt\"\"\"\n",
    "        batch_size = z.shape[0]\n",
    "        out = self.forward(z, t)\n",
    "        a = grad_outputs\n",
    "        adfdz, adfdt, *adfdp = torch.autograd.grad(\n",
    "            (out,), (z, t) + tuple(self.parameters()), grad_outputs=(a),\n",
    "            allow_unused=True, retain_graph=True)\n",
    "        # grad method automatically sums gradients for batch items, we have to expand them back\n",
    "        if adfdp is not None:\n",
    "            adfdp = torch.cat([p_grad.flatten()\n",
    "                              for p_grad in adfdp]).unsqueeze(0)\n",
    "            adfdp = adfdp.expand(batch_size, -1) / batch_size\n",
    "        if adfdt is not None:\n",
    "            adfdt = adfdt.expand(batch_size, 1) / batch_size\n",
    "        return out, adfdz, adfdt, adfdp\n",
    "\n",
    "    def flatten_parameters(self):\n",
    "        p_shapes = []\n",
    "        flat_parameters = []\n",
    "        for p in self.parameters():\n",
    "            p_shapes.append(p.size())\n",
    "            flat_parameters.append(p.flatten())\n",
    "        return torch.cat(flat_parameters)\n",
    "\n",
    "class ODEAdjoint(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, z0, t, flat_parameters, func):\n",
    "        assert isinstance(func, ODEF)\n",
    "        bs, *z_shape = z0.size()\n",
    "        time_len = t.size(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            z = torch.zeros(time_len, bs, *z_shape).to(z0)\n",
    "            z[0] = z0\n",
    "            for i_t in range(time_len - 1):\n",
    "                z0 = ode_solve(z0, t[i_t], t[i_t+1], func)\n",
    "                z[i_t+1] = z0\n",
    "\n",
    "        ctx.func = func\n",
    "        ctx.save_for_backward(t, z.clone(), flat_parameters)\n",
    "        return z\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, dLdz):\n",
    "        \"\"\"\n",
    "        dLdz shape: time_len, batch_size, *z_shape\n",
    "        \"\"\"\n",
    "        func = ctx.func\n",
    "        t, z, flat_parameters = ctx.saved_tensors\n",
    "        time_len, bs, *z_shape = z.size()\n",
    "        n_dim = np.prod(z_shape)\n",
    "        n_params = flat_parameters.size(0)\n",
    "\n",
    "        # Dynamics of augmented system to be calculated backwards in time\n",
    "        def augmented_dynamics(aug_z_i, t_i):\n",
    "            \"\"\"\n",
    "            tensors here are temporal slices\n",
    "            t_i - is tensor with size: bs, 1\n",
    "            aug_z_i - is tensor with size: bs, n_dim*2 + n_params + 1\n",
    "            \"\"\"\n",
    "            z_i, a = aug_z_i[:, :n_dim], aug_z_i[:, n_dim:2*n_dim]  # ignore parameters and time\n",
    "\n",
    "            # Unflatten z and a\n",
    "            z_i = z_i.view(bs, *z_shape)\n",
    "            a = a.view(bs, *z_shape)\n",
    "            with torch.set_grad_enabled(True):\n",
    "                t_i = t_i.detach().requires_grad_(True)\n",
    "                z_i = z_i.detach().requires_grad_(True)\n",
    "                func_eval, adfdz, adfdt, adfdp = func.forward_with_grad(z_i, t_i, grad_outputs=a)  # bs, *z_shape\n",
    "                adfdz = adfdz.to(z_i) if adfdz is not None else torch.zeros(bs, *z_shape).to(z_i)\n",
    "                adfdp = adfdp.to(z_i) if adfdp is not None else torch.zeros(bs, n_params).to(z_i)\n",
    "                adfdt = adfdt.to(z_i) if adfdt is not None else torch.zeros(bs, 1).to(z_i)\n",
    "\n",
    "            # Flatten f and adfdz\n",
    "            func_eval = func_eval.view(bs, n_dim)\n",
    "            adfdz = adfdz.view(bs, n_dim)\n",
    "            return torch.cat((func_eval, -adfdz, -adfdp, -adfdt), dim=1)\n",
    "\n",
    "        dLdz = dLdz.view(time_len, bs, n_dim)  # flatten dLdz for convenience\n",
    "        with torch.no_grad():\n",
    "            ## Create placeholders for output gradients\n",
    "            # Prev computed backwards adjoints to be adjusted by direct gradients\n",
    "            adj_z = torch.zeros(bs, n_dim).to(dLdz)\n",
    "            adj_p = torch.zeros(bs, n_params).to(dLdz)\n",
    "            # In contrast to z and p we need to return gradients for all times\n",
    "            adj_t = torch.zeros(time_len, bs, 1).to(dLdz)\n",
    "\n",
    "            for i_t in range(time_len-1, 0, -1):\n",
    "                z_i = z[i_t]\n",
    "                t_i = t[i_t]\n",
    "                f_i = func(z_i, t_i).view(bs, n_dim)\n",
    "\n",
    "                # Compute direct gradients\n",
    "                dLdz_i = dLdz[i_t]\n",
    "                dLdt_i = torch.bmm(torch.transpose(dLdz_i.unsqueeze(-1), 1, 2), f_i.unsqueeze(-1))[:, 0]\n",
    "\n",
    "                # Adjusting adjoints with direct gradients\n",
    "                adj_z += dLdz_i\n",
    "                adj_t[i_t] = adj_t[i_t] - dLdt_i\n",
    "\n",
    "                # Pack augmented variable\n",
    "                aug_z = torch.cat((z_i.view(bs, n_dim), adj_z, torch.zeros(bs, n_params).to(z), adj_t[i_t]), dim=-1)\n",
    "\n",
    "                # Solve augmented system backwards\n",
    "                aug_ans = ode_solve(aug_z, t_i, t[i_t-1], augmented_dynamics)\n",
    "\n",
    "                # Unpack solved backwards augmented system\n",
    "                adj_z[:] = aug_ans[:, n_dim:2*n_dim]\n",
    "                adj_p[:] += aug_ans[:, 2*n_dim:2*n_dim + n_params]\n",
    "                adj_t[i_t-1] = aug_ans[:, 2*n_dim + n_params:]\n",
    "\n",
    "                del aug_z, aug_ans\n",
    "\n",
    "            ## Adjust 0 time adjoint with direct gradients\n",
    "            # Compute direct gradients\n",
    "            dLdz_0 = dLdz[0]\n",
    "            dLdt_0 = torch.bmm(torch.transpose(dLdz_0.unsqueeze(-1), 1, 2), f_i.unsqueeze(-1))[:, 0]\n",
    "\n",
    "            # Adjust adjoints\n",
    "            adj_z += dLdz_0\n",
    "            adj_t[0] = adj_t[0] - dLdt_0\n",
    "        return adj_z.view(bs, *z_shape), adj_t, adj_p, None\n",
    "\n",
    "class NeuralODE(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super(NeuralODE, self).__init__()\n",
    "        assert isinstance(func, ODEF)\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, z0, t=Tensor([0., 1.]), return_whole_sequence=False):\n",
    "        t = t.to(z0)\n",
    "        # print(\"the data\", t, t.size(), z0.size())\n",
    "        z = ODEAdjoint.apply(z0, t, self.func.flatten_parameters(), self.func)\n",
    "        if return_whole_sequence:\n",
    "            return z\n",
    "        else:\n",
    "            return z[-1]\n",
    "\n",
    "\n",
    "class NNODEF(ODEF):\n",
    "    def __init__(self, in_dim, hid_dim, time_invariant=False):\n",
    "        super(NNODEF, self).__init__()\n",
    "        self.time_invariant = time_invariant\n",
    "\n",
    "        if time_invariant:\n",
    "            self.lin1 = nn.Linear(in_dim, hid_dim)\n",
    "        else:\n",
    "            self.lin1 = nn.Linear(in_dim+1, hid_dim)\n",
    "        self.lin2     = nn.Linear(hid_dim, hid_dim)\n",
    "        self.lin3     = nn.Linear(hid_dim, in_dim)\n",
    "        self.elu      = nn.ELU(inplace=True)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        # print(x.shape, t.shape)\n",
    "        if not self.time_invariant:\n",
    "            x = torch.cat((x, t.reshape([1,-1]) ), dim=-1)\n",
    "        # print(x.shape)\n",
    "        h = self.elu(self.lin1(x))\n",
    "        h = self.elu(self.lin2(h))\n",
    "        out = self.lin3(h)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class RNNEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(RNNEncoder, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        self.rnn = nn.GRU(input_dim+1, hidden_dim)\n",
    "        self.hid2lat = nn.Linear(hidden_dim, 2*latent_dim)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        # Concatenate time to input\n",
    "        t = t.clone()\n",
    "        t[1:] = t[:-1] - t[1:]\n",
    "        t[0] = 0.\n",
    "        xt = torch.cat((x, t), dim=-1)\n",
    "\n",
    "        _, h0 = self.rnn(xt.flip((0,)))  # Reversed\n",
    "        # Compute latent dimension\n",
    "        z0 = self.hid2lat(h0[0])\n",
    "        z0_mean = z0[:, :self.latent_dim]\n",
    "        z0_log_var = z0[:, self.latent_dim:]\n",
    "        return z0_mean, z0_log_var\n",
    "\n",
    "class NeuralODEDecoder(nn.Module):\n",
    "    def __init__(self, output_dim, hidden_dim, latent_dim):\n",
    "        super(NeuralODEDecoder, self).__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        func = NNODEF(latent_dim, hidden_dim, time_invariant=True)\n",
    "        self.ode = NeuralODE(func)\n",
    "        self.l2h = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.h2o = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, z0, t):\n",
    "        zs = self.ode(z0, t, return_whole_sequence=True)\n",
    "\n",
    "        hs = self.l2h(zs)\n",
    "        xs = self.h2o(hs)\n",
    "        return xs\n",
    "\n",
    "class ODEVAE(nn.Module):\n",
    "    def __init__(self, output_dim, hidden_dim, latent_dim):\n",
    "        super(ODEVAE, self).__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        self.encoder = RNNEncoder(output_dim, hidden_dim, latent_dim)\n",
    "        self.decoder = NeuralODEDecoder(output_dim, hidden_dim, latent_dim)\n",
    "\n",
    "    def forward(self, x, t, MAP=False):\n",
    "        z_mean, z_log_var = self.encoder(x, t)\n",
    "        if MAP:\n",
    "            z = z_mean\n",
    "        else:\n",
    "            z = z_mean + torch.randn_like(z_mean) * torch.exp(0.5 * z_log_var)\n",
    "        x_p = self.decoder(z, t)\n",
    "        return x_p, z, z_mean, z_log_var\n",
    "\n",
    "    def generate_with_seed(self, seed_x, t):\n",
    "        seed_t_len = seed_x.shape[0]\n",
    "        z_mean, z_log_var = self.encoder(seed_x, t[:seed_t_len])\n",
    "        x_p = self.decoder(z_mean, t)\n",
    "        return x_p\n",
    "\n",
    "\n",
    "def create_batch_latent(X, y, N_Max):\n",
    "    idx = [np.random.randint(0, X.shape[0]) for _ in range(20)]\n",
    "    obs_ = torch.from_numpy(X[idx, :].astype(np.float32).T).unsqueeze(2)\n",
    "    ts_ = np.vstack(N_Max).astype(np.float32).reshape([-1, 1])\n",
    "    ts_ = torch.from_numpy(np.repeat(ts_, obs_.shape[1], axis=1)).unsqueeze(2)\n",
    "    ho_ = torch.from_numpy(np.repeat(y[idx].astype(\n",
    "        np.float32).reshape([1, -1]), obs_.shape[0], axis=0)).unsqueeze(2)\n",
    "    return obs_, ts_, ho_\n",
    "\n",
    "\n",
    "def create_batch_latent_order(X, y, N_Max):\n",
    "    idx = [i for i in range(X.shape[0])]\n",
    "    obs_ = torch.from_numpy(X[idx, :].astype(np.float32).T).unsqueeze(2)\n",
    "    ts_ = np.vstack(N_Max).astype(np.float32).reshape([-1, 1])\n",
    "    ts_ = torch.from_numpy(np.repeat(ts_, obs_.shape[1], axis=1)).unsqueeze(2)\n",
    "    ho_ = torch.from_numpy(np.repeat(y[idx].astype(\n",
    "        np.float32).reshape([1, -1]), obs_.shape[0], axis=0)).unsqueeze(2)\n",
    "    return obs_, ts_, ho_\n",
    "\n",
    "def conduct_experiment_latent(X, step_model_optimizer_loss, save_path, device='cpu', epochs=5000, save_iter=1000, print_iter=100):\n",
    "    z0 = Variable(torch.Tensor([[0.6, 0.3]]))\n",
    "    E = X[()]['data'][:, 1:]\n",
    "    h_omega = X[()]['data'][:, 0]/50\n",
    "    N_Max = X[()]['Nmax'].reshape([-1])/18\n",
    "    n_points = h_omega.shape[0]\n",
    "    noise_std = 1\n",
    "    permutation = [np.random.randint(0, n_points) for k in range(10)]\n",
    "    ETr = E[permutation]\n",
    "    h_omegaT = h_omega[permutation]\n",
    "    # Train Neural ODE\n",
    "    prev_epoch, ode_trained, optimizer, prev_loss = step_model_optimizer_loss\n",
    "    print(\"Starting training from epoch \", prev_epoch, flush=True)\n",
    "    for i in range(prev_epoch, epochs):\n",
    "        obs_, ts_, ho_ = create_batch_latent(ETr, h_omegaT, N_Max)\n",
    "        input_d = torch.cat( [obs_, ho_], axis=2).to(device)\n",
    "        x_p, z, z_mean, z_log_var = ode_trained(input_d, ts_.to(device))\n",
    "        kl_loss = -0.5 * torch.sum(1 + z_log_var - z_mean**2 - torch.exp(z_log_var), -1)\n",
    "        error_loss = 0.5 * ((input_d-x_p)**2).sum(-1).sum(0) / noise_std**2\n",
    "        loss = torch.mean(error_loss+ kl_loss)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        if i % print_iter == 0:\n",
    "            print(\"(Print) Epoch:\", i, \"Total_Loss: \"+str(loss.item()) + \" with error\", str(torch.mean(error_loss).item())+\\\n",
    "                  \" KL divergence \" + str(torch.mean(kl_loss).item()), flush=True)\n",
    "        if i % save_iter == 0 or i == epochs:\n",
    "            print(\"(Save) Epoch:\", i, \"Total_Loss: \"+str(loss.item()) + \" with error\", str(torch.mean(error_loss).item())+\\\n",
    "                  \" KL divergence \" + str(torch.mean(kl_loss).item()), flush=True)\n",
    "            torch.save({\n",
    "                'step': i,\n",
    "                'model_state_dict': ode_trained.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss\n",
    "                },\n",
    "                save_path)\n",
    "            obs_, ts_, ho_ = create_batch_latent_order(E, h_omega, N_Max)\n",
    "            input_d = torch.cat([obs_, ho_], axis=2).to(device)\n",
    "            samp_trajs_p = to_np(ode_trained.generate_with_seed(input_d, ts_.to(device)))\n",
    "            #print(samp_trajs_p.shape)\n",
    "\n",
    "            plt.figure()\n",
    "            fig, axes = plt.subplots(nrows=3, ncols=6, facecolor='white', figsize=(9, 9),\\\n",
    "                    gridspec_kw={'wspace': 0.5, 'hspace': 0.5}, dpi=400)\n",
    "            axes = axes.flatten()\n",
    "            for j, ax in enumerate(axes):\n",
    "                ax.plot(18*to_np(ts_[:, j, 0]), to_np(input_d[:, j, 0]), label='real', linewidth = 1)\n",
    "                ax.scatter(18*ts_[:, j, 0], samp_trajs_p[:, j, 0], 3,\n",
    "                           label=\"predicted\" , marker='*',\n",
    "                           c=samp_trajs_p[:, j, 0], cmap=cm.plasma)\n",
    "                ax.grid(\"True\")\n",
    "                ax.set_xlabel('NMax, \\n h$\\\\Omega$ ='\\\n",
    "                    +str( np.round(ho_[0,j,0].item()*50, 2 )), fontsize = 10)\n",
    "                if j == 5:\n",
    "                    ax.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "                if j == 0 or j==6 or j ==12:\n",
    "                    ax.set_ylabel('Ground state Energy', fontsize = 10)\n",
    "            plt.text(20, 75, \"\\n Total loss: \"+str(np.round(loss.item(), 2)) + \"\\n with error: \"\\\n",
    "                + str(np.round(torch.mean(error_loss).item(), 2))+\" \\n KL divergence: \" + str(np.round(torch.mean(kl_loss).item(), 2)))\n",
    "            plt.savefig('Figures/training/reconstruction_'+str(i)+'.png', dpi= 300,  bbox_inches=\"tight\")\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "\n",
    "########################################################################\n",
    "## Plot the first one\n",
    "def plot_homega_average_(n_models, X, odes):\n",
    "    traj_mean = []\n",
    "    traj_var = []\n",
    "    E = X[()]['data'][:, 1:]\n",
    "    h_omega = X[()]['data'][:, 0]/50\n",
    "    N_Max = X[()]['Nmax'].reshape([-1])/18\n",
    "    obs_, ts_, ho_ = create_batch_latent_order(E, h_omega, N_Max)\n",
    "    input_d = torch.cat([obs_, ho_], axis=2)\n",
    "    \n",
    "    for i in range(n_models):\n",
    "        ode_trained = odes[i]\n",
    "        samp_trajs_p = to_np(ode_trained.generate_with_seed(input_d, ts_))\n",
    "        traj_mean.append( np.mean(samp_trajs_p, axis = 1) )\n",
    "        traj_var.append(np.std(samp_trajs_p, axis=1)**2)\n",
    "\n",
    "    plt.figure()\n",
    "    traj_mean = np.array(traj_mean)\n",
    "    traj_var = np.array(traj_var)\n",
    "    mu = np.mean(traj_mean, axis = 0)\n",
    "    var = np.mean(traj_var, axis = 0)\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=1, facecolor='white', figsize=(\n",
    "    8, 3),  gridspec_kw={'wspace': 0.5, 'hspace': 0.5}, dpi=400)\n",
    "    axes.scatter((18*ts_[:,0, 0]).reshape([-1,1]),  mu[:,0],  label=\"predicted\",\\\n",
    "        marker='*', c=samp_trajs_p[:, 0, 0], cmap=cm.plasma)\n",
    "    axes.fill_between(18*ts_[:, 0, 0].reshape([-1]), (mu[:, 0] - var[:, 0] ).reshape([-1]),\\\n",
    "        (mu[:, 0]+var[:, 0]).reshape([-1]), color='gray', alpha=0.2)\n",
    "    axes.grid(\"True\")\n",
    "    axes.set_xlabel('NMax', fontsize=10)\n",
    "    axes.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "    axes.set_ylabel('Ground state Energy', fontsize=10)\n",
    "    plt.title(\"Ground State Energy averaged w.r.t. $\\\\overline{h} \\\\Omega$\")\n",
    "    plt.savefig('Figures/reconstruction_extrapolation_averaged_homega__.png', dpi=300,  bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_model_averaged_(n_models, X, odes):\n",
    "    traj = []\n",
    "    E = X[()]['data'][:, 1:]\n",
    "    h_omega = X[()]['data'][:, 0]/50\n",
    "    N_Max = X[()]['Nmax'].reshape([-1])/18\n",
    "    obs_, ts_, ho_ = create_batch_latent_order(E, h_omega, N_Max)\n",
    "    input_d = torch.cat([obs_, ho_], axis=2)\n",
    "    for i in range(n_models):\n",
    "        ode_trained = odes[i]\n",
    "        samp_trajs_p = to_np(ode_trained.generate_with_seed(input_d, ts_))\n",
    "        traj.append(samp_trajs_p[:, :, 0])\n",
    "\n",
    "\n",
    "    mu = np.mean(np.array(traj), axis=0)\n",
    "    var = np.std(np.array(traj), axis=0)\n",
    "\n",
    "\n",
    "    plt.figure()\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=6, facecolor='white', figsize=(\n",
    "        16, 9),  gridspec_kw={'wspace': 0.5, 'hspace': 0.5}, dpi=400)\n",
    "    axes = axes.flatten()\n",
    "    for j, ax in enumerate(axes):\n",
    "        ax.scatter((18*ts_[:, 0, 0]).reshape([-1, 1]),  mu[:, j],\n",
    "            label=\"predicted\", marker='*', c=samp_trajs_p[:, j, 0], cmap=cm.plasma)\n",
    "        ax.fill_between(18*ts_[:, 0, 0].reshape([-1]), (mu[:, j] - var[:, j] ).reshape([-1]),\\\n",
    "            (mu[:, j]+var[:, j]).reshape([-1]), color='gray', alpha=0.2)\n",
    "        ax.grid(\"True\")\n",
    "        ax.set_xlabel('NMax, \\n h$\\\\Omega$ = '+str(np.round(ho_[0, j, 0].item()*50, 2)), fontsize=10)\n",
    "        if j == 5:\n",
    "            ax.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "        if j == 0 or j == 6 or j == 12:\n",
    "            ax.set_ylabel('Ground state Energy', fontsize=10)\n",
    "            ax.set_title(\"Ground State Energy averaged  w.r.t. models\")\n",
    "        ax.set_ylim([-15, -33])\n",
    "        # ax.set_xlim([-35,0])\n",
    "\n",
    "    plt.savefig('Figures/reconstruction_extrapolation_model_averaged__.png',\n",
    "                dpi=300,  bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def load_checkpoint(path, device='cpu'):\n",
    "    step = 0\n",
    "    loss = 0\n",
    "    model = ODEVAE(2, 128, 6)\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    if os.path.exists(path):\n",
    "        checkpoint = torch.load(PATH)\n",
    "        step = checkpoint['step']\n",
    "        loss = checkpoint['loss']\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    return step, model, optimizer, loss\n",
    "\n",
    "\n",
    "def train_model(stuff):\n",
    "    i, model, device = stuff\n",
    "    PATH = 'models/Trained_ode_'+str(i)\n",
    "    X = np.load('data/processed_extrapolation.npy', allow_pickle=True)\n",
    "    print(F'Launch training of model {i} on process {mp.current_process().pid}', flush=True)\n",
    "    conduct_experiment_latent(X, model, PATH, device=device, epochs=30000, save_iter=100, print_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## The main run loop\n",
    "if __name__ == '__main__':\n",
    "    mp.set_start_method('spawn')\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    use_cuda = True\n",
    "    if use_cuda:\n",
    "        devices = [torch.device('cuda:%d' % i) for i in range(torch.cuda.device_count())]\n",
    "        num_devices = len(devices)\n",
    "        num_processes = num_devices\n",
    "    else:\n",
    "        num_processes = 1\n",
    "        devices = [torch.device('cpu')] * num_processes\n",
    "        num_devices = len(devices)\n",
    "    print(F'use_cuda = {use_cuda}, num_devices = {num_devices}, num_processes = {num_processes}', flush=True)\n",
    "\n",
    "    odes = []\n",
    "    n_models__ = 100\n",
    "    for i in range(n_models__):\n",
    "        odes.append(ODEVAE(2, 128, 6))\n",
    "    X = np.load('data/processed_extrapolation.npy', allow_pickle=True)\n",
    "    plot_homega_average_(n_models__, X, odes)\n",
    "    plot_model_averaged_(n_models__, X, odes)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
