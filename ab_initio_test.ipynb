{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db34a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd42b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "pds_xls = pd.read_excel(\"6Li_with_Daejeon16_gs_energy_from_Dropbox.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28de3b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "pds_xls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ef257a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pds_xls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bd77ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pds_xls.pop(pds_xls.columns[1])\n",
    "pds_xls.pop(pds_xls.columns[len(pds_xls.columns)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146a5cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pds_xls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a78c0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_xls.pop(pds_xls.columns[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b485a9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = pds_xls.to_numpy()\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11f685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datum = {'Nmax': N_Max, 'data': data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0ebf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save( 'processed_extrapolation.npy', datum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "a633f037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.load('processed_extrapolation.npy', allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "031bb366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  8.      -16.57529 -22.07245 -25.76041 -28.26697 -29.85611 -30.82073\n",
      "  -31.37646 -31.68395 -31.8479 ]\n",
      " [  9.      -18.76554 -24.21102 -27.54317 -29.59771 -30.75878 -31.38568\n",
      "  -31.70678 -31.8667  -31.94453]\n",
      " [ 10.      -20.62863 -25.90418 -28.81887 -30.44101 -31.25914 -31.65792\n",
      "  -31.84509 -31.93299 -31.97466]\n",
      " [ 12.5     -23.92152 -28.51269 -30.44546 -31.30909 -31.67491 -31.8374\n",
      "  -31.91427 -31.95437 -31.97709]\n",
      " [ 15.      -25.57763 -29.50027 -30.86382 -31.43441 -31.68819 -31.81424\n",
      "  -31.88416 -31.92669 -31.95399]\n",
      " [ 17.5     -26.05861 -29.57761 -30.78639 -31.32032 -31.58441 -31.73186\n",
      "  -31.82064 -31.87769 -31.91603]\n",
      " [ 20.      -25.7044  -29.14255 -30.45505 -31.07796 -31.40886 -31.60391\n",
      "  -31.72595 -31.8062  -31.86106]\n",
      " [ 22.5     -24.67286 -28.36076 -29.931   -30.72161 -31.16096 -31.42602\n",
      "  -31.59523 -31.70796 -31.78564]\n",
      " [ 25.      -23.01104 -27.27792 -29.22278 -30.2445  -30.8306  -31.18986\n",
      "  -31.42179 -31.57754 -31.68565]\n",
      " [ 27.5     -20.7303  -25.88942 -28.32302 -29.63613 -30.40687 -30.88621\n",
      "  -31.19842 -31.4095  -31.55667]\n",
      " [ 30.      -17.83933 -24.17577 -27.21829 -28.88568 -29.87984 -30.5062\n",
      "  -30.91779 -31.19782 -31.39395]\n",
      " [ 32.5     -14.35257 -22.11859 -25.89369 -27.98276 -29.24114 -30.04231\n",
      "  -30.5734  -30.93702 -31.19283]\n",
      " [ 35.      -10.28989 -19.70531 -24.33523 -26.91708 -28.48301 -29.48793\n",
      "  -30.15929 -30.62196 -30.94925]\n",
      " [ 37.5      -5.67529 -16.92969 -22.53144 -25.67878 -27.59798 -28.83691\n",
      "  -29.67001 -30.24772 -30.65846]\n",
      " [ 40.       -0.53572 -13.79125 -20.47436 -24.25945 -26.57929 -28.08387\n",
      "  -29.10095 -29.8102  -30.31705]\n",
      " [ 42.5       5.09995 -10.2941  -18.15945 -22.65236 -25.42084 -27.22389\n",
      "  -28.4479  -29.30552 -29.92168]\n",
      " [ 45.       11.20194  -6.44575 -15.58501 -20.85256 -24.11726 -26.2523\n",
      "  -27.7069  -28.73045 -29.46899]\n",
      " [ 47.5      17.74026  -2.25632 -12.75183 -18.85687 -22.66422 -25.16495\n",
      "  -26.8747  -28.08199 -28.95641]\n",
      " [ 50.       24.68502   2.26209  -9.66277 -16.66379 -21.05843 -23.95823\n",
      "  -25.9478  -27.35716 -28.3814 ]]\n",
      "[2 4 6 8 10 12 14 16 18]\n"
     ]
    }
   ],
   "source": [
    "print(X[()]['data'])\n",
    "print(X[()]['Nmax'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "d0a61ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to figure out a network now, the idea is to get an ODE to integrate this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "9b48c082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.color_palette(\"bright\")\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "from torch.nn  import functional as F \n",
    "from torch.autograd import Variable\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "\n",
    "def ode_solve(z0, t0, t1, f):\n",
    "    \"\"\"\n",
    "    Simplest Euler ODE initial value solver\n",
    "    \"\"\"\n",
    "    h_max = 0.05\n",
    "    n_steps = math.ceil((abs(t1 - t0)/h_max).max().item())\n",
    "\n",
    "    h = (t1 - t0)/n_steps\n",
    "    t = t0\n",
    "    z = z0\n",
    "\n",
    "    for i_step in range(n_steps):\n",
    "        z = z + h * f(z, t)\n",
    "        t = t + h\n",
    "    return z\n",
    "\n",
    "\n",
    "\n",
    "## Let us now figure out how to get a model.\n",
    "class ODEF(nn.Module):\n",
    "    def forward_with_grad(self, z, t, grad_outputs):\n",
    "        \"\"\"Compute f and a df/dz, a df/dp, a df/dt\"\"\"\n",
    "        batch_size = z.shape[0]\n",
    "\n",
    "        out = self.forward(z, t)\n",
    "\n",
    "        a = grad_outputs\n",
    "        adfdz, adfdt, *adfdp = torch.autograd.grad(\n",
    "            (out,), (z, t) + tuple(self.parameters()), grad_outputs=(a),\n",
    "            allow_unused=True, retain_graph=True\n",
    "        )\n",
    "        # grad method automatically sums gradients for batch items, we have to expand them back\n",
    "        if adfdp is not None:\n",
    "            adfdp = torch.cat([p_grad.flatten()\n",
    "                              for p_grad in adfdp]).unsqueeze(0)\n",
    "            adfdp = adfdp.expand(batch_size, -1) / batch_size\n",
    "        if adfdt is not None:\n",
    "            adfdt = adfdt.expand(batch_size, 1) / batch_size\n",
    "        return out, adfdz, adfdt, adfdp\n",
    "\n",
    "    def flatten_parameters(self):\n",
    "        p_shapes = []\n",
    "        flat_parameters = []\n",
    "        for p in self.parameters():\n",
    "            p_shapes.append(p.size())\n",
    "            flat_parameters.append(p.flatten())\n",
    "        return torch.cat(flat_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "dd9a33e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODEAdjoint(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, z0, t, flat_parameters, func):\n",
    "        assert isinstance(func, ODEF)\n",
    "        bs, *z_shape = z0.size()\n",
    "        time_len = t.size(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            z = torch.zeros(time_len, bs, *z_shape).to(z0)\n",
    "            z[0] = z0\n",
    "            for i_t in range(time_len - 1):\n",
    "                z0 = ode_solve(z0, t[i_t], t[i_t+1], func)\n",
    "                z[i_t+1] = z0\n",
    "\n",
    "        ctx.func = func\n",
    "        ctx.save_for_backward(t, z.clone(), flat_parameters)\n",
    "        return z\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, dLdz):\n",
    "        \"\"\"\n",
    "        dLdz shape: time_len, batch_size, *z_shape\n",
    "        \"\"\"\n",
    "        func = ctx.func\n",
    "        t, z, flat_parameters = ctx.saved_tensors\n",
    "        time_len, bs, *z_shape = z.size()\n",
    "        n_dim = np.prod(z_shape)\n",
    "        n_params = flat_parameters.size(0)\n",
    "\n",
    "        # Dynamics of augmented system to be calculated backwards in time\n",
    "        def augmented_dynamics(aug_z_i, t_i):\n",
    "            \"\"\"\n",
    "            tensors here are temporal slices\n",
    "            t_i - is tensor with size: bs, 1\n",
    "            aug_z_i - is tensor with size: bs, n_dim*2 + n_params + 1\n",
    "            \"\"\"\n",
    "            z_i, a = aug_z_i[:, :n_dim], aug_z_i[:, n_dim:2*n_dim]  # ignore parameters and time\n",
    "\n",
    "            # Unflatten z and a\n",
    "            z_i = z_i.view(bs, *z_shape)\n",
    "            a = a.view(bs, *z_shape)\n",
    "            with torch.set_grad_enabled(True):\n",
    "                t_i = t_i.detach().requires_grad_(True)\n",
    "                z_i = z_i.detach().requires_grad_(True)\n",
    "                func_eval, adfdz, adfdt, adfdp = func.forward_with_grad(z_i, t_i, grad_outputs=a)  # bs, *z_shape\n",
    "                adfdz = adfdz.to(z_i) if adfdz is not None else torch.zeros(bs, *z_shape).to(z_i)\n",
    "                adfdp = adfdp.to(z_i) if adfdp is not None else torch.zeros(bs, n_params).to(z_i)\n",
    "                adfdt = adfdt.to(z_i) if adfdt is not None else torch.zeros(bs, 1).to(z_i)\n",
    "\n",
    "            # Flatten f and adfdz\n",
    "            func_eval = func_eval.view(bs, n_dim)\n",
    "            adfdz = adfdz.view(bs, n_dim) \n",
    "            return torch.cat((func_eval, -adfdz, -adfdp, -adfdt), dim=1)\n",
    "\n",
    "        dLdz = dLdz.view(time_len, bs, n_dim)  # flatten dLdz for convenience\n",
    "        with torch.no_grad():\n",
    "            ## Create placeholders for output gradients\n",
    "            # Prev computed backwards adjoints to be adjusted by direct gradients\n",
    "            adj_z = torch.zeros(bs, n_dim).to(dLdz)\n",
    "            adj_p = torch.zeros(bs, n_params).to(dLdz)\n",
    "            # In contrast to z and p we need to return gradients for all times\n",
    "            adj_t = torch.zeros(time_len, bs, 1).to(dLdz)\n",
    "\n",
    "            for i_t in range(time_len-1, 0, -1):\n",
    "                z_i = z[i_t]\n",
    "                t_i = t[i_t]\n",
    "                f_i = func(z_i, t_i).view(bs, n_dim)\n",
    "\n",
    "                # Compute direct gradients\n",
    "                dLdz_i = dLdz[i_t]\n",
    "                dLdt_i = torch.bmm(torch.transpose(dLdz_i.unsqueeze(-1), 1, 2), f_i.unsqueeze(-1))[:, 0]\n",
    "\n",
    "                # Adjusting adjoints with direct gradients\n",
    "                adj_z += dLdz_i\n",
    "                adj_t[i_t] = adj_t[i_t] - dLdt_i\n",
    "\n",
    "                # Pack augmented variable\n",
    "                aug_z = torch.cat((z_i.view(bs, n_dim), adj_z, torch.zeros(bs, n_params).to(z), adj_t[i_t]), dim=-1)\n",
    "\n",
    "                # Solve augmented system backwards\n",
    "                aug_ans = ode_solve(aug_z, t_i, t[i_t-1], augmented_dynamics)\n",
    "\n",
    "                # Unpack solved backwards augmented system\n",
    "                adj_z[:] = aug_ans[:, n_dim:2*n_dim]\n",
    "                adj_p[:] += aug_ans[:, 2*n_dim:2*n_dim + n_params]\n",
    "                adj_t[i_t-1] = aug_ans[:, 2*n_dim + n_params:]\n",
    "\n",
    "                del aug_z, aug_ans\n",
    "\n",
    "            ## Adjust 0 time adjoint with direct gradients\n",
    "            # Compute direct gradients \n",
    "            dLdz_0 = dLdz[0]\n",
    "            dLdt_0 = torch.bmm(torch.transpose(dLdz_0.unsqueeze(-1), 1, 2), f_i.unsqueeze(-1))[:, 0]\n",
    "\n",
    "            # Adjust adjoints\n",
    "            adj_z += dLdz_0\n",
    "            adj_t[0] = adj_t[0] - dLdt_0\n",
    "        return adj_z.view(bs, *z_shape), adj_t, adj_p, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "e33de136",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralODE(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super(NeuralODE, self).__init__()\n",
    "        assert isinstance(func, ODEF)\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, z0, t=Tensor([0., 1.]), return_whole_sequence=False):\n",
    "        t = t.to(z0)\n",
    "        # print(\"the data\", t, t.size(), z0.size())\n",
    "        z = ODEAdjoint.apply(z0, t, self.func.flatten_parameters(), self.func)\n",
    "        if return_whole_sequence:\n",
    "            return z\n",
    "        else:\n",
    "            return z[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893ddd41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "4528246c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNODEF(ODEF):\n",
    "    def __init__(self, in_dim, hid_dim, time_invariant=False):\n",
    "        super(NNODEF, self).__init__()\n",
    "        self.time_invariant = time_invariant\n",
    "        \n",
    "        if time_invariant:\n",
    "            self.lin1 = nn.Linear(in_dim, hid_dim)\n",
    "        else:\n",
    "            self.lin1 = nn.Linear(in_dim+1, hid_dim)\n",
    "        self.lin2     = nn.Linear(hid_dim, hid_dim)\n",
    "        self.lin3     = nn.Linear(hid_dim, in_dim)\n",
    "        self.elu      = nn.ELU(inplace=True)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        # print(x.shape, t.shape)\n",
    "        if not self.time_invariant:\n",
    "            x = torch.cat((x, t.reshape([1,-1]) ), dim=-1)\n",
    "        # print(x.shape)\n",
    "        h = self.elu(self.lin1(x))\n",
    "        h = self.elu(self.lin2(h))\n",
    "        out = self.lin3(h)\n",
    "        return out\n",
    "    \n",
    "def to_np(x):\n",
    "    return x.detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "3fe98238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conduct_experiment(X, ode_trained, n_steps):\n",
    "    \n",
    "\n",
    "    z0 = Variable(torch.Tensor([[0.6, 0.3]]))\n",
    "\n",
    "\n",
    "\n",
    "    E= X[()]['data'][:,1:]\n",
    "    h_omega = X[()]['data'][:,0]/50\n",
    "    N_Max = X[()]['Nmax'].reshape([-1])/18\n",
    "    n_points =h_omega.shape[0]\n",
    "\n",
    " \n",
    "    def create_batch():\n",
    "        idx = np.random.randint(0, n_points)      \n",
    "        ho_ = h_omega[idx].astype(np.float32)\n",
    "        obs_ = E[idx, :].astype(np.float32)\n",
    "        ts_ = np.vstack(N_Max).astype(np.float32)\n",
    "        print(idx, ho_.dtype, obs_.dtype, ts_.dtype)\n",
    "        return torch.from_numpy(np.array(obs_)), torch.from_numpy(np.array(ts_)), ho_\n",
    "\n",
    "    # Train Neural ODE\n",
    "    optimizer = torch.optim.Adam(ode_trained.parameters(), lr=0.01)\n",
    "    for i in range(n_steps):\n",
    "        obs_, ts_, ho_ = create_batch()\n",
    "        # print(obs_[0], torch.tensor(ho_))\n",
    "        input_d= torch.cat([obs_[0].reshape([1,-1]), torch.tensor(ho_).reshape([1, -1 ])], axis = 1)\n",
    "        # print(input_d, input_d.shape, ts_)\n",
    "        z_ = ode_trained(input_d, ts_, return_whole_sequence=True).squeeze(1)\n",
    "        input_d = torch.cat([obs_.reshape([-1,1]), torch.tensor(np.tile(ho_, 9)).reshape([-1,1])], axis=1)\n",
    "        # print(z_.shape, input_d.shape)\n",
    "        loss = F.mse_loss(z_, input_d.detach())\n",
    "        print(\"The loss is:\", loss.item(), \"at step\", i)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "4a5abd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 float32 float32 float32\n",
      "The loss is: 200.4632568359375 at step 0\n",
      "17 float32 float32 float32\n",
      "The loss is: 703.2500610351562 at step 1\n",
      "1 float32 float32 float32\n",
      "The loss is: 54.1910285949707 at step 2\n",
      "10 float32 float32 float32\n",
      "The loss is: 55.01251983642578 at step 3\n",
      "11 float32 float32 float32\n",
      "The loss is: 83.89783477783203 at step 4\n",
      "11 float32 float32 float32\n",
      "The loss is: 81.16926574707031 at step 5\n",
      "13 float32 float32 float32\n",
      "The loss is: 188.9925537109375 at step 6\n",
      "10 float32 float32 float32\n",
      "The loss is: 44.31179428100586 at step 7\n",
      "9 float32 float32 float32\n",
      "The loss is: 22.426122665405273 at step 8\n",
      "17 float32 float32 float32\n",
      "The loss is: 666.849853515625 at step 9\n",
      "13 float32 float32 float32\n",
      "The loss is: 177.4063720703125 at step 10\n",
      "11 float32 float32 float32\n",
      "The loss is: 60.83683395385742 at step 11\n",
      "10 float32 float32 float32\n",
      "The loss is: 28.76845932006836 at step 12\n",
      "17 float32 float32 float32\n",
      "The loss is: 647.0274047851562 at step 13\n",
      "18 float32 float32 float32\n",
      "The loss is: 809.7510375976562 at step 14\n",
      "10 float32 float32 float32\n",
      "The loss is: 19.772457122802734 at step 15\n",
      "12 float32 float32 float32\n",
      "The loss is: 85.27053833007812 at step 16\n",
      "9 float32 float32 float32\n",
      "The loss is: 5.468922138214111 at step 17\n",
      "15 float32 float32 float32\n",
      "The loss is: 370.8682861328125 at step 18\n",
      "2 float32 float32 float32\n",
      "The loss is: 6.206645965576172 at step 19\n",
      "14 float32 float32 float32\n",
      "The loss is: 256.4897766113281 at step 20\n",
      "13 float32 float32 float32\n",
      "The loss is: 134.53802490234375 at step 21\n",
      "2 float32 float32 float32\n",
      "The loss is: 10.434374809265137 at step 22\n",
      "15 float32 float32 float32\n",
      "The loss is: 359.10650634765625 at step 23\n",
      "13 float32 float32 float32\n",
      "The loss is: 121.30550384521484 at step 24\n",
      "17 float32 float32 float32\n",
      "The loss is: 552.5060424804688 at step 25\n",
      "8 float32 float32 float32\n",
      "The loss is: 56.158138275146484 at step 26\n",
      "17 float32 float32 float32\n",
      "The loss is: 533.849365234375 at step 27\n",
      "3 float32 float32 float32\n",
      "The loss is: 56.71881866455078 at step 28\n",
      "5 float32 float32 float32\n",
      "The loss is: 76.8111572265625 at step 29\n",
      "6 float32 float32 float32\n",
      "The loss is: 54.96467590332031 at step 30\n",
      "4 float32 float32 float32\n",
      "The loss is: 36.931724548339844 at step 31\n",
      "2 float32 float32 float32\n",
      "The loss is: 6.727362155914307 at step 32\n",
      "3 float32 float32 float32\n",
      "The loss is: 9.987957000732422 at step 33\n",
      "10 float32 float32 float32\n",
      "The loss is: 13.794506072998047 at step 34\n",
      "5 float32 float32 float32\n",
      "The loss is: 9.674722671508789 at step 35\n",
      "16 float32 float32 float32\n",
      "The loss is: 396.1150817871094 at step 36\n",
      "1 float32 float32 float32\n",
      "The loss is: 18.95078468322754 at step 37\n",
      "5 float32 float32 float32\n",
      "The loss is: 3.6257383823394775 at step 38\n",
      "11 float32 float32 float32\n",
      "The loss is: 52.35699462890625 at step 39\n",
      "8 float32 float32 float32\n",
      "The loss is: 4.6818623542785645 at step 40\n",
      "10 float32 float32 float32\n",
      "The loss is: 27.941274642944336 at step 41\n",
      "11 float32 float32 float32\n",
      "The loss is: 56.748451232910156 at step 42\n",
      "10 float32 float32 float32\n",
      "The loss is: 29.338918685913086 at step 43\n",
      "14 float32 float32 float32\n",
      "The loss is: 248.86590576171875 at step 44\n",
      "9 float32 float32 float32\n",
      "The loss is: 13.64749526977539 at step 45\n",
      "1 float32 float32 float32\n",
      "The loss is: 27.084928512573242 at step 46\n",
      "1 float32 float32 float32\n",
      "The loss is: 26.81066131591797 at step 47\n",
      "8 float32 float32 float32\n",
      "The loss is: 5.366673946380615 at step 48\n",
      "16 float32 float32 float32\n",
      "The loss is: 366.9971618652344 at step 49\n",
      "9 float32 float32 float32\n",
      "The loss is: 12.403885841369629 at step 50\n",
      "16 float32 float32 float32\n",
      "The loss is: 360.3545227050781 at step 51\n",
      "4 float32 float32 float32\n",
      "The loss is: 2.2660558223724365 at step 52\n",
      "17 float32 float32 float32\n",
      "The loss is: 412.52032470703125 at step 53\n",
      "18 float32 float32 float32\n",
      "The loss is: 466.85113525390625 at step 54\n",
      "11 float32 float32 float32\n",
      "The loss is: 52.13239288330078 at step 55\n",
      "17 float32 float32 float32\n",
      "The loss is: 372.1738586425781 at step 56\n",
      "12 float32 float32 float32\n",
      "The loss is: 93.39569854736328 at step 57\n",
      "13 float32 float32 float32\n",
      "The loss is: 155.3539581298828 at step 58\n",
      "12 float32 float32 float32\n",
      "The loss is: 90.17620086669922 at step 59\n",
      "13 float32 float32 float32\n",
      "The loss is: 150.5065460205078 at step 60\n",
      "15 float32 float32 float32\n",
      "The loss is: 247.58224487304688 at step 61\n",
      "6 float32 float32 float32\n",
      "The loss is: 8.103163719177246 at step 62\n",
      "0 float32 float32 float32\n",
      "The loss is: 24.92290687561035 at step 63\n",
      "12 float32 float32 float32\n",
      "The loss is: 76.25381469726562 at step 64\n",
      "17 float32 float32 float32\n",
      "The loss is: 261.78607177734375 at step 65\n",
      "9 float32 float32 float32\n",
      "The loss is: 8.401836395263672 at step 66\n",
      "3 float32 float32 float32\n",
      "The loss is: 13.950481414794922 at step 67\n",
      "6 float32 float32 float32\n",
      "The loss is: 24.3944091796875 at step 68\n",
      "11 float32 float32 float32\n",
      "The loss is: 29.568050384521484 at step 69\n",
      "18 float32 float32 float32\n",
      "The loss is: 237.02845764160156 at step 70\n",
      "11 float32 float32 float32\n",
      "The loss is: 28.324129104614258 at step 71\n",
      "15 float32 float32 float32\n",
      "The loss is: 184.68206787109375 at step 72\n",
      "8 float32 float32 float32\n",
      "The loss is: 12.70059871673584 at step 73\n",
      "0 float32 float32 float32\n",
      "The loss is: 14.304994583129883 at step 74\n",
      "13 float32 float32 float32\n",
      "The loss is: 116.48661041259766 at step 75\n",
      "9 float32 float32 float32\n",
      "The loss is: 8.16379165649414 at step 76\n",
      "16 float32 float32 float32\n",
      "The loss is: 155.81585693359375 at step 77\n",
      "14 float32 float32 float32\n",
      "The loss is: 161.3462371826172 at step 78\n",
      "15 float32 float32 float32\n",
      "The loss is: 148.40521240234375 at step 79\n",
      "3 float32 float32 float32\n",
      "The loss is: 28.87099838256836 at step 80\n",
      "4 float32 float32 float32\n",
      "The loss is: 45.93878936767578 at step 81\n",
      "17 float32 float32 float32\n",
      "The loss is: 124.13681030273438 at step 82\n",
      "14 float32 float32 float32\n",
      "The loss is: 140.42613220214844 at step 83\n",
      "5 float32 float32 float32\n",
      "The loss is: 40.201454162597656 at step 84\n",
      "15 float32 float32 float32\n",
      "The loss is: 116.31328582763672 at step 85\n",
      "13 float32 float32 float32\n",
      "The loss is: 101.56552124023438 at step 86\n",
      "3 float32 float32 float32\n",
      "The loss is: 15.305228233337402 at step 87\n",
      "12 float32 float32 float32\n",
      "The loss is: 50.11176681518555 at step 88\n",
      "13 float32 float32 float32\n",
      "The loss is: 95.70693969726562 at step 89\n",
      "5 float32 float32 float32\n",
      "The loss is: 29.93789291381836 at step 90\n",
      "18 float32 float32 float32\n",
      "The loss is: 199.16510009765625 at step 91\n",
      "10 float32 float32 float32\n",
      "The loss is: 8.439187049865723 at step 92\n",
      "8 float32 float32 float32\n",
      "The loss is: 7.467329978942871 at step 93\n",
      "14 float32 float32 float32\n",
      "The loss is: 123.69245147705078 at step 94\n",
      "0 float32 float32 float32\n",
      "The loss is: 18.07526206970215 at step 95\n",
      "4 float32 float32 float32\n",
      "The loss is: 9.587928771972656 at step 96\n",
      "2 float32 float32 float32\n",
      "The loss is: 6.706136703491211 at step 97\n",
      "10 float32 float32 float32\n",
      "The loss is: 11.771162986755371 at step 98\n",
      "15 float32 float32 float32\n",
      "The loss is: 109.35226440429688 at step 99\n",
      "0 float32 float32 float32\n",
      "The loss is: 20.154401779174805 at step 100\n",
      "14 float32 float32 float32\n",
      "The loss is: 127.83583068847656 at step 101\n",
      "5 float32 float32 float32\n",
      "The loss is: 10.680057525634766 at step 102\n",
      "11 float32 float32 float32\n",
      "The loss is: 23.900266647338867 at step 103\n",
      "18 float32 float32 float32\n",
      "The loss is: 70.24376678466797 at step 104\n",
      "6 float32 float32 float32\n",
      "The loss is: 13.340961456298828 at step 105\n",
      "1 float32 float32 float32\n",
      "The loss is: 8.223995208740234 at step 106\n",
      "8 float32 float32 float32\n",
      "The loss is: 7.158011436462402 at step 107\n",
      "16 float32 float32 float32\n",
      "The loss is: 82.48565673828125 at step 108\n",
      "1 float32 float32 float32\n",
      "The loss is: 7.754476547241211 at step 109\n",
      "0 float32 float32 float32\n",
      "The loss is: 12.291543960571289 at step 110\n",
      "17 float32 float32 float32\n",
      "The loss is: 65.87615203857422 at step 111\n",
      "9 float32 float32 float32\n",
      "The loss is: 6.812655925750732 at step 112\n",
      "5 float32 float32 float32\n",
      "The loss is: 22.835777282714844 at step 113\n",
      "2 float32 float32 float32\n",
      "The loss is: 5.569019794464111 at step 114\n",
      "5 float32 float32 float32\n",
      "The loss is: 17.29939842224121 at step 115\n",
      "13 float32 float32 float32\n",
      "The loss is: 82.78667449951172 at step 116\n",
      "13 float32 float32 float32\n",
      "The loss is: 83.5626449584961 at step 117\n",
      "1 float32 float32 float32\n",
      "The loss is: 8.553773880004883 at step 118\n",
      "2 float32 float32 float32\n",
      "The loss is: 5.416485786437988 at step 119\n",
      "12 float32 float32 float32\n",
      "The loss is: 41.62385177612305 at step 120\n",
      "10 float32 float32 float32\n",
      "The loss is: 7.11079216003418 at step 121\n",
      "8 float32 float32 float32\n",
      "The loss is: 9.344520568847656 at step 122\n",
      "14 float32 float32 float32\n",
      "The loss is: 90.68856048583984 at step 123\n",
      "12 float32 float32 float32\n",
      "The loss is: 34.18571472167969 at step 124\n",
      "6 float32 float32 float32\n",
      "The loss is: 25.891674041748047 at step 125\n",
      "4 float32 float32 float32\n",
      "The loss is: 22.13256072998047 at step 126\n",
      "3 float32 float32 float32\n",
      "The loss is: 11.125969886779785 at step 127\n",
      "13 float32 float32 float32\n",
      "The loss is: 68.21128845214844 at step 128\n",
      "6 float32 float32 float32\n",
      "The loss is: 13.957405090332031 at step 129\n",
      "11 float32 float32 float32\n",
      "The loss is: 17.816070556640625 at step 130\n",
      "10 float32 float32 float32\n",
      "The loss is: 7.851137161254883 at step 131\n",
      "12 float32 float32 float32\n",
      "The loss is: 40.59881591796875 at step 132\n",
      "5 float32 float32 float32\n",
      "The loss is: 10.080100059509277 at step 133\n",
      "11 float32 float32 float32\n",
      "The loss is: 19.363576889038086 at step 134\n",
      "14 float32 float32 float32\n",
      "The loss is: 81.9926528930664 at step 135\n",
      "6 float32 float32 float32\n",
      "The loss is: 9.64968490600586 at step 136\n",
      "11 float32 float32 float32\n",
      "The loss is: 17.333255767822266 at step 137\n",
      "14 float32 float32 float32\n",
      "The loss is: 74.47184753417969 at step 138\n",
      "11 float32 float32 float32\n",
      "The loss is: 15.147685050964355 at step 139\n",
      "14 float32 float32 float32\n",
      "The loss is: 66.99695587158203 at step 140\n",
      "14 float32 float32 float32\n",
      "The loss is: 62.59101104736328 at step 141\n",
      "11 float32 float32 float32\n",
      "The loss is: 13.426023483276367 at step 142\n",
      "18 float32 float32 float32\n",
      "The loss is: 133.5650177001953 at step 143\n",
      "17 float32 float32 float32\n",
      "The loss is: 73.20397186279297 at step 144\n",
      "11 float32 float32 float32\n",
      "The loss is: 12.619169235229492 at step 145\n",
      "1 float32 float32 float32\n",
      "The loss is: 6.771874904632568 at step 146\n",
      "10 float32 float32 float32\n",
      "The loss is: 7.218189716339111 at step 147\n",
      "0 float32 float32 float32\n",
      "The loss is: 9.332843780517578 at step 148\n",
      "6 float32 float32 float32\n",
      "The loss is: 13.42903995513916 at step 149\n",
      "10 float32 float32 float32\n",
      "The loss is: 6.601864814758301 at step 150\n",
      "13 float32 float32 float32\n",
      "The loss is: 61.44236755371094 at step 151\n",
      "9 float32 float32 float32\n",
      "The loss is: 3.9680912494659424 at step 152\n",
      "10 float32 float32 float32\n",
      "The loss is: 7.3823699951171875 at step 153\n",
      "11 float32 float32 float32\n",
      "The loss is: 17.235776901245117 at step 154\n",
      "17 float32 float32 float32\n",
      "The loss is: 60.86167526245117 at step 155\n",
      "7 float32 float32 float32\n",
      "The loss is: 7.543702125549316 at step 156\n",
      "0 float32 float32 float32\n",
      "The loss is: 12.348262786865234 at step 157\n",
      "17 float32 float32 float32\n",
      "The loss is: 61.14031982421875 at step 158\n",
      "13 float32 float32 float32\n",
      "The loss is: 58.91788864135742 at step 159\n",
      "4 float32 float32 float32\n",
      "The loss is: 11.59565258026123 at step 160\n",
      "8 float32 float32 float32\n",
      "The loss is: 7.726511478424072 at step 161\n",
      "14 float32 float32 float32\n",
      "The loss is: 72.3985366821289 at step 162\n",
      "7 float32 float32 float32\n",
      "The loss is: 12.90048885345459 at step 163\n",
      "18 float32 float32 float32\n",
      "The loss is: 45.072017669677734 at step 164\n",
      "0 float32 float32 float32\n",
      "The loss is: 8.203409194946289 at step 165\n",
      "2 float32 float32 float32\n",
      "The loss is: 5.183699131011963 at step 166\n",
      "10 float32 float32 float32\n",
      "The loss is: 6.279763221740723 at step 167\n",
      "14 float32 float32 float32\n",
      "The loss is: 63.02010726928711 at step 168\n",
      "17 float32 float32 float32\n",
      "The loss is: 43.35478591918945 at step 169\n",
      "15 float32 float32 float32\n",
      "The loss is: 54.07991027832031 at step 170\n",
      "9 float32 float32 float32\n",
      "The loss is: 10.319432258605957 at step 171\n",
      "14 float32 float32 float32\n",
      "The loss is: 53.319969177246094 at step 172\n",
      "2 float32 float32 float32\n",
      "The loss is: 8.113043785095215 at step 173\n",
      "8 float32 float32 float32\n",
      "The loss is: 18.534934997558594 at step 174\n",
      "2 float32 float32 float32\n",
      "The loss is: 7.271186828613281 at step 175\n",
      "16 float32 float32 float32\n",
      "The loss is: 38.38313674926758 at step 176\n",
      "10 float32 float32 float32\n",
      "The loss is: 6.644776821136475 at step 177\n",
      "11 float32 float32 float32\n",
      "The loss is: 10.801493644714355 at step 178\n",
      "0 float32 float32 float32\n",
      "The loss is: 8.569005012512207 at step 179\n",
      "12 float32 float32 float32\n",
      "The loss is: 23.18880271911621 at step 180\n",
      "2 float32 float32 float32\n",
      "The loss is: 4.845697402954102 at step 181\n",
      "16 float32 float32 float32\n",
      "The loss is: 33.94623947143555 at step 182\n",
      "8 float32 float32 float32\n",
      "The loss is: 6.985305309295654 at step 183\n",
      "18 float32 float32 float32\n",
      "The loss is: 40.27406311035156 at step 184\n",
      "17 float32 float32 float32\n",
      "The loss is: 31.044822692871094 at step 185\n",
      "17 float32 float32 float32\n",
      "The loss is: 29.07839584350586 at step 186\n",
      "15 float32 float32 float32\n",
      "The loss is: 40.65159606933594 at step 187\n",
      "5 float32 float32 float32\n",
      "The loss is: 10.124460220336914 at step 188\n",
      "14 float32 float32 float32\n",
      "The loss is: 53.97633743286133 at step 189\n",
      "7 float32 float32 float32\n",
      "The loss is: 6.193946361541748 at step 190\n",
      "16 float32 float32 float32\n",
      "The loss is: 31.1973876953125 at step 191\n",
      "12 float32 float32 float32\n",
      "The loss is: 32.81764221191406 at step 192\n",
      "10 float32 float32 float32\n",
      "The loss is: 8.518741607666016 at step 193\n",
      "17 float32 float32 float32\n",
      "The loss is: 23.50372886657715 at step 194\n",
      "5 float32 float32 float32\n",
      "The loss is: 8.573894500732422 at step 195\n",
      "5 float32 float32 float32\n",
      "The loss is: 8.362525939941406 at step 196\n",
      "5 float32 float32 float32\n",
      "The loss is: 7.826163291931152 at step 197\n",
      "18 float32 float32 float32\n",
      "The loss is: 24.877262115478516 at step 198\n",
      "3 float32 float32 float32\n",
      "The loss is: 3.708137035369873 at step 199\n",
      "18 float32 float32 float32\n",
      "The loss is: 21.58427619934082 at step 200\n",
      "6 float32 float32 float32\n",
      "The loss is: 4.39361047744751 at step 201\n",
      "12 float32 float32 float32\n",
      "The loss is: 34.241546630859375 at step 202\n",
      "10 float32 float32 float32\n",
      "The loss is: 10.958612442016602 at step 203\n",
      "12 float32 float32 float32\n",
      "The loss is: 34.117557525634766 at step 204\n",
      "5 float32 float32 float32\n",
      "The loss is: 3.626642942428589 at step 205\n",
      "13 float32 float32 float32\n",
      "The loss is: 45.93539810180664 at step 206\n",
      "5 float32 float32 float32\n",
      "The loss is: 3.784158945083618 at step 207\n",
      "8 float32 float32 float32\n",
      "The loss is: 2.5317654609680176 at step 208\n",
      "15 float32 float32 float32\n",
      "The loss is: 35.70138931274414 at step 209\n",
      "6 float32 float32 float32\n",
      "The loss is: 4.680868148803711 at step 210\n",
      "3 float32 float32 float32\n",
      "The loss is: 3.407606840133667 at step 211\n",
      "3 float32 float32 float32\n",
      "The loss is: 3.6426146030426025 at step 212\n",
      "7 float32 float32 float32\n",
      "The loss is: 5.304556846618652 at step 213\n",
      "6 float32 float32 float32\n",
      "The loss is: 5.8658061027526855 at step 214\n",
      "4 float32 float32 float32\n",
      "The loss is: 4.234474182128906 at step 215\n",
      "9 float32 float32 float32\n",
      "The loss is: 3.6630451679229736 at step 216\n",
      "9 float32 float32 float32\n",
      "The loss is: 3.607940196990967 at step 217\n",
      "15 float32 float32 float32\n",
      "The loss is: 32.69823455810547 at step 218\n",
      "17 float32 float32 float32\n",
      "The loss is: 20.047340393066406 at step 219\n",
      "7 float32 float32 float32\n",
      "The loss is: 2.1431326866149902 at step 220\n",
      "14 float32 float32 float32\n",
      "The loss is: 40.78652572631836 at step 221\n",
      "0 float32 float32 float32\n",
      "The loss is: 15.116546630859375 at step 222\n",
      "13 float32 float32 float32\n",
      "The loss is: 34.82719421386719 at step 223\n",
      "1 float32 float32 float32\n",
      "The loss is: 9.638740539550781 at step 224\n",
      "18 float32 float32 float32\n",
      "The loss is: 27.956912994384766 at step 225\n",
      "15 float32 float32 float32\n",
      "The loss is: 27.654096603393555 at step 226\n",
      "1 float32 float32 float32\n",
      "The loss is: 7.42992639541626 at step 227\n",
      "16 float32 float32 float32\n",
      "The loss is: 23.501068115234375 at step 228\n",
      "10 float32 float32 float32\n",
      "The loss is: 6.0380706787109375 at step 229\n",
      "3 float32 float32 float32\n",
      "The loss is: 4.301766395568848 at step 230\n",
      "6 float32 float32 float32\n",
      "The loss is: 6.728865623474121 at step 231\n",
      "14 float32 float32 float32\n",
      "The loss is: 30.75895881652832 at step 232\n",
      "11 float32 float32 float32\n",
      "The loss is: 9.947004318237305 at step 233\n",
      "12 float32 float32 float32\n",
      "The loss is: 17.1431827545166 at step 234\n",
      "4 float32 float32 float32\n",
      "The loss is: 4.52047872543335 at step 235\n",
      "13 float32 float32 float32\n",
      "The loss is: 24.830322265625 at step 236\n",
      "3 float32 float32 float32\n",
      "The loss is: 3.4744136333465576 at step 237\n",
      "9 float32 float32 float32\n",
      "The loss is: 3.859938621520996 at step 238\n",
      "11 float32 float32 float32\n",
      "The loss is: 9.127872467041016 at step 239\n",
      "16 float32 float32 float32\n",
      "The loss is: 21.667036056518555 at step 240\n",
      "17 float32 float32 float32\n",
      "The loss is: 22.128347396850586 at step 241\n",
      "9 float32 float32 float32\n",
      "The loss is: 3.135867118835449 at step 242\n",
      "11 float32 float32 float32\n",
      "The loss is: 9.829599380493164 at step 243\n",
      "6 float32 float32 float32\n",
      "The loss is: 3.9334394931793213 at step 244\n",
      "4 float32 float32 float32\n",
      "The loss is: 3.3611741065979004 at step 245\n",
      "5 float32 float32 float32\n",
      "The loss is: 3.7788264751434326 at step 246\n",
      "11 float32 float32 float32\n",
      "The loss is: 11.812116622924805 at step 247\n",
      "8 float32 float32 float32\n",
      "The loss is: 2.39730167388916 at step 248\n",
      "16 float32 float32 float32\n",
      "The loss is: 18.917198181152344 at step 249\n",
      "11 float32 float32 float32\n",
      "The loss is: 11.921846389770508 at step 250\n",
      "10 float32 float32 float32\n",
      "The loss is: 6.351446151733398 at step 251\n",
      "6 float32 float32 float32\n",
      "The loss is: 3.4653592109680176 at step 252\n",
      "14 float32 float32 float32\n",
      "The loss is: 27.65390396118164 at step 253\n",
      "10 float32 float32 float32\n",
      "The loss is: 4.983339309692383 at step 254\n",
      "18 float32 float32 float32\n",
      "The loss is: 21.25011444091797 at step 255\n",
      "2 float32 float32 float32\n",
      "The loss is: 4.76225471496582 at step 256\n",
      "9 float32 float32 float32\n",
      "The loss is: 3.03730845451355 at step 257\n",
      "1 float32 float32 float32\n",
      "The loss is: 6.050246715545654 at step 258\n",
      "5 float32 float32 float32\n",
      "The loss is: 5.510034561157227 at step 259\n",
      "9 float32 float32 float32\n",
      "The loss is: 3.254234552383423 at step 260\n",
      "3 float32 float32 float32\n",
      "The loss is: 3.172308921813965 at step 261\n",
      "1 float32 float32 float32\n",
      "The loss is: 5.816248416900635 at step 262\n",
      "1 float32 float32 float32\n",
      "The loss is: 5.739903450012207 at step 263\n",
      "15 float32 float32 float32\n",
      "The loss is: 22.21979522705078 at step 264\n",
      "12 float32 float32 float32\n",
      "The loss is: 12.215215682983398 at step 265\n",
      "15 float32 float32 float32\n",
      "The loss is: 21.859275817871094 at step 266\n",
      "10 float32 float32 float32\n",
      "The loss is: 4.770933628082275 at step 267\n",
      "17 float32 float32 float32\n",
      "The loss is: 18.87730598449707 at step 268\n",
      "0 float32 float32 float32\n",
      "The loss is: 5.422881126403809 at step 269\n",
      "1 float32 float32 float32\n",
      "The loss is: 4.490129470825195 at step 270\n",
      "14 float32 float32 float32\n",
      "The loss is: 22.57030487060547 at step 271\n",
      "9 float32 float32 float32\n",
      "The loss is: 4.865589141845703 at step 272\n",
      "17 float32 float32 float32\n",
      "The loss is: 18.066360473632812 at step 273\n",
      "6 float32 float32 float32\n",
      "The loss is: 7.775089740753174 at step 274\n",
      "2 float32 float32 float32\n",
      "The loss is: 3.7599902153015137 at step 275\n",
      "18 float32 float32 float32\n",
      "The loss is: 14.212515830993652 at step 276\n",
      "12 float32 float32 float32\n",
      "The loss is: 12.674421310424805 at step 277\n",
      "14 float32 float32 float32\n",
      "The loss is: 25.40743637084961 at step 278\n",
      "18 float32 float32 float32\n",
      "The loss is: 11.20439338684082 at step 279\n",
      "5 float32 float32 float32\n",
      "The loss is: 4.421196937561035 at step 280\n",
      "18 float32 float32 float32\n",
      "The loss is: 10.279373168945312 at step 281\n",
      "17 float32 float32 float32\n",
      "The loss is: 13.191060066223145 at step 282\n",
      "1 float32 float32 float32\n",
      "The loss is: 9.436629295349121 at step 283\n",
      "11 float32 float32 float32\n",
      "The loss is: 10.13794994354248 at step 284\n",
      "17 float32 float32 float32\n",
      "The loss is: 12.563637733459473 at step 285\n",
      "4 float32 float32 float32\n",
      "The loss is: 3.470791816711426 at step 286\n",
      "13 float32 float32 float32\n",
      "The loss is: 20.642822265625 at step 287\n",
      "2 float32 float32 float32\n",
      "The loss is: 5.215220928192139 at step 288\n",
      "14 float32 float32 float32\n",
      "The loss is: 22.173397064208984 at step 289\n",
      "5 float32 float32 float32\n",
      "The loss is: 5.739719390869141 at step 290\n",
      "11 float32 float32 float32\n",
      "The loss is: 5.502809524536133 at step 291\n",
      "1 float32 float32 float32\n",
      "The loss is: 3.7382240295410156 at step 292\n",
      "3 float32 float32 float32\n",
      "The loss is: 4.57736349105835 at step 293\n",
      "0 float32 float32 float32\n",
      "The loss is: 3.7529542446136475 at step 294\n",
      "15 float32 float32 float32\n",
      "The loss is: 18.501115798950195 at step 295\n",
      "18 float32 float32 float32\n",
      "The loss is: 23.091459274291992 at step 296\n",
      "4 float32 float32 float32\n",
      "The loss is: 7.210591793060303 at step 297\n",
      "17 float32 float32 float32\n",
      "The loss is: 14.165352821350098 at step 298\n",
      "4 float32 float32 float32\n",
      "The loss is: 4.166385650634766 at step 299\n",
      "2 float32 float32 float32\n",
      "The loss is: 4.7769694328308105 at step 300\n",
      "12 float32 float32 float32\n",
      "The loss is: 12.554526329040527 at step 301\n",
      "6 float32 float32 float32\n",
      "The loss is: 3.220789909362793 at step 302\n",
      "8 float32 float32 float32\n",
      "The loss is: 2.2731924057006836 at step 303\n",
      "5 float32 float32 float32\n",
      "The loss is: 3.0482161045074463 at step 304\n",
      "5 float32 float32 float32\n",
      "The loss is: 2.8909268379211426 at step 305\n",
      "2 float32 float32 float32\n",
      "The loss is: 8.239594459533691 at step 306\n",
      "16 float32 float32 float32\n",
      "The loss is: 18.77703857421875 at step 307\n",
      "15 float32 float32 float32\n",
      "The loss is: 24.166481018066406 at step 308\n",
      "4 float32 float32 float32\n",
      "The loss is: 2.4508798122406006 at step 309\n",
      "12 float32 float32 float32\n",
      "The loss is: 14.359020233154297 at step 310\n",
      "14 float32 float32 float32\n",
      "The loss is: 22.99657440185547 at step 311\n",
      "13 float32 float32 float32\n",
      "The loss is: 16.295936584472656 at step 312\n",
      "18 float32 float32 float32\n",
      "The loss is: 9.072763442993164 at step 313\n",
      "15 float32 float32 float32\n",
      "The loss is: 16.411867141723633 at step 314\n",
      "8 float32 float32 float32\n",
      "The loss is: 4.992920875549316 at step 315\n",
      "10 float32 float32 float32\n",
      "The loss is: 5.063261032104492 at step 316\n",
      "15 float32 float32 float32\n",
      "The loss is: 16.292945861816406 at step 317\n",
      "14 float32 float32 float32\n",
      "The loss is: 16.356590270996094 at step 318\n",
      "12 float32 float32 float32\n",
      "The loss is: 8.230677604675293 at step 319\n",
      "7 float32 float32 float32\n",
      "The loss is: 5.57538366317749 at step 320\n",
      "15 float32 float32 float32\n",
      "The loss is: 14.961467742919922 at step 321\n",
      "1 float32 float32 float32\n",
      "The loss is: 3.968794822692871 at step 322\n",
      "9 float32 float32 float32\n",
      "The loss is: 2.3983023166656494 at step 323\n",
      "14 float32 float32 float32\n",
      "The loss is: 15.110179901123047 at step 324\n",
      "4 float32 float32 float32\n",
      "The loss is: 2.8755083084106445 at step 325\n",
      "11 float32 float32 float32\n",
      "The loss is: 4.812850475311279 at step 326\n",
      "13 float32 float32 float32\n",
      "The loss is: 11.576205253601074 at step 327\n",
      "9 float32 float32 float32\n",
      "The loss is: 2.1508398056030273 at step 328\n",
      "10 float32 float32 float32\n",
      "The loss is: 2.860769748687744 at step 329\n",
      "14 float32 float32 float32\n",
      "The loss is: 13.85582447052002 at step 330\n",
      "15 float32 float32 float32\n",
      "The loss is: 12.83826732635498 at step 331\n",
      "7 float32 float32 float32\n",
      "The loss is: 3.356362819671631 at step 332\n",
      "10 float32 float32 float32\n",
      "The loss is: 2.6884422302246094 at step 333\n",
      "4 float32 float32 float32\n",
      "The loss is: 3.2651071548461914 at step 334\n",
      "16 float32 float32 float32\n",
      "The loss is: 11.822588920593262 at step 335\n",
      "4 float32 float32 float32\n",
      "The loss is: 2.9075469970703125 at step 336\n",
      "13 float32 float32 float32\n",
      "The loss is: 10.537884712219238 at step 337\n",
      "8 float32 float32 float32\n",
      "The loss is: 2.018983840942383 at step 338\n",
      "0 float32 float32 float32\n",
      "The loss is: 7.78898811340332 at step 339\n",
      "15 float32 float32 float32\n",
      "The loss is: 11.233281135559082 at step 340\n",
      "6 float32 float32 float32\n",
      "The loss is: 2.8853185176849365 at step 341\n",
      "8 float32 float32 float32\n",
      "The loss is: 1.9695682525634766 at step 342\n",
      "18 float32 float32 float32\n",
      "The loss is: 13.710651397705078 at step 343\n",
      "11 float32 float32 float32\n",
      "The loss is: 4.972596168518066 at step 344\n",
      "3 float32 float32 float32\n",
      "The loss is: 2.916374444961548 at step 345\n",
      "10 float32 float32 float32\n",
      "The loss is: 3.89994215965271 at step 346\n",
      "0 float32 float32 float32\n",
      "The loss is: 8.600903511047363 at step 347\n",
      "8 float32 float32 float32\n",
      "The loss is: 1.8606637716293335 at step 348\n",
      "9 float32 float32 float32\n",
      "The loss is: 2.048889636993408 at step 349\n",
      "3 float32 float32 float32\n",
      "The loss is: 2.4230222702026367 at step 350\n",
      "12 float32 float32 float32\n",
      "The loss is: 6.1872406005859375 at step 351\n",
      "3 float32 float32 float32\n",
      "The loss is: 2.298596143722534 at step 352\n",
      "15 float32 float32 float32\n",
      "The loss is: 12.178438186645508 at step 353\n",
      "14 float32 float32 float32\n",
      "The loss is: 12.592121124267578 at step 354\n",
      "12 float32 float32 float32\n",
      "The loss is: 6.087557315826416 at step 355\n",
      "17 float32 float32 float32\n",
      "The loss is: 11.446161270141602 at step 356\n",
      "7 float32 float32 float32\n",
      "The loss is: 4.139087200164795 at step 357\n",
      "3 float32 float32 float32\n",
      "The loss is: 2.302945613861084 at step 358\n",
      "16 float32 float32 float32\n",
      "The loss is: 9.55101203918457 at step 359\n",
      "3 float32 float32 float32\n",
      "The loss is: 2.352999687194824 at step 360\n",
      "9 float32 float32 float32\n",
      "The loss is: 2.007841110229492 at step 361\n",
      "1 float32 float32 float32\n",
      "The loss is: 6.671845436096191 at step 362\n",
      "8 float32 float32 float32\n",
      "The loss is: 1.7914447784423828 at step 363\n",
      "16 float32 float32 float32\n",
      "The loss is: 9.433255195617676 at step 364\n",
      "1 float32 float32 float32\n",
      "The loss is: 6.402213096618652 at step 365\n",
      "16 float32 float32 float32\n",
      "The loss is: 9.17013168334961 at step 366\n",
      "13 float32 float32 float32\n",
      "The loss is: 10.057063102722168 at step 367\n",
      "1 float32 float32 float32\n",
      "The loss is: 3.9381823539733887 at step 368\n",
      "5 float32 float32 float32\n",
      "The loss is: 4.17363166809082 at step 369\n",
      "1 float32 float32 float32\n",
      "The loss is: 2.638535976409912 at step 370\n",
      "7 float32 float32 float32\n",
      "The loss is: 5.5377702713012695 at step 371\n",
      "10 float32 float32 float32\n",
      "The loss is: 3.7181332111358643 at step 372\n",
      "10 float32 float32 float32\n",
      "The loss is: 3.4597976207733154 at step 373\n",
      "14 float32 float32 float32\n",
      "The loss is: 11.419269561767578 at step 374\n",
      "12 float32 float32 float32\n",
      "The loss is: 5.338587760925293 at step 375\n",
      "9 float32 float32 float32\n",
      "The loss is: 2.194517135620117 at step 376\n",
      "17 float32 float32 float32\n",
      "The loss is: 7.380302429199219 at step 377\n",
      "18 float32 float32 float32\n",
      "The loss is: 6.019216060638428 at step 378\n",
      "3 float32 float32 float32\n",
      "The loss is: 2.512601375579834 at step 379\n",
      "4 float32 float32 float32\n",
      "The loss is: 2.2222139835357666 at step 380\n",
      "11 float32 float32 float32\n",
      "The loss is: 6.978629112243652 at step 381\n",
      "0 float32 float32 float32\n",
      "The loss is: 10.837894439697266 at step 382\n",
      "4 float32 float32 float32\n",
      "The loss is: 2.2339844703674316 at step 383\n",
      "15 float32 float32 float32\n",
      "The loss is: 12.625675201416016 at step 384\n",
      "16 float32 float32 float32\n",
      "The loss is: 8.314534187316895 at step 385\n",
      "2 float32 float32 float32\n",
      "The loss is: 5.558469772338867 at step 386\n",
      "13 float32 float32 float32\n",
      "The loss is: 9.815990447998047 at step 387\n",
      "12 float32 float32 float32\n",
      "The loss is: 5.615996837615967 at step 388\n",
      "18 float32 float32 float32\n",
      "The loss is: 7.616286277770996 at step 389\n",
      "3 float32 float32 float32\n",
      "The loss is: 2.40570330619812 at step 390\n",
      "0 float32 float32 float32\n",
      "The loss is: 2.500361442565918 at step 391\n",
      "3 float32 float32 float32\n",
      "The loss is: 2.9266343116760254 at step 392\n",
      "6 float32 float32 float32\n",
      "The loss is: 6.083522319793701 at step 393\n",
      "8 float32 float32 float32\n",
      "The loss is: 4.290163040161133 at step 394\n",
      "0 float32 float32 float32\n",
      "The loss is: 2.48547625541687 at step 395\n",
      "9 float32 float32 float32\n",
      "The loss is: 2.4725847244262695 at step 396\n",
      "11 float32 float32 float32\n",
      "The loss is: 3.1465365886688232 at step 397\n",
      "3 float32 float32 float32\n",
      "The loss is: 2.0948076248168945 at step 398\n",
      "12 float32 float32 float32\n",
      "The loss is: 5.2014360427856445 at step 399\n",
      "14 float32 float32 float32\n",
      "The loss is: 10.451081275939941 at step 400\n",
      "3 float32 float32 float32\n",
      "The loss is: 2.14681339263916 at step 401\n",
      "18 float32 float32 float32\n",
      "The loss is: 5.174687385559082 at step 402\n",
      "14 float32 float32 float32\n",
      "The loss is: 10.466675758361816 at step 403\n",
      "16 float32 float32 float32\n",
      "The loss is: 6.792607307434082 at step 404\n",
      "17 float32 float32 float32\n",
      "The loss is: 4.90617036819458 at step 405\n",
      "4 float32 float32 float32\n",
      "The loss is: 2.035176992416382 at step 406\n",
      "2 float32 float32 float32\n",
      "The loss is: 5.031561374664307 at step 407\n",
      "2 float32 float32 float32\n",
      "The loss is: 4.959123134613037 at step 408\n",
      "17 float32 float32 float32\n",
      "The loss is: 4.596408367156982 at step 409\n",
      "4 float32 float32 float32\n",
      "The loss is: 2.0748724937438965 at step 410\n",
      "11 float32 float32 float32\n",
      "The loss is: 3.5061981678009033 at step 411\n",
      "13 float32 float32 float32\n",
      "The loss is: 7.639527320861816 at step 412\n",
      "3 float32 float32 float32\n",
      "The loss is: 2.0532889366149902 at step 413\n",
      "17 float32 float32 float32\n",
      "The loss is: 5.948940277099609 at step 414\n",
      "18 float32 float32 float32\n",
      "The loss is: 6.20440149307251 at step 415\n",
      "7 float32 float32 float32\n",
      "The loss is: 2.44791316986084 at step 416\n",
      "7 float32 float32 float32\n",
      "The loss is: 2.177995443344116 at step 417\n",
      "13 float32 float32 float32\n",
      "The loss is: 7.956717491149902 at step 418\n",
      "4 float32 float32 float32\n",
      "The loss is: 2.0309932231903076 at step 419\n",
      "1 float32 float32 float32\n",
      "The loss is: 5.480377674102783 at step 420\n",
      "3 float32 float32 float32\n",
      "The loss is: 2.2500154972076416 at step 421\n",
      "18 float32 float32 float32\n",
      "The loss is: 3.089709997177124 at step 422\n",
      "9 float32 float32 float32\n",
      "The loss is: 1.5962002277374268 at step 423\n",
      "5 float32 float32 float32\n",
      "The loss is: 2.277475118637085 at step 424\n",
      "2 float32 float32 float32\n",
      "The loss is: 3.800360679626465 at step 425\n",
      "4 float32 float32 float32\n",
      "The loss is: 1.982566237449646 at step 426\n",
      "6 float32 float32 float32\n",
      "The loss is: 2.343714475631714 at step 427\n",
      "18 float32 float32 float32\n",
      "The loss is: 3.2493276596069336 at step 428\n",
      "6 float32 float32 float32\n",
      "The loss is: 2.21022629737854 at step 429\n",
      "17 float32 float32 float32\n",
      "The loss is: 4.542996406555176 at step 430\n",
      "13 float32 float32 float32\n",
      "The loss is: 8.164729118347168 at step 431\n",
      "4 float32 float32 float32\n",
      "The loss is: 1.7618627548217773 at step 432\n",
      "18 float32 float32 float32\n",
      "The loss is: 2.774383544921875 at step 433\n",
      "8 float32 float32 float32\n",
      "The loss is: 1.3518000841140747 at step 434\n",
      "12 float32 float32 float32\n",
      "The loss is: 5.41373872756958 at step 435\n",
      "14 float32 float32 float32\n",
      "The loss is: 10.265580177307129 at step 436\n",
      "2 float32 float32 float32\n",
      "The loss is: 3.4146084785461426 at step 437\n",
      "6 float32 float32 float32\n",
      "The loss is: 2.190995454788208 at step 438\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.8345781564712524 at step 439\n",
      "2 float32 float32 float32\n",
      "The loss is: 2.3699941635131836 at step 440\n",
      "15 float32 float32 float32\n",
      "The loss is: 8.51330852508545 at step 441\n",
      "17 float32 float32 float32\n",
      "The loss is: 6.10808801651001 at step 442\n",
      "16 float32 float32 float32\n",
      "The loss is: 7.024348735809326 at step 443\n",
      "16 float32 float32 float32\n",
      "The loss is: 6.678447246551514 at step 444\n",
      "12 float32 float32 float32\n",
      "The loss is: 4.2291364669799805 at step 445\n",
      "5 float32 float32 float32\n",
      "The loss is: 2.248028516769409 at step 446\n",
      "11 float32 float32 float32\n",
      "The loss is: 2.771857976913452 at step 447\n",
      "13 float32 float32 float32\n",
      "The loss is: 7.001775741577148 at step 448\n",
      "6 float32 float32 float32\n",
      "The loss is: 1.7441298961639404 at step 449\n",
      "7 float32 float32 float32\n",
      "The loss is: 1.445042610168457 at step 450\n",
      "4 float32 float32 float32\n",
      "The loss is: 1.6236343383789062 at step 451\n",
      "13 float32 float32 float32\n",
      "The loss is: 7.466825485229492 at step 452\n",
      "7 float32 float32 float32\n",
      "The loss is: 1.3571490049362183 at step 453\n",
      "10 float32 float32 float32\n",
      "The loss is: 2.113401412963867 at step 454\n",
      "4 float32 float32 float32\n",
      "The loss is: 1.5967075824737549 at step 455\n",
      "10 float32 float32 float32\n",
      "The loss is: 1.8882098197937012 at step 456\n",
      "8 float32 float32 float32\n",
      "The loss is: 1.288036823272705 at step 457\n",
      "15 float32 float32 float32\n",
      "The loss is: 7.103017807006836 at step 458\n",
      "16 float32 float32 float32\n",
      "The loss is: 5.172943592071533 at step 459\n",
      "17 float32 float32 float32\n",
      "The loss is: 4.12695837020874 at step 460\n",
      "8 float32 float32 float32\n",
      "The loss is: 1.3465101718902588 at step 461\n",
      "10 float32 float32 float32\n",
      "The loss is: 1.732914924621582 at step 462\n",
      "7 float32 float32 float32\n",
      "The loss is: 1.404996395111084 at step 463\n",
      "13 float32 float32 float32\n",
      "The loss is: 6.255682468414307 at step 464\n",
      "6 float32 float32 float32\n",
      "The loss is: 1.5316612720489502 at step 465\n",
      "3 float32 float32 float32\n",
      "The loss is: 2.136334180831909 at step 466\n",
      "8 float32 float32 float32\n",
      "The loss is: 1.1948317289352417 at step 467\n",
      "12 float32 float32 float32\n",
      "The loss is: 4.051482677459717 at step 468\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.9650357961654663 at step 469\n",
      "2 float32 float32 float32\n",
      "The loss is: 3.0522451400756836 at step 470\n",
      "9 float32 float32 float32\n",
      "The loss is: 1.436992883682251 at step 471\n",
      "12 float32 float32 float32\n",
      "The loss is: 3.6541454792022705 at step 472\n",
      "11 float32 float32 float32\n",
      "The loss is: 2.585608720779419 at step 473\n",
      "16 float32 float32 float32\n",
      "The loss is: 6.250113010406494 at step 474\n",
      "11 float32 float32 float32\n",
      "The loss is: 2.447526216506958 at step 475\n",
      "13 float32 float32 float32\n",
      "The loss is: 5.336733818054199 at step 476\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.668077826499939 at step 477\n",
      "13 float32 float32 float32\n",
      "The loss is: 5.330068588256836 at step 478\n",
      "0 float32 float32 float32\n",
      "The loss is: 3.166041612625122 at step 479\n",
      "0 float32 float32 float32\n",
      "The loss is: 2.8616814613342285 at step 480\n",
      "16 float32 float32 float32\n",
      "The loss is: 5.084107398986816 at step 481\n",
      "13 float32 float32 float32\n",
      "The loss is: 5.078052997589111 at step 482\n",
      "8 float32 float32 float32\n",
      "The loss is: 2.165788412094116 at step 483\n",
      "7 float32 float32 float32\n",
      "The loss is: 2.576768159866333 at step 484\n",
      "7 float32 float32 float32\n",
      "The loss is: 2.2539522647857666 at step 485\n",
      "0 float32 float32 float32\n",
      "The loss is: 2.8682258129119873 at step 486\n",
      "7 float32 float32 float32\n",
      "The loss is: 1.7710870504379272 at step 487\n",
      "17 float32 float32 float32\n",
      "The loss is: 3.443460702896118 at step 488\n",
      "9 float32 float32 float32\n",
      "The loss is: 1.2805659770965576 at step 489\n",
      "0 float32 float32 float32\n",
      "The loss is: 4.75161075592041 at step 490\n",
      "13 float32 float32 float32\n",
      "The loss is: 5.713420391082764 at step 491\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.938234806060791 at step 492\n",
      "18 float32 float32 float32\n",
      "The loss is: 3.692350149154663 at step 493\n",
      "5 float32 float32 float32\n",
      "The loss is: 1.6960759162902832 at step 494\n",
      "5 float32 float32 float32\n",
      "The loss is: 1.6353594064712524 at step 495\n",
      "4 float32 float32 float32\n",
      "The loss is: 1.4546042680740356 at step 496\n",
      "17 float32 float32 float32\n",
      "The loss is: 2.5894393920898438 at step 497\n",
      "0 float32 float32 float32\n",
      "The loss is: 4.4239606857299805 at step 498\n",
      "16 float32 float32 float32\n",
      "The loss is: 4.0818891525268555 at step 499\n",
      "5 float32 float32 float32\n",
      "The loss is: 1.4365204572677612 at step 500\n",
      "15 float32 float32 float32\n",
      "The loss is: 6.199599266052246 at step 501\n",
      "10 float32 float32 float32\n",
      "The loss is: 1.5254099369049072 at step 502\n",
      "13 float32 float32 float32\n",
      "The loss is: 5.183080196380615 at step 503\n",
      "16 float32 float32 float32\n",
      "The loss is: 4.330318450927734 at step 504\n",
      "5 float32 float32 float32\n",
      "The loss is: 1.8045915365219116 at step 505\n",
      "10 float32 float32 float32\n",
      "The loss is: 1.5173616409301758 at step 506\n",
      "6 float32 float32 float32\n",
      "The loss is: 1.8217754364013672 at step 507\n",
      "17 float32 float32 float32\n",
      "The loss is: 3.3453691005706787 at step 508\n",
      "16 float32 float32 float32\n",
      "The loss is: 3.9371516704559326 at step 509\n",
      "0 float32 float32 float32\n",
      "The loss is: 3.7558984756469727 at step 510\n",
      "1 float32 float32 float32\n",
      "The loss is: 4.059228897094727 at step 511\n",
      "7 float32 float32 float32\n",
      "The loss is: 1.1539181470870972 at step 512\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.7365680932998657 at step 513\n",
      "15 float32 float32 float32\n",
      "The loss is: 5.512623310089111 at step 514\n",
      "11 float32 float32 float32\n",
      "The loss is: 2.0369601249694824 at step 515\n",
      "17 float32 float32 float32\n",
      "The loss is: 3.799940824508667 at step 516\n",
      "10 float32 float32 float32\n",
      "The loss is: 1.4577194452285767 at step 517\n",
      "1 float32 float32 float32\n",
      "The loss is: 2.613107919692993 at step 518\n",
      "16 float32 float32 float32\n",
      "The loss is: 3.98041033744812 at step 519\n",
      "17 float32 float32 float32\n",
      "The loss is: 3.0747506618499756 at step 520\n",
      "5 float32 float32 float32\n",
      "The loss is: 1.453550934791565 at step 521\n",
      "1 float32 float32 float32\n",
      "The loss is: 3.642249584197998 at step 522\n",
      "14 float32 float32 float32\n",
      "The loss is: 6.181562423706055 at step 523\n",
      "9 float32 float32 float32\n",
      "The loss is: 1.0787487030029297 at step 524\n",
      "4 float32 float32 float32\n",
      "The loss is: 1.3347197771072388 at step 525\n",
      "6 float32 float32 float32\n",
      "The loss is: 1.527823805809021 at step 526\n",
      "7 float32 float32 float32\n",
      "The loss is: 1.339416742324829 at step 527\n",
      "15 float32 float32 float32\n",
      "The loss is: 5.188901424407959 at step 528\n",
      "1 float32 float32 float32\n",
      "The loss is: 3.070856809616089 at step 529\n",
      "13 float32 float32 float32\n",
      "The loss is: 4.392819881439209 at step 530\n",
      "13 float32 float32 float32\n",
      "The loss is: 4.282172679901123 at step 531\n",
      "12 float32 float32 float32\n",
      "The loss is: 2.827974319458008 at step 532\n",
      "6 float32 float32 float32\n",
      "The loss is: 2.395707368850708 at step 533\n",
      "14 float32 float32 float32\n",
      "The loss is: 5.514186859130859 at step 534\n",
      "17 float32 float32 float32\n",
      "The loss is: 4.049660682678223 at step 535\n",
      "11 float32 float32 float32\n",
      "The loss is: 1.7812342643737793 at step 536\n",
      "18 float32 float32 float32\n",
      "The loss is: 3.2196273803710938 at step 537\n",
      "5 float32 float32 float32\n",
      "The loss is: 1.2671968936920166 at step 538\n",
      "15 float32 float32 float32\n",
      "The loss is: 5.42130184173584 at step 539\n",
      "6 float32 float32 float32\n",
      "The loss is: 1.163703203201294 at step 540\n",
      "8 float32 float32 float32\n",
      "The loss is: 1.5161670446395874 at step 541\n",
      "12 float32 float32 float32\n",
      "The loss is: 5.902925491333008 at step 542\n",
      "17 float32 float32 float32\n",
      "The loss is: 1.6046572923660278 at step 543\n",
      "4 float32 float32 float32\n",
      "The loss is: 1.6140142679214478 at step 544\n",
      "7 float32 float32 float32\n",
      "The loss is: 1.1092263460159302 at step 545\n",
      "8 float32 float32 float32\n",
      "The loss is: 1.165550947189331 at step 546\n",
      "3 float32 float32 float32\n",
      "The loss is: 2.3309309482574463 at step 547\n",
      "13 float32 float32 float32\n",
      "The loss is: 4.531425952911377 at step 548\n",
      "0 float32 float32 float32\n",
      "The loss is: 2.8789398670196533 at step 549\n",
      "7 float32 float32 float32\n",
      "The loss is: 1.7673591375350952 at step 550\n",
      "8 float32 float32 float32\n",
      "The loss is: 2.1260976791381836 at step 551\n",
      "18 float32 float32 float32\n",
      "The loss is: 6.054594039916992 at step 552\n",
      "11 float32 float32 float32\n",
      "The loss is: 2.0223283767700195 at step 553\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.3577873706817627 at step 554\n",
      "14 float32 float32 float32\n",
      "The loss is: 4.970052719116211 at step 555\n",
      "8 float32 float32 float32\n",
      "The loss is: 1.092231035232544 at step 556\n",
      "15 float32 float32 float32\n",
      "The loss is: 4.785194396972656 at step 557\n",
      "2 float32 float32 float32\n",
      "The loss is: 3.224241256713867 at step 558\n",
      "12 float32 float32 float32\n",
      "The loss is: 2.8692362308502197 at step 559\n",
      "0 float32 float32 float32\n",
      "The loss is: 2.831575393676758 at step 560\n",
      "14 float32 float32 float32\n",
      "The loss is: 4.913259983062744 at step 561\n",
      "15 float32 float32 float32\n",
      "The loss is: 4.730924606323242 at step 562\n",
      "9 float32 float32 float32\n",
      "The loss is: 1.789101481437683 at step 563\n",
      "17 float32 float32 float32\n",
      "The loss is: 3.761476755142212 at step 564\n",
      "1 float32 float32 float32\n",
      "The loss is: 1.527915120124817 at step 565\n",
      "16 float32 float32 float32\n",
      "The loss is: 3.8251047134399414 at step 566\n",
      "8 float32 float32 float32\n",
      "The loss is: 1.6396825313568115 at step 567\n",
      "9 float32 float32 float32\n",
      "The loss is: 1.117352843284607 at step 568\n",
      "14 float32 float32 float32\n",
      "The loss is: 4.719323635101318 at step 569\n",
      "0 float32 float32 float32\n",
      "The loss is: 2.9783148765563965 at step 570\n",
      "6 float32 float32 float32\n",
      "The loss is: 1.3939437866210938 at step 571\n",
      "5 float32 float32 float32\n",
      "The loss is: 1.375257968902588 at step 572\n",
      "1 float32 float32 float32\n",
      "The loss is: 3.2432878017425537 at step 573\n",
      "5 float32 float32 float32\n",
      "The loss is: 1.407646656036377 at step 574\n",
      "10 float32 float32 float32\n",
      "The loss is: 1.1201176643371582 at step 575\n",
      "2 float32 float32 float32\n",
      "The loss is: 2.158287525177002 at step 576\n",
      "16 float32 float32 float32\n",
      "The loss is: 3.298743963241577 at step 577\n",
      "14 float32 float32 float32\n",
      "The loss is: 4.423240661621094 at step 578\n",
      "14 float32 float32 float32\n",
      "The loss is: 4.4454851150512695 at step 579\n",
      "12 float32 float32 float32\n",
      "The loss is: 2.3233537673950195 at step 580\n",
      "14 float32 float32 float32\n",
      "The loss is: 4.373817443847656 at step 581\n",
      "16 float32 float32 float32\n",
      "The loss is: 3.3997201919555664 at step 582\n",
      "1 float32 float32 float32\n",
      "The loss is: 1.903330683708191 at step 583\n",
      "16 float32 float32 float32\n",
      "The loss is: 3.0613298416137695 at step 584\n",
      "1 float32 float32 float32\n",
      "The loss is: 2.1432769298553467 at step 585\n",
      "0 float32 float32 float32\n",
      "The loss is: 1.7554802894592285 at step 586\n",
      "7 float32 float32 float32\n",
      "The loss is: 1.881401538848877 at step 587\n",
      "5 float32 float32 float32\n",
      "The loss is: 2.048754930496216 at step 588\n",
      "5 float32 float32 float32\n",
      "The loss is: 1.9569265842437744 at step 589\n",
      "11 float32 float32 float32\n",
      "The loss is: 1.4006985425949097 at step 590\n",
      "15 float32 float32 float32\n",
      "The loss is: 3.6985902786254883 at step 591\n",
      "4 float32 float32 float32\n",
      "The loss is: 1.215306043624878 at step 592\n",
      "4 float32 float32 float32\n",
      "The loss is: 1.1780871152877808 at step 593\n",
      "4 float32 float32 float32\n",
      "The loss is: 1.1698384284973145 at step 594\n",
      "14 float32 float32 float32\n",
      "The loss is: 3.9619739055633545 at step 595\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.8758720755577087 at step 596\n",
      "2 float32 float32 float32\n",
      "The loss is: 3.41125750541687 at step 597\n",
      "13 float32 float32 float32\n",
      "The loss is: 2.9770703315734863 at step 598\n",
      "1 float32 float32 float32\n",
      "The loss is: 2.5286881923675537 at step 599\n",
      "10 float32 float32 float32\n",
      "The loss is: 1.1352185010910034 at step 600\n",
      "1 float32 float32 float32\n",
      "The loss is: 1.366997241973877 at step 601\n",
      "8 float32 float32 float32\n",
      "The loss is: 2.5108070373535156 at step 602\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.5562301874160767 at step 603\n",
      "16 float32 float32 float32\n",
      "The loss is: 5.233994960784912 at step 604\n",
      "14 float32 float32 float32\n",
      "The loss is: 4.3050055503845215 at step 605\n",
      "10 float32 float32 float32\n",
      "The loss is: 1.1016920804977417 at step 606\n",
      "4 float32 float32 float32\n",
      "The loss is: 1.1037909984588623 at step 607\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.893248438835144 at step 608\n",
      "11 float32 float32 float32\n",
      "The loss is: 2.183244466781616 at step 609\n",
      "0 float32 float32 float32\n",
      "The loss is: 5.176529884338379 at step 610\n",
      "5 float32 float32 float32\n",
      "The loss is: 1.0731215476989746 at step 611\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.9366623759269714 at step 612\n",
      "14 float32 float32 float32\n",
      "The loss is: 3.783602714538574 at step 613\n",
      "1 float32 float32 float32\n",
      "The loss is: 3.303793430328369 at step 614\n",
      "1 float32 float32 float32\n",
      "The loss is: 2.194291830062866 at step 615\n",
      "17 float32 float32 float32\n",
      "The loss is: 3.602184295654297 at step 616\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.923608124256134 at step 617\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.6286238431930542 at step 618\n",
      "18 float32 float32 float32\n",
      "The loss is: 6.625602722167969 at step 619\n",
      "8 float32 float32 float32\n",
      "The loss is: 2.410736083984375 at step 620\n",
      "1 float32 float32 float32\n",
      "The loss is: 1.4780325889587402 at step 621\n",
      "17 float32 float32 float32\n",
      "The loss is: 1.9004321098327637 at step 622\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.4950664043426514 at step 623\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.9217877984046936 at step 624\n",
      "2 float32 float32 float32\n",
      "The loss is: 3.771528959274292 at step 625\n",
      "0 float32 float32 float32\n",
      "The loss is: 3.839171886444092 at step 626\n",
      "4 float32 float32 float32\n",
      "The loss is: 1.0768269300460815 at step 627\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.8357892036437988 at step 628\n",
      "15 float32 float32 float32\n",
      "The loss is: 4.286451816558838 at step 629\n",
      "13 float32 float32 float32\n",
      "The loss is: 2.9394149780273438 at step 630\n",
      "16 float32 float32 float32\n",
      "The loss is: 3.4258790016174316 at step 631\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.9570479989051819 at step 632\n",
      "17 float32 float32 float32\n",
      "The loss is: 2.9611430168151855 at step 633\n",
      "13 float32 float32 float32\n",
      "The loss is: 3.325117349624634 at step 634\n",
      "5 float32 float32 float32\n",
      "The loss is: 3.3554840087890625 at step 635\n",
      "7 float32 float32 float32\n",
      "The loss is: 2.744335889816284 at step 636\n",
      "11 float32 float32 float32\n",
      "The loss is: 1.3074822425842285 at step 637\n",
      "4 float32 float32 float32\n",
      "The loss is: 1.1551830768585205 at step 638\n",
      "14 float32 float32 float32\n",
      "The loss is: 4.4221696853637695 at step 639\n",
      "12 float32 float32 float32\n",
      "The loss is: 2.666140079498291 at step 640\n",
      "1 float32 float32 float32\n",
      "The loss is: 3.8792736530303955 at step 641\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.9187948703765869 at step 642\n",
      "4 float32 float32 float32\n",
      "The loss is: 1.0569990873336792 at step 643\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.8499671220779419 at step 644\n",
      "1 float32 float32 float32\n",
      "The loss is: 2.408324718475342 at step 645\n",
      "4 float32 float32 float32\n",
      "The loss is: 1.1322574615478516 at step 646\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.1235727071762085 at step 647\n",
      "8 float32 float32 float32\n",
      "The loss is: 1.5466986894607544 at step 648\n",
      "6 float32 float32 float32\n",
      "The loss is: 2.0044095516204834 at step 649\n",
      "16 float32 float32 float32\n",
      "The loss is: 2.9457106590270996 at step 650\n",
      "5 float32 float32 float32\n",
      "The loss is: 1.4341658353805542 at step 651\n",
      "6 float32 float32 float32\n",
      "The loss is: 1.2337679862976074 at step 652\n",
      "11 float32 float32 float32\n",
      "The loss is: 1.2493298053741455 at step 653\n",
      "14 float32 float32 float32\n",
      "The loss is: 3.572739601135254 at step 654\n",
      "10 float32 float32 float32\n",
      "The loss is: 1.0506179332733154 at step 655\n",
      "2 float32 float32 float32\n",
      "The loss is: 3.1014015674591064 at step 656\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.8998098373413086 at step 657\n",
      "0 float32 float32 float32\n",
      "The loss is: 1.984304428100586 at step 658\n",
      "17 float32 float32 float32\n",
      "The loss is: 1.9304841756820679 at step 659\n",
      "9 float32 float32 float32\n",
      "The loss is: 1.009838581085205 at step 660\n",
      "2 float32 float32 float32\n",
      "The loss is: 1.483026146888733 at step 661\n",
      "1 float32 float32 float32\n",
      "The loss is: 1.3097470998764038 at step 662\n",
      "15 float32 float32 float32\n",
      "The loss is: 3.8808255195617676 at step 663\n",
      "16 float32 float32 float32\n",
      "The loss is: 3.4829232692718506 at step 664\n",
      "7 float32 float32 float32\n",
      "The loss is: 1.6983678340911865 at step 665\n",
      "17 float32 float32 float32\n",
      "The loss is: 2.229497194290161 at step 666\n",
      "11 float32 float32 float32\n",
      "The loss is: 1.1221957206726074 at step 667\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.8590273857116699 at step 668\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.9538760781288147 at step 669\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.8088694214820862 at step 670\n",
      "1 float32 float32 float32\n",
      "The loss is: 5.1900553703308105 at step 671\n",
      "10 float32 float32 float32\n",
      "The loss is: 1.5550509691238403 at step 672\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.8588476181030273 at step 673\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.71734219789505 at step 674\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.8662732839584351 at step 675\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.7862569093704224 at step 676\n",
      "16 float32 float32 float32\n",
      "The loss is: 2.251295804977417 at step 677\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.9518088102340698 at step 678\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.2678182125091553 at step 679\n",
      "12 float32 float32 float32\n",
      "The loss is: 1.5508042573928833 at step 680\n",
      "18 float32 float32 float32\n",
      "The loss is: 1.7506781816482544 at step 681\n",
      "14 float32 float32 float32\n",
      "The loss is: 2.9731550216674805 at step 682\n",
      "14 float32 float32 float32\n",
      "The loss is: 2.9640896320343018 at step 683\n",
      "14 float32 float32 float32\n",
      "The loss is: 2.9449732303619385 at step 684\n",
      "12 float32 float32 float32\n",
      "The loss is: 1.5221186876296997 at step 685\n",
      "16 float32 float32 float32\n",
      "The loss is: 2.1673078536987305 at step 686\n",
      "0 float32 float32 float32\n",
      "The loss is: 1.687769889831543 at step 687\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.9368345737457275 at step 688\n",
      "18 float32 float32 float32\n",
      "The loss is: 2.0284337997436523 at step 689\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.8916258215904236 at step 690\n",
      "17 float32 float32 float32\n",
      "The loss is: 1.550163745880127 at step 691\n",
      "18 float32 float32 float32\n",
      "The loss is: 1.3207836151123047 at step 692\n",
      "16 float32 float32 float32\n",
      "The loss is: 2.007899284362793 at step 693\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.7296961545944214 at step 694\n",
      "2 float32 float32 float32\n",
      "The loss is: 4.25587797164917 at step 695\n",
      "2 float32 float32 float32\n",
      "The loss is: 4.041370391845703 at step 696\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.6982192397117615 at step 697\n",
      "17 float32 float32 float32\n",
      "The loss is: 1.2895188331604004 at step 698\n",
      "0 float32 float32 float32\n",
      "The loss is: 1.6555933952331543 at step 699\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.0024155378341675 at step 700\n",
      "5 float32 float32 float32\n",
      "The loss is: 1.8810893297195435 at step 701\n",
      "13 float32 float32 float32\n",
      "The loss is: 2.6258952617645264 at step 702\n",
      "8 float32 float32 float32\n",
      "The loss is: 2.204291343688965 at step 703\n",
      "4 float32 float32 float32\n",
      "The loss is: 1.4301310777664185 at step 704\n",
      "9 float32 float32 float32\n",
      "The loss is: 1.048170566558838 at step 705\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.7722347974777222 at step 706\n",
      "0 float32 float32 float32\n",
      "The loss is: 2.116093158721924 at step 707\n",
      "14 float32 float32 float32\n",
      "The loss is: 2.8248326778411865 at step 708\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.8400269150733948 at step 709\n",
      "0 float32 float32 float32\n",
      "The loss is: 2.389885902404785 at step 710\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.3458350896835327 at step 711\n",
      "6 float32 float32 float32\n",
      "The loss is: 1.024328589439392 at step 712\n",
      "1 float32 float32 float32\n",
      "The loss is: 1.44148588180542 at step 713\n",
      "7 float32 float32 float32\n",
      "The loss is: 1.4997726678848267 at step 714\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.7352569103240967 at step 715\n",
      "9 float32 float32 float32\n",
      "The loss is: 1.672216534614563 at step 716\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.9920266270637512 at step 717\n",
      "13 float32 float32 float32\n",
      "The loss is: 2.5156307220458984 at step 718\n",
      "2 float32 float32 float32\n",
      "The loss is: 1.1624324321746826 at step 719\n",
      "15 float32 float32 float32\n",
      "The loss is: 2.8593268394470215 at step 720\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.0208253860473633 at step 721\n",
      "0 float32 float32 float32\n",
      "The loss is: 1.1619676351547241 at step 722\n",
      "6 float32 float32 float32\n",
      "The loss is: 1.035387635231018 at step 723\n",
      "0 float32 float32 float32\n",
      "The loss is: 1.2217899560928345 at step 724\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.9936161041259766 at step 725\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.0328359603881836 at step 726\n",
      "13 float32 float32 float32\n",
      "The loss is: 1.926399827003479 at step 727\n",
      "6 float32 float32 float32\n",
      "The loss is: 1.1119108200073242 at step 728\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.9432854056358337 at step 729\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.9007580876350403 at step 730\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.8157413005828857 at step 731\n",
      "18 float32 float32 float32\n",
      "The loss is: 1.4798061847686768 at step 732\n",
      "2 float32 float32 float32\n",
      "The loss is: 2.8400497436523438 at step 733\n",
      "2 float32 float32 float32\n",
      "The loss is: 2.8603219985961914 at step 734\n",
      "16 float32 float32 float32\n",
      "The loss is: 1.7407034635543823 at step 735\n",
      "13 float32 float32 float32\n",
      "The loss is: 1.7668431997299194 at step 736\n",
      "12 float32 float32 float32\n",
      "The loss is: 1.2386786937713623 at step 737\n",
      "2 float32 float32 float32\n",
      "The loss is: 1.4437782764434814 at step 738\n",
      "18 float32 float32 float32\n",
      "The loss is: 2.485976219177246 at step 739\n",
      "11 float32 float32 float32\n",
      "The loss is: 1.1289657354354858 at step 740\n",
      "6 float32 float32 float32\n",
      "The loss is: 1.2516436576843262 at step 741\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.990280270576477 at step 742\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.0596709251403809 at step 743\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.6459174752235413 at step 744\n",
      "1 float32 float32 float32\n",
      "The loss is: 1.8628565073013306 at step 745\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.9412043690681458 at step 746\n",
      "17 float32 float32 float32\n",
      "The loss is: 1.5318090915679932 at step 747\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.9371998906135559 at step 748\n",
      "12 float32 float32 float32\n",
      "The loss is: 1.2429348230361938 at step 749\n",
      "12 float32 float32 float32\n",
      "The loss is: 1.2608542442321777 at step 750\n",
      "17 float32 float32 float32\n",
      "The loss is: 1.3922557830810547 at step 751\n",
      "1 float32 float32 float32\n",
      "The loss is: 2.125511407852173 at step 752\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.6716082096099854 at step 753\n",
      "12 float32 float32 float32\n",
      "The loss is: 1.217889666557312 at step 754\n",
      "12 float32 float32 float32\n",
      "The loss is: 1.238955020904541 at step 755\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.8100501298904419 at step 756\n",
      "18 float32 float32 float32\n",
      "The loss is: 1.65145742893219 at step 757\n",
      "18 float32 float32 float32\n",
      "The loss is: 1.4349708557128906 at step 758\n",
      "18 float32 float32 float32\n",
      "The loss is: 1.1541718244552612 at step 759\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.7103091478347778 at step 760\n",
      "17 float32 float32 float32\n",
      "The loss is: 1.348158359527588 at step 761\n",
      "2 float32 float32 float32\n",
      "The loss is: 3.98331618309021 at step 762\n",
      "12 float32 float32 float32\n",
      "The loss is: 2.0071065425872803 at step 763\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.9410550594329834 at step 764\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.366809368133545 at step 765\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.8407955765724182 at step 766\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.9389445781707764 at step 767\n",
      "14 float32 float32 float32\n",
      "The loss is: 2.4787564277648926 at step 768\n",
      "12 float32 float32 float32\n",
      "The loss is: 1.4792561531066895 at step 769\n",
      "14 float32 float32 float32\n",
      "The loss is: 2.5144166946411133 at step 770\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.7104594707489014 at step 771\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.9845957159996033 at step 772\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.8439921140670776 at step 773\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.832206130027771 at step 774\n",
      "15 float32 float32 float32\n",
      "The loss is: 2.304210662841797 at step 775\n",
      "18 float32 float32 float32\n",
      "The loss is: 1.145423412322998 at step 776\n",
      "17 float32 float32 float32\n",
      "The loss is: 1.1538766622543335 at step 777\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.8750114440917969 at step 778\n",
      "2 float32 float32 float32\n",
      "The loss is: 3.2047457695007324 at step 779\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.8727174401283264 at step 780\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.9444325566291809 at step 781\n",
      "14 float32 float32 float32\n",
      "The loss is: 2.094860076904297 at step 782\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.6760858297348022 at step 783\n",
      "2 float32 float32 float32\n",
      "The loss is: 1.2302179336547852 at step 784\n",
      "13 float32 float32 float32\n",
      "The loss is: 1.7816230058670044 at step 785\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.8587352633476257 at step 786\n",
      "9 float32 float32 float32\n",
      "The loss is: 1.7405446767807007 at step 787\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.9359249472618103 at step 788\n",
      "16 float32 float32 float32\n",
      "The loss is: 2.3855504989624023 at step 789\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.9731190800666809 at step 790\n",
      "17 float32 float32 float32\n",
      "The loss is: 1.6184574365615845 at step 791\n",
      "2 float32 float32 float32\n",
      "The loss is: 1.5215504169464111 at step 792\n",
      "1 float32 float32 float32\n",
      "The loss is: 1.6706169843673706 at step 793\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.8107406497001648 at step 794\n",
      "1 float32 float32 float32\n",
      "The loss is: 1.278862476348877 at step 795\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.9924463629722595 at step 796\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.8191152215003967 at step 797\n",
      "9 float32 float32 float32\n",
      "The loss is: 1.5884448289871216 at step 798\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.4626886546611786 at step 799\n",
      "17 float32 float32 float32\n",
      "The loss is: 2.3332936763763428 at step 800\n",
      "10 float32 float32 float32\n",
      "The loss is: 1.1114459037780762 at step 801\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.8095448017120361 at step 802\n",
      "15 float32 float32 float32\n",
      "The loss is: 2.0678420066833496 at step 803\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.6330850124359131 at step 804\n",
      "12 float32 float32 float32\n",
      "The loss is: 1.0800681114196777 at step 805\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.7204764485359192 at step 806\n",
      "1 float32 float32 float32\n",
      "The loss is: 2.3874638080596924 at step 807\n",
      "13 float32 float32 float32\n",
      "The loss is: 1.5384607315063477 at step 808\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.8823500871658325 at step 809\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.6250298023223877 at step 810\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.773179292678833 at step 811\n",
      "14 float32 float32 float32\n",
      "The loss is: 1.921522617340088 at step 812\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.6224181652069092 at step 813\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.7310599088668823 at step 814\n",
      "17 float32 float32 float32\n",
      "The loss is: 1.2004214525222778 at step 815\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.6580060124397278 at step 816\n",
      "1 float32 float32 float32\n",
      "The loss is: 2.1408350467681885 at step 817\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.5369157791137695 at step 818\n",
      "15 float32 float32 float32\n",
      "The loss is: 1.9044990539550781 at step 819\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.646472692489624 at step 820\n",
      "18 float32 float32 float32\n",
      "The loss is: 1.3252005577087402 at step 821\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.5639946460723877 at step 822\n",
      "15 float32 float32 float32\n",
      "The loss is: 1.8636430501937866 at step 823\n",
      "2 float32 float32 float32\n",
      "The loss is: 2.2672812938690186 at step 824\n",
      "14 float32 float32 float32\n",
      "The loss is: 1.7821420431137085 at step 825\n",
      "13 float32 float32 float32\n",
      "The loss is: 1.3496557474136353 at step 826\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.764563798904419 at step 827\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.6818707585334778 at step 828\n",
      "17 float32 float32 float32\n",
      "The loss is: 1.4096717834472656 at step 829\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.6826284527778625 at step 830\n",
      "17 float32 float32 float32\n",
      "The loss is: 1.0751069784164429 at step 831\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.9170893430709839 at step 832\n",
      "2 float32 float32 float32\n",
      "The loss is: 3.074979782104492 at step 833\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.7434174418449402 at step 834\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.5360115170478821 at step 835\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.9463852643966675 at step 836\n",
      "15 float32 float32 float32\n",
      "The loss is: 1.6655235290527344 at step 837\n",
      "14 float32 float32 float32\n",
      "The loss is: 1.6255602836608887 at step 838\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.1667472124099731 at step 839\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.9812472462654114 at step 840\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.8261693716049194 at step 841\n",
      "8 float32 float32 float32\n",
      "The loss is: 1.3118997812271118 at step 842\n",
      "17 float32 float32 float32\n",
      "The loss is: 2.6087281703948975 at step 843\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.7778311967849731 at step 844\n",
      "16 float32 float32 float32\n",
      "The loss is: 1.9457662105560303 at step 845\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.6415804624557495 at step 846\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.6312685012817383 at step 847\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.5493965148925781 at step 848\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.61368727684021 at step 849\n",
      "11 float32 float32 float32\n",
      "The loss is: 1.158092975616455 at step 850\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.703819751739502 at step 851\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.7754936218261719 at step 852\n",
      "4 float32 float32 float32\n",
      "The loss is: 1.0776257514953613 at step 853\n",
      "11 float32 float32 float32\n",
      "The loss is: 1.1383813619613647 at step 854\n",
      "13 float32 float32 float32\n",
      "The loss is: 1.4668022394180298 at step 855\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.48057693243026733 at step 856\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.6355351209640503 at step 857\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.7966268658638 at step 858\n",
      "17 float32 float32 float32\n",
      "The loss is: 1.4308573007583618 at step 859\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.937953531742096 at step 860\n",
      "1 float32 float32 float32\n",
      "The loss is: 1.196610927581787 at step 861\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.847376823425293 at step 862\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.8601629734039307 at step 863\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.595940351486206 at step 864\n",
      "1 float32 float32 float32\n",
      "The loss is: 1.2325438261032104 at step 865\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.8274993896484375 at step 866\n",
      "14 float32 float32 float32\n",
      "The loss is: 1.6874839067459106 at step 867\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.7482125759124756 at step 868\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.613861083984375 at step 869\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.8434065580368042 at step 870\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.6660066246986389 at step 871\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.9320365190505981 at step 872\n",
      "1 float32 float32 float32\n",
      "The loss is: 2.3878023624420166 at step 873\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.2380210161209106 at step 874\n",
      "1 float32 float32 float32\n",
      "The loss is: 1.201934814453125 at step 875\n",
      "15 float32 float32 float32\n",
      "The loss is: 2.2127885818481445 at step 876\n",
      "14 float32 float32 float32\n",
      "The loss is: 2.584073305130005 at step 877\n",
      "14 float32 float32 float32\n",
      "The loss is: 2.5652217864990234 at step 878\n",
      "10 float32 float32 float32\n",
      "The loss is: 1.141736388206482 at step 879\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.7168170809745789 at step 880\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.5537053346633911 at step 881\n",
      "14 float32 float32 float32\n",
      "The loss is: 1.6696803569793701 at step 882\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.8703100085258484 at step 883\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.8236050009727478 at step 884\n",
      "15 float32 float32 float32\n",
      "The loss is: 2.2490670680999756 at step 885\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.8847745060920715 at step 886\n",
      "14 float32 float32 float32\n",
      "The loss is: 2.0618767738342285 at step 887\n",
      "3 float32 float32 float32\n",
      "The loss is: 2.176372766494751 at step 888\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.5134096145629883 at step 889\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.5067302584648132 at step 890\n",
      "15 float32 float32 float32\n",
      "The loss is: 1.890616536140442 at step 891\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.5889018177986145 at step 892\n",
      "14 float32 float32 float32\n",
      "The loss is: 2.6905622482299805 at step 893\n",
      "5 float32 float32 float32\n",
      "The loss is: 1.6884137392044067 at step 894\n",
      "7 float32 float32 float32\n",
      "The loss is: 1.5282177925109863 at step 895\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.7202751636505127 at step 896\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.9734765291213989 at step 897\n",
      "14 float32 float32 float32\n",
      "The loss is: 1.3039427995681763 at step 898\n",
      "4 float32 float32 float32\n",
      "The loss is: 1.0434304475784302 at step 899\n",
      "10 float32 float32 float32\n",
      "The loss is: 1.198096752166748 at step 900\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.8980839848518372 at step 901\n",
      "9 float32 float32 float32\n",
      "The loss is: 1.10539710521698 at step 902\n",
      "2 float32 float32 float32\n",
      "The loss is: 4.347474098205566 at step 903\n",
      "15 float32 float32 float32\n",
      "The loss is: 1.3089890480041504 at step 904\n",
      "15 float32 float32 float32\n",
      "The loss is: 1.2117514610290527 at step 905\n",
      "2 float32 float32 float32\n",
      "The loss is: 1.4630669355392456 at step 906\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.9622554779052734 at step 907\n",
      "15 float32 float32 float32\n",
      "The loss is: 2.5224015712738037 at step 908\n",
      "13 float32 float32 float32\n",
      "The loss is: 2.113933563232422 at step 909\n",
      "12 float32 float32 float32\n",
      "The loss is: 1.3164708614349365 at step 910\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.860605001449585 at step 911\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.9906976222991943 at step 912\n",
      "2 float32 float32 float32\n",
      "The loss is: 2.203768491744995 at step 913\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.5636476278305054 at step 914\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.802966833114624 at step 915\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.8563647866249084 at step 916\n",
      "16 float32 float32 float32\n",
      "The loss is: 1.0368554592132568 at step 917\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.546296238899231 at step 918\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.6819798946380615 at step 919\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.7946107387542725 at step 920\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.5903568863868713 at step 921\n",
      "1 float32 float32 float32\n",
      "The loss is: 2.0915040969848633 at step 922\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.7099798917770386 at step 923\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.9775097966194153 at step 924\n",
      "7 float32 float32 float32\n",
      "The loss is: 1.01655912399292 at step 925\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.9097392559051514 at step 926\n",
      "14 float32 float32 float32\n",
      "The loss is: 1.531076431274414 at step 927\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.7028172016143799 at step 928\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.8057732582092285 at step 929\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.683182954788208 at step 930\n",
      "15 float32 float32 float32\n",
      "The loss is: 1.2997796535491943 at step 931\n",
      "18 float32 float32 float32\n",
      "The loss is: 1.09373140335083 at step 932\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.680637538433075 at step 933\n",
      "2 float32 float32 float32\n",
      "The loss is: 2.869499683380127 at step 934\n",
      "16 float32 float32 float32\n",
      "The loss is: 1.0333771705627441 at step 935\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.7463935613632202 at step 936\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.8589140176773071 at step 937\n",
      "14 float32 float32 float32\n",
      "The loss is: 1.2031259536743164 at step 938\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.9361488819122314 at step 939\n",
      "1 float32 float32 float32\n",
      "The loss is: 1.239060878753662 at step 940\n",
      "16 float32 float32 float32\n",
      "The loss is: 1.3338512182235718 at step 941\n",
      "16 float32 float32 float32\n",
      "The loss is: 1.428882122039795 at step 942\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.781225323677063 at step 943\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.6268739104270935 at step 944\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.6157963871955872 at step 945\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.41651880741119385 at step 946\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.4096856713294983 at step 947\n",
      "0 float32 float32 float32\n",
      "The loss is: 1.9611318111419678 at step 948\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.5632797479629517 at step 949\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.37558093667030334 at step 950\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.4123130440711975 at step 951\n",
      "14 float32 float32 float32\n",
      "The loss is: 1.188949465751648 at step 952\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.5625813007354736 at step 953\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.6974716782569885 at step 954\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.9166262745857239 at step 955\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.9909161329269409 at step 956\n",
      "9 float32 float32 float32\n",
      "The loss is: 1.0112205743789673 at step 957\n",
      "12 float32 float32 float32\n",
      "The loss is: 1.0696221590042114 at step 958\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.563431441783905 at step 959\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.5233845114707947 at step 960\n",
      "16 float32 float32 float32\n",
      "The loss is: 1.016477346420288 at step 961\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.3710717260837555 at step 962\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.9100729823112488 at step 963\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.4733673334121704 at step 964\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.4522252678871155 at step 965\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.4773508608341217 at step 966\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.7773062586784363 at step 967\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.4333936274051666 at step 968\n",
      "2 float32 float32 float32\n",
      "The loss is: 2.0995826721191406 at step 969\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.48482486605644226 at step 970\n",
      "16 float32 float32 float32\n",
      "The loss is: 1.4151206016540527 at step 971\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.7984927892684937 at step 972\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.7498355507850647 at step 973\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.5642935037612915 at step 974\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.4306834936141968 at step 975\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.5867041945457458 at step 976\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.8565072417259216 at step 977\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.48160320520401 at step 978\n",
      "15 float32 float32 float32\n",
      "The loss is: 1.0668872594833374 at step 979\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.4784746766090393 at step 980\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.483233243227005 at step 981\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.5860196948051453 at step 982\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.49003493785858154 at step 983\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.39571478962898254 at step 984\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.4110121428966522 at step 985\n",
      "16 float32 float32 float32\n",
      "The loss is: 1.0605783462524414 at step 986\n",
      "1 float32 float32 float32\n",
      "The loss is: 1.1456952095031738 at step 987\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.5536577701568604 at step 988\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.7041314840316772 at step 989\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.7624191045761108 at step 990\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.7511413097381592 at step 991\n",
      "17 float32 float32 float32\n",
      "The loss is: 1.7225849628448486 at step 992\n",
      "15 float32 float32 float32\n",
      "The loss is: 1.2224031686782837 at step 993\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.3266454339027405 at step 994\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.5578075647354126 at step 995\n",
      "3 float32 float32 float32\n",
      "The loss is: 2.085139274597168 at step 996\n",
      "0 float32 float32 float32\n",
      "The loss is: 2.2668867111206055 at step 997\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.48231327533721924 at step 998\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.9896527528762817 at step 999\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.400918573141098 at step 1000\n",
      "9 float32 float32 float32\n",
      "The loss is: 1.4484710693359375 at step 1001\n",
      "4 float32 float32 float32\n",
      "The loss is: 1.2209349870681763 at step 1002\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.8644447922706604 at step 1003\n",
      "8 float32 float32 float32\n",
      "The loss is: 1.482154369354248 at step 1004\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.8125138878822327 at step 1005\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.4568832218647003 at step 1006\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.49741634726524353 at step 1007\n",
      "4 float32 float32 float32\n",
      "The loss is: 1.151980996131897 at step 1008\n",
      "3 float32 float32 float32\n",
      "The loss is: 2.672433853149414 at step 1009\n",
      "10 float32 float32 float32\n",
      "The loss is: 1.048987627029419 at step 1010\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.5283975005149841 at step 1011\n",
      "2 float32 float32 float32\n",
      "The loss is: 2.8189353942871094 at step 1012\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.7314895987510681 at step 1013\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.596832275390625 at step 1014\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.27617180347442627 at step 1015\n",
      "6 float32 float32 float32\n",
      "The loss is: 1.6982637643814087 at step 1016\n",
      "16 float32 float32 float32\n",
      "The loss is: 2.3754982948303223 at step 1017\n",
      "6 float32 float32 float32\n",
      "The loss is: 1.4417673349380493 at step 1018\n",
      "14 float32 float32 float32\n",
      "The loss is: 1.2752857208251953 at step 1019\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.52740877866745 at step 1020\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.3859422206878662 at step 1021\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.836123526096344 at step 1022\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.839415192604065 at step 1023\n",
      "14 float32 float32 float32\n",
      "The loss is: 1.2225496768951416 at step 1024\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.39011016488075256 at step 1025\n",
      "1 float32 float32 float32\n",
      "The loss is: 1.860168695449829 at step 1026\n",
      "14 float32 float32 float32\n",
      "The loss is: 1.0175565481185913 at step 1027\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.7843552231788635 at step 1028\n",
      "9 float32 float32 float32\n",
      "The loss is: 1.0379605293273926 at step 1029\n",
      "14 float32 float32 float32\n",
      "The loss is: 1.4168800115585327 at step 1030\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.5718099474906921 at step 1031\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.793755292892456 at step 1032\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.8040259480476379 at step 1033\n",
      "17 float32 float32 float32\n",
      "The loss is: 1.0780447721481323 at step 1034\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.4824468791484833 at step 1035\n",
      "15 float32 float32 float32\n",
      "The loss is: 1.1127043962478638 at step 1036\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.9696371555328369 at step 1037\n",
      "0 float32 float32 float32\n",
      "The loss is: 1.7476255893707275 at step 1038\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.5839599370956421 at step 1039\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.7904355525970459 at step 1040\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.5030378103256226 at step 1041\n",
      "15 float32 float32 float32\n",
      "The loss is: 1.0999387502670288 at step 1042\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.7584525942802429 at step 1043\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.5023227334022522 at step 1044\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.5799465775489807 at step 1045\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.5620196461677551 at step 1046\n",
      "1 float32 float32 float32\n",
      "The loss is: 1.379769206047058 at step 1047\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.49736520648002625 at step 1048\n",
      "1 float32 float32 float32\n",
      "The loss is: 1.0726284980773926 at step 1049\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.6976834535598755 at step 1050\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.7386974096298218 at step 1051\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.6911724209785461 at step 1052\n",
      "13 float32 float32 float32\n",
      "The loss is: 1.1504992246627808 at step 1053\n",
      "16 float32 float32 float32\n",
      "The loss is: 1.3121380805969238 at step 1054\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.8460933566093445 at step 1055\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.4724796712398529 at step 1056\n",
      "2 float32 float32 float32\n",
      "The loss is: 1.792187213897705 at step 1057\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.5792081952095032 at step 1058\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.9398069381713867 at step 1059\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.7812286615371704 at step 1060\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.32953792810440063 at step 1061\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.6141411662101746 at step 1062\n",
      "2 float32 float32 float32\n",
      "The loss is: 1.91602623462677 at step 1063\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.5152826905250549 at step 1064\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.5984693169593811 at step 1065\n",
      "14 float32 float32 float32\n",
      "The loss is: 1.0857268571853638 at step 1066\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.6670820713043213 at step 1067\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.70491623878479 at step 1068\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.4925757050514221 at step 1069\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.901322066783905 at step 1070\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.9769912362098694 at step 1071\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.5858603715896606 at step 1072\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.5635815858840942 at step 1073\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.3513563275337219 at step 1074\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.30934208631515503 at step 1075\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.29314982891082764 at step 1076\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.3715311288833618 at step 1077\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.48188316822052 at step 1078\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.9453712105751038 at step 1079\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.9364031553268433 at step 1080\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.5305265784263611 at step 1081\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.31040602922439575 at step 1082\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.34843575954437256 at step 1083\n",
      "2 float32 float32 float32\n",
      "The loss is: 1.5923676490783691 at step 1084\n",
      "18 float32 float32 float32\n",
      "The loss is: 1.3931171894073486 at step 1085\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.9220402240753174 at step 1086\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.8095757961273193 at step 1087\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.7831878066062927 at step 1088\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.3724004030227661 at step 1089\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.7281539440155029 at step 1090\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.30535075068473816 at step 1091\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.31740671396255493 at step 1092\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.629172146320343 at step 1093\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.8009549379348755 at step 1094\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.6308404803276062 at step 1095\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.41335397958755493 at step 1096\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.3092670440673828 at step 1097\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.8184208273887634 at step 1098\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.29340261220932007 at step 1099\n",
      "18 float32 float32 float32\n",
      "The loss is: 1.4642345905303955 at step 1100\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.43250003457069397 at step 1101\n",
      "1 float32 float32 float32\n",
      "The loss is: 1.5486812591552734 at step 1102\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.3341059982776642 at step 1103\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.8893445134162903 at step 1104\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.8047893047332764 at step 1105\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.8177239298820496 at step 1106\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.6695988178253174 at step 1107\n",
      "7 float32 float32 float32\n",
      "The loss is: 1.0902595520019531 at step 1108\n",
      "13 float32 float32 float32\n",
      "The loss is: 1.1275993585586548 at step 1109\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.7520857453346252 at step 1110\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.8006816506385803 at step 1111\n",
      "2 float32 float32 float32\n",
      "The loss is: 1.9884858131408691 at step 1112\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.3473854064941406 at step 1113\n",
      "18 float32 float32 float32\n",
      "The loss is: 1.0570988655090332 at step 1114\n",
      "2 float32 float32 float32\n",
      "The loss is: 1.4263731241226196 at step 1115\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.4302184581756592 at step 1116\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.6291391849517822 at step 1117\n",
      "16 float32 float32 float32\n",
      "The loss is: 1.1406930685043335 at step 1118\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.5430535674095154 at step 1119\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.4358280599117279 at step 1120\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.3570305109024048 at step 1121\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.766280472278595 at step 1122\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.39057227969169617 at step 1123\n",
      "2 float32 float32 float32\n",
      "The loss is: 2.204737424850464 at step 1124\n",
      "2 float32 float32 float32\n",
      "The loss is: 1.7982152700424194 at step 1125\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.47216346859931946 at step 1126\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.6094162464141846 at step 1127\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.5431488156318665 at step 1128\n",
      "11 float32 float32 float32\n",
      "The loss is: 1.0250425338745117 at step 1129\n",
      "14 float32 float32 float32\n",
      "The loss is: 1.2390055656433105 at step 1130\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.7334780097007751 at step 1131\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.6608039736747742 at step 1132\n",
      "18 float32 float32 float32\n",
      "The loss is: 1.0040863752365112 at step 1133\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.3048732876777649 at step 1134\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.4777151346206665 at step 1135\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.7568391561508179 at step 1136\n",
      "0 float32 float32 float32\n",
      "The loss is: 1.6504765748977661 at step 1137\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.7913220524787903 at step 1138\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.440889447927475 at step 1139\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.5101101398468018 at step 1140\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.6458960175514221 at step 1141\n",
      "17 float32 float32 float32\n",
      "The loss is: 1.0536295175552368 at step 1142\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.6533634066581726 at step 1143\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.9249774217605591 at step 1144\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.31092706322669983 at step 1145\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.8042271137237549 at step 1146\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.7949701547622681 at step 1147\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.7187075018882751 at step 1148\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.7598108053207397 at step 1149\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.6564514636993408 at step 1150\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.3908374011516571 at step 1151\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.31602609157562256 at step 1152\n",
      "1 float32 float32 float32\n",
      "The loss is: 1.8169182538986206 at step 1153\n",
      "2 float32 float32 float32\n",
      "The loss is: 1.2220368385314941 at step 1154\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.7544858455657959 at step 1155\n",
      "8 float32 float32 float32\n",
      "The loss is: 1.3240147829055786 at step 1156\n",
      "14 float32 float32 float32\n",
      "The loss is: 2.1709671020507812 at step 1157\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.5533477067947388 at step 1158\n",
      "16 float32 float32 float32\n",
      "The loss is: 1.1693449020385742 at step 1159\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.5469933152198792 at step 1160\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.2962704300880432 at step 1161\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.48007121682167053 at step 1162\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.6947721242904663 at step 1163\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.47612693905830383 at step 1164\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.5712755918502808 at step 1165\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.927439570426941 at step 1166\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.3746066093444824 at step 1167\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.8592060804367065 at step 1168\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.6690624356269836 at step 1169\n",
      "10 float32 float32 float32\n",
      "The loss is: 1.2183012962341309 at step 1170\n",
      "12 float32 float32 float32\n",
      "The loss is: 1.6567225456237793 at step 1171\n",
      "8 float32 float32 float32\n",
      "The loss is: 1.01492440700531 at step 1172\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.9263492226600647 at step 1173\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.29646727442741394 at step 1174\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.567517876625061 at step 1175\n",
      "3 float32 float32 float32\n",
      "The loss is: 2.367055892944336 at step 1176\n",
      "3 float32 float32 float32\n",
      "The loss is: 2.417759895324707 at step 1177\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.7583020329475403 at step 1178\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.32283899188041687 at step 1179\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.680136501789093 at step 1180\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.41627782583236694 at step 1181\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.45526060461997986 at step 1182\n",
      "18 float32 float32 float32\n",
      "The loss is: 1.5167464017868042 at step 1183\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.7720199227333069 at step 1184\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.7812938094139099 at step 1185\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.7367927432060242 at step 1186\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.6828834414482117 at step 1187\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.33126962184906006 at step 1188\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.6947499513626099 at step 1189\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.3506628274917603 at step 1190\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.5275588035583496 at step 1191\n",
      "2 float32 float32 float32\n",
      "The loss is: 1.4601714611053467 at step 1192\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.8078882098197937 at step 1193\n",
      "15 float32 float32 float32\n",
      "The loss is: 1.2593770027160645 at step 1194\n",
      "6 float32 float32 float32\n",
      "The loss is: 2.0605616569519043 at step 1195\n",
      "9 float32 float32 float32\n",
      "The loss is: 1.8759517669677734 at step 1196\n",
      "13 float32 float32 float32\n",
      "The loss is: 1.0984457731246948 at step 1197\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.8581091165542603 at step 1198\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.8194998502731323 at step 1199\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.9492300748825073 at step 1200\n",
      "18 float32 float32 float32\n",
      "The loss is: 1.0416024923324585 at step 1201\n",
      "13 float32 float32 float32\n",
      "The loss is: 1.385406494140625 at step 1202\n",
      "0 float32 float32 float32\n",
      "The loss is: 3.316354751586914 at step 1203\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.954107940196991 at step 1204\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.27548131346702576 at step 1205\n",
      "2 float32 float32 float32\n",
      "The loss is: 1.0050415992736816 at step 1206\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.5947558879852295 at step 1207\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.7194826602935791 at step 1208\n",
      "13 float32 float32 float32\n",
      "The loss is: 2.6585638523101807 at step 1209\n",
      "17 float32 float32 float32\n",
      "The loss is: 2.3772921562194824 at step 1210\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.9946177005767822 at step 1211\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.9570087790489197 at step 1212\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.2692447304725647 at step 1213\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.7040520310401917 at step 1214\n",
      "4 float32 float32 float32\n",
      "The loss is: 1.0419288873672485 at step 1215\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.909013032913208 at step 1216\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.8349087834358215 at step 1217\n",
      "0 float32 float32 float32\n",
      "The loss is: 2.0895369052886963 at step 1218\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.1126823425292969 at step 1219\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.42917025089263916 at step 1220\n",
      "17 float32 float32 float32\n",
      "The loss is: 1.6468605995178223 at step 1221\n",
      "16 float32 float32 float32\n",
      "The loss is: 1.898637294769287 at step 1222\n",
      "13 float32 float32 float32\n",
      "The loss is: 1.697777509689331 at step 1223\n",
      "16 float32 float32 float32\n",
      "The loss is: 1.1777106523513794 at step 1224\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.8273798823356628 at step 1225\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.3985001742839813 at step 1226\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.5894548892974854 at step 1227\n",
      "16 float32 float32 float32\n",
      "The loss is: 1.1516504287719727 at step 1228\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.4214399755001068 at step 1229\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.39010855555534363 at step 1230\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.7423207759857178 at step 1231\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.9570280909538269 at step 1232\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.4056542217731476 at step 1233\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.5025264024734497 at step 1234\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.4656822979450226 at step 1235\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.5568092465400696 at step 1236\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.8489242196083069 at step 1237\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.4875001311302185 at step 1238\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.42443645000457764 at step 1239\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.42407283186912537 at step 1240\n",
      "1 float32 float32 float32\n",
      "The loss is: 1.1802854537963867 at step 1241\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.29444658756256104 at step 1242\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.3686969578266144 at step 1243\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.4210761785507202 at step 1244\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.679227888584137 at step 1245\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.5607520341873169 at step 1246\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.6873370409011841 at step 1247\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.32002171874046326 at step 1248\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.26626867055892944 at step 1249\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.643358051776886 at step 1250\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.9064227342605591 at step 1251\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.6049377918243408 at step 1252\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.5867040753364563 at step 1253\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.31295859813690186 at step 1254\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.9424067735671997 at step 1255\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.2289455235004425 at step 1256\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.2266508787870407 at step 1257\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.27868276834487915 at step 1258\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.22045870125293732 at step 1259\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.2267794907093048 at step 1260\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.5275613069534302 at step 1261\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.2714490294456482 at step 1262\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.6340187788009644 at step 1263\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.27312102913856506 at step 1264\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.2788625955581665 at step 1265\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.3087564706802368 at step 1266\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.26883572340011597 at step 1267\n",
      "18 float32 float32 float32\n",
      "The loss is: 1.2308157682418823 at step 1268\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.22458124160766602 at step 1269\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.5644078850746155 at step 1270\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.0389902591705322 at step 1271\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.2780108153820038 at step 1272\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.2271755486726761 at step 1273\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.4104008078575134 at step 1274\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.24851076304912567 at step 1275\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.2153453230857849 at step 1276\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.34416913986206055 at step 1277\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.45846590399742126 at step 1278\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.1927649974822998 at step 1279\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.26522237062454224 at step 1280\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.5801149606704712 at step 1281\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.2704237699508667 at step 1282\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.4348667860031128 at step 1283\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.45516544580459595 at step 1284\n",
      "2 float32 float32 float32\n",
      "The loss is: 1.0086325407028198 at step 1285\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.6019089818000793 at step 1286\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.6077568531036377 at step 1287\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.5582940578460693 at step 1288\n",
      "15 float32 float32 float32\n",
      "The loss is: 1.0606011152267456 at step 1289\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.6671946048736572 at step 1290\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.9374434351921082 at step 1291\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.921403169631958 at step 1292\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.3403061628341675 at step 1293\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.4191645681858063 at step 1294\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.3175647556781769 at step 1295\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.24652232229709625 at step 1296\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.6789202690124512 at step 1297\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.25640472769737244 at step 1298\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.33454781770706177 at step 1299\n",
      "1 float32 float32 float32\n",
      "The loss is: 1.6830253601074219 at step 1300\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.24204190075397491 at step 1301\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.3333381414413452 at step 1302\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.5589981079101562 at step 1303\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.4984915554523468 at step 1304\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.7266271710395813 at step 1305\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.3388976752758026 at step 1306\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.3731844127178192 at step 1307\n",
      "1 float32 float32 float32\n",
      "The loss is: 1.547723650932312 at step 1308\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.25069016218185425 at step 1309\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.2077077180147171 at step 1310\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.22457844018936157 at step 1311\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.283072829246521 at step 1312\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.2776181399822235 at step 1313\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.4413833022117615 at step 1314\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.29722824692726135 at step 1315\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.24158531427383423 at step 1316\n",
      "1 float32 float32 float32\n",
      "The loss is: 1.0767428874969482 at step 1317\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.2899961471557617 at step 1318\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.8176136612892151 at step 1319\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.8770123720169067 at step 1320\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.6677828431129456 at step 1321\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.5468195676803589 at step 1322\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.3411572277545929 at step 1323\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.5856866836547852 at step 1324\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.28194281458854675 at step 1325\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.4043785631656647 at step 1326\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.4251214861869812 at step 1327\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.8632562756538391 at step 1328\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.43333563208580017 at step 1329\n",
      "2 float32 float32 float32\n",
      "The loss is: 2.012667655944824 at step 1330\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.4739215075969696 at step 1331\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.5768094062805176 at step 1332\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.834915816783905 at step 1333\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.7404398322105408 at step 1334\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.9426174163818359 at step 1335\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.5701341032981873 at step 1336\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.5592970848083496 at step 1337\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.3150387108325958 at step 1338\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.5929747223854065 at step 1339\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.8459916710853577 at step 1340\n",
      "1 float32 float32 float32\n",
      "The loss is: 2.5857229232788086 at step 1341\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.22397321462631226 at step 1342\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.21164505183696747 at step 1343\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.28210365772247314 at step 1344\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.38701993227005005 at step 1345\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.534044623374939 at step 1346\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.9906391501426697 at step 1347\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.5263684391975403 at step 1348\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.5411106944084167 at step 1349\n",
      "18 float32 float32 float32\n",
      "The loss is: 1.0208172798156738 at step 1350\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.24951571226119995 at step 1351\n",
      "1 float32 float32 float32\n",
      "The loss is: 2.468700885772705 at step 1352\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.5124134421348572 at step 1353\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.8556187152862549 at step 1354\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.5887980461120605 at step 1355\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.21200527250766754 at step 1356\n",
      "18 float32 float32 float32\n",
      "The loss is: 1.064400315284729 at step 1357\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.2919066548347473 at step 1358\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.3101383149623871 at step 1359\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.7226654887199402 at step 1360\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.2862468361854553 at step 1361\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.9934208989143372 at step 1362\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.9641216993331909 at step 1363\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.5593558549880981 at step 1364\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.9574674963951111 at step 1365\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.6245854496955872 at step 1366\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.6902492046356201 at step 1367\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.2752213776111603 at step 1368\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.8619607090950012 at step 1369\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.5027336478233337 at step 1370\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.5936943292617798 at step 1371\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.6072068810462952 at step 1372\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.8596355319023132 at step 1373\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.48771798610687256 at step 1374\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.3317188322544098 at step 1375\n",
      "2 float32 float32 float32\n",
      "The loss is: 1.2355310916900635 at step 1376\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.21290448307991028 at step 1377\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.21015827357769012 at step 1378\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.8634192943572998 at step 1379\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.8479956388473511 at step 1380\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.24692824482917786 at step 1381\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.4238934516906738 at step 1382\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.5057983994483948 at step 1383\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.25788581371307373 at step 1384\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.6874313354492188 at step 1385\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.6853699088096619 at step 1386\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.5916742086410522 at step 1387\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.4661141037940979 at step 1388\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.8736588954925537 at step 1389\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.763200044631958 at step 1390\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.4187489151954651 at step 1391\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.5963721871376038 at step 1392\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.2565593421459198 at step 1393\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.32837387919425964 at step 1394\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.5145114660263062 at step 1395\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.5432685613632202 at step 1396\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.609994649887085 at step 1397\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.18024304509162903 at step 1398\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.20163926482200623 at step 1399\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.2683086693286896 at step 1400\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.23431380093097687 at step 1401\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.28709876537323 at step 1402\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.22957304120063782 at step 1403\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.33370479941368103 at step 1404\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.3114839792251587 at step 1405\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.17591220140457153 at step 1406\n",
      "1 float32 float32 float32\n",
      "The loss is: 1.5576677322387695 at step 1407\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.17918147146701813 at step 1408\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.5852034091949463 at step 1409\n",
      "18 float32 float32 float32\n",
      "The loss is: 1.1474888324737549 at step 1410\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.8394742012023926 at step 1411\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.4553028345108032 at step 1412\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.38154831528663635 at step 1413\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.2851717174053192 at step 1414\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.9579393863677979 at step 1415\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.15127348899841309 at step 1416\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.2531430125236511 at step 1417\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.4075613021850586 at step 1418\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.2862268090248108 at step 1419\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.39606472849845886 at step 1420\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.20905718207359314 at step 1421\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.3835943639278412 at step 1422\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.22891460359096527 at step 1423\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.7616336345672607 at step 1424\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.8005329966545105 at step 1425\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.9128713607788086 at step 1426\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.5555274486541748 at step 1427\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.7338657975196838 at step 1428\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.4576616883277893 at step 1429\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.4785267412662506 at step 1430\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.17534559965133667 at step 1431\n",
      "0 float32 float32 float32\n",
      "The loss is: 1.0352109670639038 at step 1432\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.6204345226287842 at step 1433\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.1556711196899414 at step 1434\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.15709352493286133 at step 1435\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.4961307942867279 at step 1436\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.18873949348926544 at step 1437\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.5495608448982239 at step 1438\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.3913620710372925 at step 1439\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.17350353300571442 at step 1440\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.977891206741333 at step 1441\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.25495028495788574 at step 1442\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.3047194182872772 at step 1443\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.28067702054977417 at step 1444\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.26292648911476135 at step 1445\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.7738946080207825 at step 1446\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.2690836787223816 at step 1447\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.5555753707885742 at step 1448\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.27862444519996643 at step 1449\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.18494397401809692 at step 1450\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.21285608410835266 at step 1451\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.16394886374473572 at step 1452\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.23501136898994446 at step 1453\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.7943933606147766 at step 1454\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.3079984784126282 at step 1455\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.24297396838665009 at step 1456\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.25952672958374023 at step 1457\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.2458857148885727 at step 1458\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.0958774089813232 at step 1459\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.20472949743270874 at step 1460\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.7383198738098145 at step 1461\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.5494889616966248 at step 1462\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.41441935300827026 at step 1463\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.8153231143951416 at step 1464\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.6108744144439697 at step 1465\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.5206753611564636 at step 1466\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.45889219641685486 at step 1467\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.4832945466041565 at step 1468\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.24237863719463348 at step 1469\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.6160569190979004 at step 1470\n",
      "2 float32 float32 float32\n",
      "The loss is: 1.198347568511963 at step 1471\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.19406168162822723 at step 1472\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.5235020518302917 at step 1473\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.24694770574569702 at step 1474\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.236627995967865 at step 1475\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.3737705945968628 at step 1476\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.6779862642288208 at step 1477\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.39385712146759033 at step 1478\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.22418814897537231 at step 1479\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.29908621311187744 at step 1480\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.8313038349151611 at step 1481\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.12677840888500214 at step 1482\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.08753897249698639 at step 1483\n",
      "16 float32 float32 float32\n",
      "The loss is: 1.0144907236099243 at step 1484\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.924971878528595 at step 1485\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.5548615455627441 at step 1486\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.8542589545249939 at step 1487\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.48244374990463257 at step 1488\n",
      "2 float32 float32 float32\n",
      "The loss is: 1.331244945526123 at step 1489\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.19323092699050903 at step 1490\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.2201811969280243 at step 1491\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.3038841187953949 at step 1492\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.7417343258857727 at step 1493\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.5175332427024841 at step 1494\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.8424674272537231 at step 1495\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.7958845496177673 at step 1496\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.6380940675735474 at step 1497\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.5268769860267639 at step 1498\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.28749048709869385 at step 1499\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.3898341953754425 at step 1500\n",
      "1 float32 float32 float32\n",
      "The loss is: 1.0135043859481812 at step 1501\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.25371652841567993 at step 1502\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.2744934856891632 at step 1503\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.7536066174507141 at step 1504\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.2799173891544342 at step 1505\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.20809921622276306 at step 1506\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.378584623336792 at step 1507\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.822903573513031 at step 1508\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.2897902727127075 at step 1509\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.9432548880577087 at step 1510\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.6831256151199341 at step 1511\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.21911484003067017 at step 1512\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.5593110918998718 at step 1513\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.4258936643600464 at step 1514\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.7048876285552979 at step 1515\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.42506641149520874 at step 1516\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.5005499720573425 at step 1517\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.38630759716033936 at step 1518\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.49060359597206116 at step 1519\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.6084181070327759 at step 1520\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.7574233412742615 at step 1521\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.41899269819259644 at step 1522\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.8166995644569397 at step 1523\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.21445129811763763 at step 1524\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.20189087092876434 at step 1525\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.1991058588027954 at step 1526\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.1804271787405014 at step 1527\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.6005728244781494 at step 1528\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.1927441954612732 at step 1529\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.21142131090164185 at step 1530\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.4524661600589752 at step 1531\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.29209578037261963 at step 1532\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.6361996531486511 at step 1533\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.3544306457042694 at step 1534\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.13359244167804718 at step 1535\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.8986514210700989 at step 1536\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.21806441247463226 at step 1537\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.47434166073799133 at step 1538\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.26701563596725464 at step 1539\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.21037448942661285 at step 1540\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.30754950642585754 at step 1541\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.8854578137397766 at step 1542\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.25313737988471985 at step 1543\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.13995495438575745 at step 1544\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.19057606160640717 at step 1545\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.21305115520954132 at step 1546\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.24891240894794464 at step 1547\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.49618154764175415 at step 1548\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.16029037535190582 at step 1549\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.3806651532649994 at step 1550\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.24329154193401337 at step 1551\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.3166333734989166 at step 1552\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.28665027022361755 at step 1553\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.6808642745018005 at step 1554\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.5445841550827026 at step 1555\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.31860336661338806 at step 1556\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.3102123737335205 at step 1557\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.3023173213005066 at step 1558\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.26792627573013306 at step 1559\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.18221591413021088 at step 1560\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.136860191822052 at step 1561\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.4308718144893646 at step 1562\n",
      "0 float32 float32 float32\n",
      "The loss is: 1.156206727027893 at step 1563\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.8424411416053772 at step 1564\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.9513755440711975 at step 1565\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.3352136015892029 at step 1566\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.39524853229522705 at step 1567\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.7831062078475952 at step 1568\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.8315168619155884 at step 1569\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.29121312499046326 at step 1570\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.19242431223392487 at step 1571\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.23322778940200806 at step 1572\n",
      "0 float32 float32 float32\n",
      "The loss is: 1.0541274547576904 at step 1573\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.0639721155166626 at step 1574\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.64869624376297 at step 1575\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.777729868888855 at step 1576\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.7549149990081787 at step 1577\n",
      "17 float32 float32 float32\n",
      "The loss is: 1.10084867477417 at step 1578\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.5738393664360046 at step 1579\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.14498959481716156 at step 1580\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.4324703812599182 at step 1581\n",
      "2 float32 float32 float32\n",
      "The loss is: 2.4193778038024902 at step 1582\n",
      "2 float32 float32 float32\n",
      "The loss is: 2.0889387130737305 at step 1583\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.6140446662902832 at step 1584\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.6346372961997986 at step 1585\n",
      "13 float32 float32 float32\n",
      "The loss is: 1.336643099784851 at step 1586\n",
      "5 float32 float32 float32\n",
      "The loss is: 1.032095193862915 at step 1587\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.8476840853691101 at step 1588\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.33555665612220764 at step 1589\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.2634776532649994 at step 1590\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.7113526463508606 at step 1591\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.3502967655658722 at step 1592\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.42283573746681213 at step 1593\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.47780144214630127 at step 1594\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.40096330642700195 at step 1595\n",
      "2 float32 float32 float32\n",
      "The loss is: 1.639936923980713 at step 1596\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.46925947070121765 at step 1597\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.06028946116566658 at step 1598\n",
      "12 float32 float32 float32\n",
      "The loss is: 1.6859872341156006 at step 1599\n",
      "6 float32 float32 float32\n",
      "The loss is: 2.45711350440979 at step 1600\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.8945159912109375 at step 1601\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.3154727816581726 at step 1602\n",
      "2 float32 float32 float32\n",
      "The loss is: 1.1238141059875488 at step 1603\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.6707697510719299 at step 1604\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.1486772298812866 at step 1605\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.21556927263736725 at step 1606\n",
      "16 float32 float32 float32\n",
      "The loss is: 1.0098332166671753 at step 1607\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.22992879152297974 at step 1608\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.40514814853668213 at step 1609\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.2368990033864975 at step 1610\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.10819939523935318 at step 1611\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.05030545964837074 at step 1612\n",
      "11 float32 float32 float32\n",
      "The loss is: 1.1907576322555542 at step 1613\n",
      "11 float32 float32 float32\n",
      "The loss is: 1.0115580558776855 at step 1614\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.6420855522155762 at step 1615\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.806150496006012 at step 1616\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.1610925793647766 at step 1617\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.3071101903915405 at step 1618\n",
      "14 float32 float32 float32\n",
      "The loss is: 1.009882926940918 at step 1619\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.8359105587005615 at step 1620\n",
      "18 float32 float32 float32\n",
      "The loss is: 1.1611363887786865 at step 1621\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.3814344108104706 at step 1622\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.361852765083313 at step 1623\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.2880783975124359 at step 1624\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.50408935546875 at step 1625\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.5880584716796875 at step 1626\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.6947788596153259 at step 1627\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.21522262692451477 at step 1628\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.19757021963596344 at step 1629\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.8030754327774048 at step 1630\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.5101825594902039 at step 1631\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.5564053058624268 at step 1632\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.8335239887237549 at step 1633\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.5553590059280396 at step 1634\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.5717236995697021 at step 1635\n",
      "3 float32 float32 float32\n",
      "The loss is: 2.2733561992645264 at step 1636\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.7822698950767517 at step 1637\n",
      "16 float32 float32 float32\n",
      "The loss is: 1.0422886610031128 at step 1638\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.8160412311553955 at step 1639\n",
      "11 float32 float32 float32\n",
      "The loss is: 1.5428881645202637 at step 1640\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.7373850345611572 at step 1641\n",
      "18 float32 float32 float32\n",
      "The loss is: 1.5384925603866577 at step 1642\n",
      "2 float32 float32 float32\n",
      "The loss is: 1.8641101121902466 at step 1643\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.2947040796279907 at step 1644\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.2618326246738434 at step 1645\n",
      "3 float32 float32 float32\n",
      "The loss is: 2.342928886413574 at step 1646\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.2576325237751007 at step 1647\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.852085292339325 at step 1648\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.46153947710990906 at step 1649\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.3932900130748749 at step 1650\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.5173332095146179 at step 1651\n",
      "16 float32 float32 float32\n",
      "The loss is: 1.1582045555114746 at step 1652\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.5950440764427185 at step 1653\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.3785121440887451 at step 1654\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.7494542002677917 at step 1655\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.9924866557121277 at step 1656\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.25408899784088135 at step 1657\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.5164206027984619 at step 1658\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.09505793452262878 at step 1659\n",
      "5 float32 float32 float32\n",
      "The loss is: 1.0774211883544922 at step 1660\n",
      "5 float32 float32 float32\n",
      "The loss is: 1.0024410486221313 at step 1661\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.8856700658798218 at step 1662\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.2971775233745575 at step 1663\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.2601217031478882 at step 1664\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.3514317274093628 at step 1665\n",
      "1 float32 float32 float32\n",
      "The loss is: 2.7690539360046387 at step 1666\n",
      "4 float32 float32 float32\n",
      "The loss is: 1.1068893671035767 at step 1667\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.8322827816009521 at step 1668\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.19950564205646515 at step 1669\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.41592442989349365 at step 1670\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.24415738880634308 at step 1671\n",
      "18 float32 float32 float32\n",
      "The loss is: 1.124172329902649 at step 1672\n",
      "18 float32 float32 float32\n",
      "The loss is: 1.113706350326538 at step 1673\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.41335397958755493 at step 1674\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.9980313181877136 at step 1675\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.1994531750679016 at step 1676\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.4658345580101013 at step 1677\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.835458517074585 at step 1678\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.4814416170120239 at step 1679\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.4201677739620209 at step 1680\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.7654039859771729 at step 1681\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.7717463374137878 at step 1682\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.27451664209365845 at step 1683\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.38233983516693115 at step 1684\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.27174463868141174 at step 1685\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.22899845242500305 at step 1686\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.1383218765258789 at step 1687\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.28855398297309875 at step 1688\n",
      "2 float32 float32 float32\n",
      "The loss is: 1.6608723402023315 at step 1689\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.8414020538330078 at step 1690\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.18173757195472717 at step 1691\n",
      "18 float32 float32 float32\n",
      "The loss is: 1.0696218013763428 at step 1692\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.5301862359046936 at step 1693\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.6584126949310303 at step 1694\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.12707754969596863 at step 1695\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.11591275781393051 at step 1696\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.5415340662002563 at step 1697\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.29934439063072205 at step 1698\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.21545711159706116 at step 1699\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.2524814307689667 at step 1700\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.17944982647895813 at step 1701\n",
      "2 float32 float32 float32\n",
      "The loss is: 1.0356812477111816 at step 1702\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.3120609521865845 at step 1703\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.2630765736103058 at step 1704\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.5763804912567139 at step 1705\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.3329751491546631 at step 1706\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.3787165880203247 at step 1707\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.314214289188385 at step 1708\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.10259436070919037 at step 1709\n",
      "1 float32 float32 float32\n",
      "The loss is: 1.4873710870742798 at step 1710\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.21239185333251953 at step 1711\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.13062921166419983 at step 1712\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.33389198780059814 at step 1713\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.7625359892845154 at step 1714\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.31823599338531494 at step 1715\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.4353245496749878 at step 1716\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.8870399594306946 at step 1717\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.3182089924812317 at step 1718\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.398540735244751 at step 1719\n",
      "13 float32 float32 float32\n",
      "The loss is: 1.0526320934295654 at step 1720\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.45280149579048157 at step 1721\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.14584262669086456 at step 1722\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.5444501638412476 at step 1723\n",
      "1 float32 float32 float32\n",
      "The loss is: 1.8315050601959229 at step 1724\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.6580356955528259 at step 1725\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.8665755391120911 at step 1726\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.1545494943857193 at step 1727\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.34812456369400024 at step 1728\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.3427196741104126 at step 1729\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.8233339786529541 at step 1730\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.36033445596694946 at step 1731\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.903314471244812 at step 1732\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.6783021688461304 at step 1733\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.2767956256866455 at step 1734\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.1364523023366928 at step 1735\n",
      "2 float32 float32 float32\n",
      "The loss is: 1.555171012878418 at step 1736\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.26397863030433655 at step 1737\n",
      "2 float32 float32 float32\n",
      "The loss is: 1.3251404762268066 at step 1738\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.3295612037181854 at step 1739\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.7079199552536011 at step 1740\n",
      "15 float32 float32 float32\n",
      "The loss is: 1.018118143081665 at step 1741\n",
      "18 float32 float32 float32\n",
      "The loss is: 1.4083527326583862 at step 1742\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.9589971899986267 at step 1743\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.5109102725982666 at step 1744\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.14486104249954224 at step 1745\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.1567910760641098 at step 1746\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.686385989189148 at step 1747\n",
      "2 float32 float32 float32\n",
      "The loss is: 3.024825096130371 at step 1748\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.2592676877975464 at step 1749\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.11742745339870453 at step 1750\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.8550630211830139 at step 1751\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.338692843914032 at step 1752\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.5054479241371155 at step 1753\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.3938339948654175 at step 1754\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.5275760293006897 at step 1755\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.32838174700737 at step 1756\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.337615430355072 at step 1757\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.16033121943473816 at step 1758\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.188712477684021 at step 1759\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.19100111722946167 at step 1760\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.17452079057693481 at step 1761\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.41618385910987854 at step 1762\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.16057534515857697 at step 1763\n",
      "18 float32 float32 float32\n",
      "The loss is: 1.0640760660171509 at step 1764\n",
      "1 float32 float32 float32\n",
      "The loss is: 1.062534213066101 at step 1765\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.6480485796928406 at step 1766\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.6360287666320801 at step 1767\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.7683023810386658 at step 1768\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.5615516304969788 at step 1769\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.19353798031806946 at step 1770\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.40886399149894714 at step 1771\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.41509151458740234 at step 1772\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.09041978418827057 at step 1773\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.5250736474990845 at step 1774\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.0894346535205841 at step 1775\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.08477571606636047 at step 1776\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.7375409007072449 at step 1777\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.21805204451084137 at step 1778\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.245356485247612 at step 1779\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.23700720071792603 at step 1780\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.1545286774635315 at step 1781\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.4319959282875061 at step 1782\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.7448301911354065 at step 1783\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.22547639906406403 at step 1784\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.24476949870586395 at step 1785\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.37864404916763306 at step 1786\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.6774036884307861 at step 1787\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.11025090515613556 at step 1788\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.7798731923103333 at step 1789\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.20629532635211945 at step 1790\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.730429768562317 at step 1791\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.42197906970977783 at step 1792\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.7679903507232666 at step 1793\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.10120133310556412 at step 1794\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.15843603014945984 at step 1795\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.5058034062385559 at step 1796\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.3442639708518982 at step 1797\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.34833914041519165 at step 1798\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.4527823030948639 at step 1799\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.38051071763038635 at step 1800\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.454002320766449 at step 1801\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.11177579313516617 at step 1802\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.1351085901260376 at step 1803\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.268764853477478 at step 1804\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.21142378449440002 at step 1805\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.2182427942752838 at step 1806\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.7993089556694031 at step 1807\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.5585799813270569 at step 1808\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.34175828099250793 at step 1809\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.4144226014614105 at step 1810\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.3253017067909241 at step 1811\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.40533435344696045 at step 1812\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.32064884901046753 at step 1813\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.21778540313243866 at step 1814\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.14143061637878418 at step 1815\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.0368953943252563 at step 1816\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.9148291349411011 at step 1817\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.1696028709411621 at step 1818\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.23018614947795868 at step 1819\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.3806487023830414 at step 1820\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.4739735424518585 at step 1821\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.3322497308254242 at step 1822\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.15280120074748993 at step 1823\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.5964196920394897 at step 1824\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.3031286597251892 at step 1825\n",
      "2 float32 float32 float32\n",
      "The loss is: 1.8143677711486816 at step 1826\n",
      "1 float32 float32 float32\n",
      "The loss is: 1.2332029342651367 at step 1827\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.3149442672729492 at step 1828\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.534521222114563 at step 1829\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.7190698385238647 at step 1830\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.5534927845001221 at step 1831\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.38957902789115906 at step 1832\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.0818043053150177 at step 1833\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.6562374830245972 at step 1834\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.30539581179618835 at step 1835\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.5771238803863525 at step 1836\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.23075121641159058 at step 1837\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.1796676367521286 at step 1838\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.438613623380661 at step 1839\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.716805636882782 at step 1840\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.46216636896133423 at step 1841\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.1747158020734787 at step 1842\n",
      "6 float32 float32 float32\n",
      "The loss is: 1.1601557731628418 at step 1843\n",
      "10 float32 float32 float32\n",
      "The loss is: 1.1215128898620605 at step 1844\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.6225125193595886 at step 1845\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.14731866121292114 at step 1846\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.29608380794525146 at step 1847\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.7540184259414673 at step 1848\n",
      "5 float32 float32 float32\n",
      "The loss is: 1.2900168895721436 at step 1849\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.8578394055366516 at step 1850\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.4489463269710541 at step 1851\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.3152304887771606 at step 1852\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.4385093152523041 at step 1853\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.33680853247642517 at step 1854\n",
      "17 float32 float32 float32\n",
      "The loss is: 1.404768705368042 at step 1855\n",
      "14 float32 float32 float32\n",
      "The loss is: 1.5403938293457031 at step 1856\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.8263821005821228 at step 1857\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.274827778339386 at step 1858\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.2314181923866272 at step 1859\n",
      "1 float32 float32 float32\n",
      "The loss is: 2.215871810913086 at step 1860\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.5901482105255127 at step 1861\n",
      "1 float32 float32 float32\n",
      "The loss is: 1.9384040832519531 at step 1862\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.0928555428981781 at step 1863\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.24378246068954468 at step 1864\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.36799177527427673 at step 1865\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.7788051962852478 at step 1866\n",
      "5 float32 float32 float32\n",
      "The loss is: 1.0682581663131714 at step 1867\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.300186425447464 at step 1868\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.8928431272506714 at step 1869\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.3354223370552063 at step 1870\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.11318889260292053 at step 1871\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.3299926519393921 at step 1872\n",
      "18 float32 float32 float32\n",
      "The loss is: 1.4743905067443848 at step 1873\n",
      "16 float32 float32 float32\n",
      "The loss is: 1.1324337720870972 at step 1874\n",
      "17 float32 float32 float32\n",
      "The loss is: 1.0036931037902832 at step 1875\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.6979730129241943 at step 1876\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.7542312741279602 at step 1877\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.8080761432647705 at step 1878\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.43346700072288513 at step 1879\n",
      "14 float32 float32 float32\n",
      "The loss is: 1.1496940851211548 at step 1880\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.5089479088783264 at step 1881\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.7719112634658813 at step 1882\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.09511390328407288 at step 1883\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.353796124458313 at step 1884\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.25531449913978577 at step 1885\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.22673887014389038 at step 1886\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.29594796895980835 at step 1887\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.47092103958129883 at step 1888\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.2241450399160385 at step 1889\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.5101302862167358 at step 1890\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.8542073369026184 at step 1891\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.3564438819885254 at step 1892\n",
      "11 float32 float32 float32\n",
      "The loss is: 1.1984686851501465 at step 1893\n",
      "12 float32 float32 float32\n",
      "The loss is: 1.4090180397033691 at step 1894\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.5235555768013 at step 1895\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.7198312878608704 at step 1896\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.209299236536026 at step 1897\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.7745322585105896 at step 1898\n",
      "4 float32 float32 float32\n",
      "The loss is: 2.0337932109832764 at step 1899\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.6138629913330078 at step 1900\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.43706002831459045 at step 1901\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.22074295580387115 at step 1902\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.24730753898620605 at step 1903\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.4846765100955963 at step 1904\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.8507871627807617 at step 1905\n",
      "9 float32 float32 float32\n",
      "The loss is: 1.1555448770523071 at step 1906\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.9443633556365967 at step 1907\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.7258482575416565 at step 1908\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.11590410768985748 at step 1909\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.32078123092651367 at step 1910\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.8593582510948181 at step 1911\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.5987493991851807 at step 1912\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.6784544587135315 at step 1913\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.5163373351097107 at step 1914\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.3795163631439209 at step 1915\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.43322911858558655 at step 1916\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.5500002503395081 at step 1917\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.38916146755218506 at step 1918\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.06796682626008987 at step 1919\n",
      "13 float32 float32 float32\n",
      "The loss is: 1.6101324558258057 at step 1920\n",
      "15 float32 float32 float32\n",
      "The loss is: 1.1703349351882935 at step 1921\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.663804829120636 at step 1922\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.48757994174957275 at step 1923\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.8085002899169922 at step 1924\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.13709592819213867 at step 1925\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.421376496553421 at step 1926\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.43912309408187866 at step 1927\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.6318755745887756 at step 1928\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.7450762987136841 at step 1929\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.34115803241729736 at step 1930\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.31134849786758423 at step 1931\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.15211212635040283 at step 1932\n",
      "16 float32 float32 float32\n",
      "The loss is: 1.097973346710205 at step 1933\n",
      "11 float32 float32 float32\n",
      "The loss is: 1.7136282920837402 at step 1934\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.8982425332069397 at step 1935\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.5819097757339478 at step 1936\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.20345889031887054 at step 1937\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.40657028555870056 at step 1938\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.32678601145744324 at step 1939\n",
      "17 float32 float32 float32\n",
      "The loss is: 1.3185491561889648 at step 1940\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.3968683183193207 at step 1941\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.687857985496521 at step 1942\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.576428234577179 at step 1943\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.7746342420578003 at step 1944\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.3589441478252411 at step 1945\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.5063357949256897 at step 1946\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.2442222237586975 at step 1947\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.5814162492752075 at step 1948\n",
      "7 float32 float32 float32\n",
      "The loss is: 1.8239688873291016 at step 1949\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.38715463876724243 at step 1950\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.41880252957344055 at step 1951\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.2037184089422226 at step 1952\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.8380254507064819 at step 1953\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.311475545167923 at step 1954\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.8623981475830078 at step 1955\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.20005667209625244 at step 1956\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.5024901032447815 at step 1957\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.13779118657112122 at step 1958\n",
      "1 float32 float32 float32\n",
      "The loss is: 1.054944396018982 at step 1959\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.5610640645027161 at step 1960\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.7843027710914612 at step 1961\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.22636498510837555 at step 1962\n",
      "14 float32 float32 float32\n",
      "The loss is: 1.3843705654144287 at step 1963\n",
      "13 float32 float32 float32\n",
      "The loss is: 1.2342263460159302 at step 1964\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.6978379487991333 at step 1965\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.21965977549552917 at step 1966\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.3313891887664795 at step 1967\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.9814360737800598 at step 1968\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.8126398324966431 at step 1969\n",
      "1 float32 float32 float32\n",
      "The loss is: 2.7262701988220215 at step 1970\n",
      "2 float32 float32 float32\n",
      "The loss is: 1.816225290298462 at step 1971\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.4550822675228119 at step 1972\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.5469545722007751 at step 1973\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.7789772152900696 at step 1974\n",
      "14 float32 float32 float32\n",
      "The loss is: 1.8423237800598145 at step 1975\n",
      "6 float32 float32 float32\n",
      "The loss is: 2.2031288146972656 at step 1976\n",
      "6 float32 float32 float32\n",
      "The loss is: 1.0742650032043457 at step 1977\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.324140340089798 at step 1978\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.3890421390533447 at step 1979\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.5163431763648987 at step 1980\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.5355043411254883 at step 1981\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.7353273034095764 at step 1982\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.4607943296432495 at step 1983\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.10681360960006714 at step 1984\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.730368435382843 at step 1985\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.4651700556278229 at step 1986\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.886064887046814 at step 1987\n",
      "18 float32 float32 float32\n",
      "The loss is: 1.125312328338623 at step 1988\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.7620920538902283 at step 1989\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.4406886398792267 at step 1990\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.21639376878738403 at step 1991\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.09742926061153412 at step 1992\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.14513806998729706 at step 1993\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.9035981297492981 at step 1994\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.6911138892173767 at step 1995\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.6269452571868896 at step 1996\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.7185566425323486 at step 1997\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.15375900268554688 at step 1998\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.3839147388935089 at step 1999\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.951335608959198 at step 2000\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.7971441745758057 at step 2001\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.41010040044784546 at step 2002\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.2975238561630249 at step 2003\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.3332979381084442 at step 2004\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.4697510898113251 at step 2005\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.2575265169143677 at step 2006\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.5402432680130005 at step 2007\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.2567998468875885 at step 2008\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.24942214787006378 at step 2009\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.6451746225357056 at step 2010\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.28424960374832153 at step 2011\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.441969633102417 at step 2012\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.8840372562408447 at step 2013\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.3434793949127197 at step 2014\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.04916103556752205 at step 2015\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.3149159252643585 at step 2016\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.780543863773346 at step 2017\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.2808327376842499 at step 2018\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.2966482639312744 at step 2019\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.4983079731464386 at step 2020\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.29338911175727844 at step 2021\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.1373140960931778 at step 2022\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.3206650912761688 at step 2023\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.7875385284423828 at step 2024\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.4192965626716614 at step 2025\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.4394426643848419 at step 2026\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.19303694367408752 at step 2027\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.1588163375854492 at step 2028\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.204622283577919 at step 2029\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.41950517892837524 at step 2030\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.3603438138961792 at step 2031\n",
      "18 float32 float32 float32\n",
      "The loss is: 1.0265026092529297 at step 2032\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.45440801978111267 at step 2033\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.17443731427192688 at step 2034\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.12452489882707596 at step 2035\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.16980615258216858 at step 2036\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.22291074693202972 at step 2037\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.38158902525901794 at step 2038\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.2512531578540802 at step 2039\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.5111356377601624 at step 2040\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.2536919116973877 at step 2041\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.17517690360546112 at step 2042\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.08636527508497238 at step 2043\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.2330358326435089 at step 2044\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.2665969431400299 at step 2045\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.3753208518028259 at step 2046\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.0930975005030632 at step 2047\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.20257578790187836 at step 2048\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.436791330575943 at step 2049\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.5723603963851929 at step 2050\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.7153461575508118 at step 2051\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.22053541243076324 at step 2052\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.2219049334526062 at step 2053\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.9996430277824402 at step 2054\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.279654860496521 at step 2055\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.23793700337409973 at step 2056\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.36047372221946716 at step 2057\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.21539944410324097 at step 2058\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.16813071072101593 at step 2059\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.975365400314331 at step 2060\n",
      "2 float32 float32 float32\n",
      "The loss is: 1.2141491174697876 at step 2061\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.08104640990495682 at step 2062\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.36982157826423645 at step 2063\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.26117515563964844 at step 2064\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.23301240801811218 at step 2065\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.49549299478530884 at step 2066\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.12802453339099884 at step 2067\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.33968669176101685 at step 2068\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.7541298270225525 at step 2069\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.36710241436958313 at step 2070\n",
      "2 float32 float32 float32\n",
      "The loss is: 1.4861018657684326 at step 2071\n",
      "2 float32 float32 float32\n",
      "The loss is: 1.0125200748443604 at step 2072\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.08625248074531555 at step 2073\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.714779794216156 at step 2074\n",
      "16 float32 float32 float32\n",
      "The loss is: 1.3827098608016968 at step 2075\n",
      "7 float32 float32 float32\n",
      "The loss is: 1.2785911560058594 at step 2076\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.6421844959259033 at step 2077\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.12028578668832779 at step 2078\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.31310051679611206 at step 2079\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.49990198016166687 at step 2080\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.8920494914054871 at step 2081\n",
      "1 float32 float32 float32\n",
      "The loss is: 3.759467124938965 at step 2082\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.620178759098053 at step 2083\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.23052732646465302 at step 2084\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.05321245267987251 at step 2085\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.1950754076242447 at step 2086\n",
      "17 float32 float32 float32\n",
      "The loss is: 1.204327940940857 at step 2087\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.5285834074020386 at step 2088\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.37377965450286865 at step 2089\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.5051543116569519 at step 2090\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.14505375921726227 at step 2091\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.1372593343257904 at step 2092\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.1936051845550537 at step 2093\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.2152317613363266 at step 2094\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.33238863945007324 at step 2095\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.3564806878566742 at step 2096\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.461957186460495 at step 2097\n",
      "4 float32 float32 float32\n",
      "The loss is: 1.1655288934707642 at step 2098\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.3880685865879059 at step 2099\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.3152921497821808 at step 2100\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.42385154962539673 at step 2101\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.4194832742214203 at step 2102\n",
      "17 float32 float32 float32\n",
      "The loss is: 1.3988078832626343 at step 2103\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.32421422004699707 at step 2104\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.44362178444862366 at step 2105\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.6526960134506226 at step 2106\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.32646849751472473 at step 2107\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.4399988651275635 at step 2108\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.15455767512321472 at step 2109\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.6788337826728821 at step 2110\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.4658878743648529 at step 2111\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.22758905589580536 at step 2112\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.6929255723953247 at step 2113\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.07832673192024231 at step 2114\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.7996866106987 at step 2115\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.2515353262424469 at step 2116\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.17619682848453522 at step 2117\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.8812358975410461 at step 2118\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.9159393310546875 at step 2119\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.1239074170589447 at step 2120\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.6801925897598267 at step 2121\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.3244623839855194 at step 2122\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.6391326785087585 at step 2123\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.10214731097221375 at step 2124\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.635330080986023 at step 2125\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.5890133380889893 at step 2126\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.18619009852409363 at step 2127\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.2542031705379486 at step 2128\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.3105213940143585 at step 2129\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.9112834930419922 at step 2130\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.4077015817165375 at step 2131\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.29975640773773193 at step 2132\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.24449509382247925 at step 2133\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.23691028356552124 at step 2134\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.3047599196434021 at step 2135\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.640081524848938 at step 2136\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.20769786834716797 at step 2137\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.2495170682668686 at step 2138\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.09217509627342224 at step 2139\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.2800987958908081 at step 2140\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.3690440356731415 at step 2141\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.30047866702079773 at step 2142\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.3028140962123871 at step 2143\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.3060159981250763 at step 2144\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.2472183108329773 at step 2145\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.10066761076450348 at step 2146\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.4688216745853424 at step 2147\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.9962478280067444 at step 2148\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.891407310962677 at step 2149\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.09626895934343338 at step 2150\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.26881200075149536 at step 2151\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.3367641866207123 at step 2152\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.25355246663093567 at step 2153\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.20556634664535522 at step 2154\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.1685134321451187 at step 2155\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.06681909412145615 at step 2156\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.14840885996818542 at step 2157\n",
      "1 float32 float32 float32\n",
      "The loss is: 1.4420487880706787 at step 2158\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.4172353148460388 at step 2159\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.11167439073324203 at step 2160\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.20971690118312836 at step 2161\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.2447529137134552 at step 2162\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.29318708181381226 at step 2163\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.18894612789154053 at step 2164\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.489576131105423 at step 2165\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.9486995339393616 at step 2166\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.16377995908260345 at step 2167\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.1532416045665741 at step 2168\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.2861575186252594 at step 2169\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.24978463351726532 at step 2170\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.32157841324806213 at step 2171\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.5348323583602905 at step 2172\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.2455148696899414 at step 2173\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.2988274395465851 at step 2174\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.05286770686507225 at step 2175\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.13653512299060822 at step 2176\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.5045774579048157 at step 2177\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.8981404900550842 at step 2178\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.08949266374111176 at step 2179\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.15414482355117798 at step 2180\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.25816264748573303 at step 2181\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.0869688093662262 at step 2182\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.3533109724521637 at step 2183\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.0750715360045433 at step 2184\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.2558234930038452 at step 2185\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.37432658672332764 at step 2186\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.39083510637283325 at step 2187\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.3434479534626007 at step 2188\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.3783867061138153 at step 2189\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.195292130112648 at step 2190\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.25492775440216064 at step 2191\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.20949634909629822 at step 2192\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.26633432507514954 at step 2193\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.17252983152866364 at step 2194\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.14594244956970215 at step 2195\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.11869323253631592 at step 2196\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.14710089564323425 at step 2197\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.2995958924293518 at step 2198\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.0677729845046997 at step 2199\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.8722054958343506 at step 2200\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.9184386730194092 at step 2201\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.8463271856307983 at step 2202\n",
      "14 float32 float32 float32\n",
      "The loss is: 1.0889984369277954 at step 2203\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.386064350605011 at step 2204\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.8473613262176514 at step 2205\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.2056114226579666 at step 2206\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.06964414566755295 at step 2207\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.536554753780365 at step 2208\n",
      "1 float32 float32 float32\n",
      "The loss is: 1.5316061973571777 at step 2209\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.9022551774978638 at step 2210\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.7014124393463135 at step 2211\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.3502046763896942 at step 2212\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.5740221738815308 at step 2213\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.7233874797821045 at step 2214\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.7225741744041443 at step 2215\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.2776167392730713 at step 2216\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.5119245052337646 at step 2217\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.0595247820019722 at step 2218\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.2366111278533936 at step 2219\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.18578104674816132 at step 2220\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.3572205603122711 at step 2221\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.26547011733055115 at step 2222\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.06519755721092224 at step 2223\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.11994457244873047 at step 2224\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.13780246675014496 at step 2225\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.20888172090053558 at step 2226\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.1724979281425476 at step 2227\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.10461176931858063 at step 2228\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.1557558923959732 at step 2229\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.17244845628738403 at step 2230\n",
      "2 float32 float32 float32\n",
      "The loss is: 1.3232671022415161 at step 2231\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.5238044261932373 at step 2232\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.4972473382949829 at step 2233\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.448681503534317 at step 2234\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.6282581090927124 at step 2235\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.8874983787536621 at step 2236\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.5255779027938843 at step 2237\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.6946027874946594 at step 2238\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.04685797914862633 at step 2239\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.08715123683214188 at step 2240\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.21321508288383484 at step 2241\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.633996307849884 at step 2242\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.221668541431427 at step 2243\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.9268879294395447 at step 2244\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.06527171283960342 at step 2245\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.2288173884153366 at step 2246\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.46115392446517944 at step 2247\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.28447601199150085 at step 2248\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.4827568829059601 at step 2249\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.273032546043396 at step 2250\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.5180655717849731 at step 2251\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.4214519262313843 at step 2252\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.4087708294391632 at step 2253\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.04557149112224579 at step 2254\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.6266860961914062 at step 2255\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.688055157661438 at step 2256\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.048249680548906326 at step 2257\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.06554009020328522 at step 2258\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.22881637513637543 at step 2259\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.2377912402153015 at step 2260\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.5458433628082275 at step 2261\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.15297001600265503 at step 2262\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.18724694848060608 at step 2263\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.4651121497154236 at step 2264\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.22505992650985718 at step 2265\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.22643327713012695 at step 2266\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.2653060853481293 at step 2267\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.1392061859369278 at step 2268\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.1286206990480423 at step 2269\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.259239673614502 at step 2270\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.12049146741628647 at step 2271\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.19369184970855713 at step 2272\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.6551578044891357 at step 2273\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.5767969489097595 at step 2274\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.4453631639480591 at step 2275\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.36025193333625793 at step 2276\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.43949779868125916 at step 2277\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.33391061425209045 at step 2278\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.16344806551933289 at step 2279\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.6911022663116455 at step 2280\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.16382218897342682 at step 2281\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.6426177620887756 at step 2282\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.19382423162460327 at step 2283\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.2664893567562103 at step 2284\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.19740110635757446 at step 2285\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.09828148037195206 at step 2286\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.07007191330194473 at step 2287\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.7944731116294861 at step 2288\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.15344734489917755 at step 2289\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.10623496770858765 at step 2290\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.15954285860061646 at step 2291\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.09314760565757751 at step 2292\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.11054962128400803 at step 2293\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.1397976279258728 at step 2294\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.10080616921186447 at step 2295\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.04800498113036156 at step 2296\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.2493758499622345 at step 2297\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.4013653099536896 at step 2298\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.5124160051345825 at step 2299\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.12359511852264404 at step 2300\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.7374634146690369 at step 2301\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.33642321825027466 at step 2302\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.26497843861579895 at step 2303\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.1551724672317505 at step 2304\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.6673884391784668 at step 2305\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.6134892702102661 at step 2306\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.10114539414644241 at step 2307\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.4495701193809509 at step 2308\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.17374497652053833 at step 2309\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.09712783247232437 at step 2310\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.04707419499754906 at step 2311\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.1416933238506317 at step 2312\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.3040073812007904 at step 2313\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.1768905520439148 at step 2314\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.30696165561676025 at step 2315\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.15551789104938507 at step 2316\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.5287724137306213 at step 2317\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.7099743485450745 at step 2318\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.19867151975631714 at step 2319\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.7788191437721252 at step 2320\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.5167453289031982 at step 2321\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.2956387400627136 at step 2322\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.0695931687951088 at step 2323\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.13940495252609253 at step 2324\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.2696024775505066 at step 2325\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.3214384913444519 at step 2326\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.4405454695224762 at step 2327\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.3516243100166321 at step 2328\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.7665021419525146 at step 2329\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.07306958734989166 at step 2330\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.37158650159835815 at step 2331\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.8356050252914429 at step 2332\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.14268043637275696 at step 2333\n",
      "18 float32 float32 float32\n",
      "The loss is: 1.5591492652893066 at step 2334\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.7173714637756348 at step 2335\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.3140742778778076 at step 2336\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.9326823353767395 at step 2337\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.39722272753715515 at step 2338\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.9058251976966858 at step 2339\n",
      "2 float32 float32 float32\n",
      "The loss is: 1.7932801246643066 at step 2340\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.6964136958122253 at step 2341\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.3328222632408142 at step 2342\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.813052237033844 at step 2343\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.8919306993484497 at step 2344\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.888866662979126 at step 2345\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.2885381281375885 at step 2346\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.7485450506210327 at step 2347\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.2122073471546173 at step 2348\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.29359281063079834 at step 2349\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.2754867374897003 at step 2350\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.7252600789070129 at step 2351\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.831592321395874 at step 2352\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.19910266995429993 at step 2353\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.033998578786849976 at step 2354\n",
      "7 float32 float32 float32\n",
      "The loss is: 1.1604191064834595 at step 2355\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.6768335103988647 at step 2356\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.7758542895317078 at step 2357\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.4391433894634247 at step 2358\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.5127238035202026 at step 2359\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.08581458032131195 at step 2360\n",
      "0 float32 float32 float32\n",
      "The loss is: 1.2907805442810059 at step 2361\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.2791273593902588 at step 2362\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.24325238168239594 at step 2363\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.525306761264801 at step 2364\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.14490574598312378 at step 2365\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.321338415145874 at step 2366\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.4171765446662903 at step 2367\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.3112086057662964 at step 2368\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.23984628915786743 at step 2369\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.567115068435669 at step 2370\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.12638252973556519 at step 2371\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.3523330092430115 at step 2372\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.1656048744916916 at step 2373\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.7488711476325989 at step 2374\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.6622026562690735 at step 2375\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.23209482431411743 at step 2376\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.2081848680973053 at step 2377\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.2935270071029663 at step 2378\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.45683273673057556 at step 2379\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.11541112512350082 at step 2380\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.05292904004454613 at step 2381\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.7180331945419312 at step 2382\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.3851369321346283 at step 2383\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.17057214677333832 at step 2384\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.08808930218219757 at step 2385\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.38202178478240967 at step 2386\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.10723865032196045 at step 2387\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.05722001567482948 at step 2388\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.1689159870147705 at step 2389\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.07007542997598648 at step 2390\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.07378445565700531 at step 2391\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.13561192154884338 at step 2392\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.03874009847640991 at step 2393\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.12790238857269287 at step 2394\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.7270908355712891 at step 2395\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.569953203201294 at step 2396\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.20880532264709473 at step 2397\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.30443552136421204 at step 2398\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.38783159852027893 at step 2399\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.3161875009536743 at step 2400\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.15752115845680237 at step 2401\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.032947175204753876 at step 2402\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.896869421005249 at step 2403\n",
      "2 float32 float32 float32\n",
      "The loss is: 1.2791815996170044 at step 2404\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.06724885106086731 at step 2405\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.22712843120098114 at step 2406\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.7432661652565002 at step 2407\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.27715012431144714 at step 2408\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.3554335832595825 at step 2409\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.4627656936645508 at step 2410\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.3103369176387787 at step 2411\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.4324731230735779 at step 2412\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.13876163959503174 at step 2413\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.04812469705939293 at step 2414\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.5508666038513184 at step 2415\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.4140835702419281 at step 2416\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.275026798248291 at step 2417\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.2486240565776825 at step 2418\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.4664720892906189 at step 2419\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.35610830783843994 at step 2420\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.2825618088245392 at step 2421\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.14366735517978668 at step 2422\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.1241493746638298 at step 2423\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.366234689950943 at step 2424\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.3940407931804657 at step 2425\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.24856768548488617 at step 2426\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.2810782194137573 at step 2427\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.10688512027263641 at step 2428\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.19180893898010254 at step 2429\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.30662646889686584 at step 2430\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.12333443760871887 at step 2431\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.15874047577381134 at step 2432\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.07480847835540771 at step 2433\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.05246420204639435 at step 2434\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.23256118595600128 at step 2435\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.1863487809896469 at step 2436\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.1085691750049591 at step 2437\n",
      "1 float32 float32 float32\n",
      "The loss is: 1.1633888483047485 at step 2438\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.04910324513912201 at step 2439\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.17995470762252808 at step 2440\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.2974967956542969 at step 2441\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.3675459623336792 at step 2442\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.15828898549079895 at step 2443\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.17236021161079407 at step 2444\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.1044137179851532 at step 2445\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.30062544345855713 at step 2446\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.11909682303667068 at step 2447\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.14514568448066711 at step 2448\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.0711435005068779 at step 2449\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.11004667729139328 at step 2450\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.03890727087855339 at step 2451\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.26387888193130493 at step 2452\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.10478465259075165 at step 2453\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.40850862860679626 at step 2454\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.40028059482574463 at step 2455\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.0627000629901886 at step 2456\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.10071611404418945 at step 2457\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.18924951553344727 at step 2458\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.09492555260658264 at step 2459\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.21489661931991577 at step 2460\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.7681009769439697 at step 2461\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.6390211582183838 at step 2462\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.4402822256088257 at step 2463\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.6638143658638 at step 2464\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.6751663684844971 at step 2465\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.48664888739585876 at step 2466\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.25903835892677307 at step 2467\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.6881415247917175 at step 2468\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.15278427302837372 at step 2469\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.4197152853012085 at step 2470\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.26084405183792114 at step 2471\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.09249602258205414 at step 2472\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.08728744089603424 at step 2473\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.10355804860591888 at step 2474\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.09526917338371277 at step 2475\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.06524863839149475 at step 2476\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.03429456800222397 at step 2477\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.8145003914833069 at step 2478\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.6896810531616211 at step 2479\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.0965791568160057 at step 2480\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.16134342551231384 at step 2481\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.37215012311935425 at step 2482\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.24272078275680542 at step 2483\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.6504958868026733 at step 2484\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.07872773706912994 at step 2485\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.4994785487651825 at step 2486\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.7685362696647644 at step 2487\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.26799318194389343 at step 2488\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.5828655362129211 at step 2489\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.5456559658050537 at step 2490\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.08609798550605774 at step 2491\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.48382410407066345 at step 2492\n",
      "0 float32 float32 float32\n",
      "The loss is: 1.1551623344421387 at step 2493\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.20913158357143402 at step 2494\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.18858517706394196 at step 2495\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.3474850058555603 at step 2496\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.4311904311180115 at step 2497\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.4205968379974365 at step 2498\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.29274505376815796 at step 2499\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.13702435791492462 at step 2500\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.047392379492521286 at step 2501\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.2705177664756775 at step 2502\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.7592302560806274 at step 2503\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.48673099279403687 at step 2504\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.3112788796424866 at step 2505\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.14295093715190887 at step 2506\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.04339611530303955 at step 2507\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.6217143535614014 at step 2508\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.11885849386453629 at step 2509\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.425047367811203 at step 2510\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.4260852634906769 at step 2511\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.34408533573150635 at step 2512\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.4819472134113312 at step 2513\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.05062162131071091 at step 2514\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.06278293579816818 at step 2515\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.05914432555437088 at step 2516\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.668093740940094 at step 2517\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.0944206565618515 at step 2518\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.6065351366996765 at step 2519\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.46414852142333984 at step 2520\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.5076879262924194 at step 2521\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.7969410419464111 at step 2522\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.2714523375034332 at step 2523\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.25825536251068115 at step 2524\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.1337137371301651 at step 2525\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.02676314115524292 at step 2526\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.6253445148468018 at step 2527\n",
      "1 float32 float32 float32\n",
      "The loss is: 1.4579126834869385 at step 2528\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.07030756026506424 at step 2529\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.4170325696468353 at step 2530\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.10600584745407104 at step 2531\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.2291359156370163 at step 2532\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.2908676862716675 at step 2533\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.21659094095230103 at step 2534\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.5839204788208008 at step 2535\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.16165047883987427 at step 2536\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.4683295786380768 at step 2537\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.22300344705581665 at step 2538\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.06039668619632721 at step 2539\n",
      "1 float32 float32 float32\n",
      "The loss is: 1.1478521823883057 at step 2540\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.37056925892829895 at step 2541\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.10742607712745667 at step 2542\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.031618569046258926 at step 2543\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.08422129601240158 at step 2544\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.11607611179351807 at step 2545\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.23193860054016113 at step 2546\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.31986096501350403 at step 2547\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.41995126008987427 at step 2548\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.331175833940506 at step 2549\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.39765822887420654 at step 2550\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.051226504147052765 at step 2551\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.6376350522041321 at step 2552\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.5641034245491028 at step 2553\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.02813497558236122 at step 2554\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.560509443283081 at step 2555\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.07736456394195557 at step 2556\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.04081924259662628 at step 2557\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.3384784460067749 at step 2558\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.10443133115768433 at step 2559\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.4737165868282318 at step 2560\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.33109211921691895 at step 2561\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.3248201608657837 at step 2562\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.47857582569122314 at step 2563\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.3213372826576233 at step 2564\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.32143911719322205 at step 2565\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.2705599367618561 at step 2566\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.1752150058746338 at step 2567\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.4806092083454132 at step 2568\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.036482181400060654 at step 2569\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.5603976845741272 at step 2570\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.3867591619491577 at step 2571\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.1921493113040924 at step 2572\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.20240823924541473 at step 2573\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.1644657403230667 at step 2574\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.13811437785625458 at step 2575\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.06692908704280853 at step 2576\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.034082166850566864 at step 2577\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.47066667675971985 at step 2578\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.6007288694381714 at step 2579\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.41001349687576294 at step 2580\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.029736021533608437 at step 2581\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.33464664220809937 at step 2582\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.11603069305419922 at step 2583\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.12143879383802414 at step 2584\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.2551170587539673 at step 2585\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.2730335295200348 at step 2586\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.26480793952941895 at step 2587\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.022629937157034874 at step 2588\n",
      "2 float32 float32 float32\n",
      "The loss is: 1.2280755043029785 at step 2589\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.16240042448043823 at step 2590\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.6972840428352356 at step 2591\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.26737716794013977 at step 2592\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.43918001651763916 at step 2593\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.3376428186893463 at step 2594\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.4739321172237396 at step 2595\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.10496344417333603 at step 2596\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.1726042628288269 at step 2597\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.21199767291545868 at step 2598\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.9350776672363281 at step 2599\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.2326386272907257 at step 2600\n",
      "1 float32 float32 float32\n",
      "The loss is: 1.2162184715270996 at step 2601\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.6267147660255432 at step 2602\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.2527828812599182 at step 2603\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.6381751298904419 at step 2604\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.6534706950187683 at step 2605\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.29394006729125977 at step 2606\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.07283540070056915 at step 2607\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.40699395537376404 at step 2608\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.2883960008621216 at step 2609\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.3853360414505005 at step 2610\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.33939772844314575 at step 2611\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.5920239090919495 at step 2612\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.38631677627563477 at step 2613\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.1602589190006256 at step 2614\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.04159613326191902 at step 2615\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.6191895008087158 at step 2616\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.4131103754043579 at step 2617\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.3841375708580017 at step 2618\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.13382655382156372 at step 2619\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.017542699351906776 at step 2620\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.9996117353439331 at step 2621\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.5583822727203369 at step 2622\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.1020391434431076 at step 2623\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.18407948315143585 at step 2624\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.37685737013816833 at step 2625\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.07068286836147308 at step 2626\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.6508764028549194 at step 2627\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.3712500333786011 at step 2628\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.2957254648208618 at step 2629\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.6482722759246826 at step 2630\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.2843872010707855 at step 2631\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.7875107526779175 at step 2632\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.21288591623306274 at step 2633\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.03855562210083008 at step 2634\n",
      "2 float32 float32 float32\n",
      "The loss is: 1.2396600246429443 at step 2635\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.4475500285625458 at step 2636\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.12850812077522278 at step 2637\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.5459704399108887 at step 2638\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.0962776392698288 at step 2639\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.18591932952404022 at step 2640\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.1526801437139511 at step 2641\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.2352212518453598 at step 2642\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.2058102786540985 at step 2643\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.2026040256023407 at step 2644\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.42585256695747375 at step 2645\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.2235773652791977 at step 2646\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.13649992644786835 at step 2647\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.043301112949848175 at step 2648\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.8354214429855347 at step 2649\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.37369346618652344 at step 2650\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.07356499135494232 at step 2651\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.18692180514335632 at step 2652\n",
      "9 float32 float32 float32\n",
      "The loss is: 1.1086411476135254 at step 2653\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.9713097810745239 at step 2654\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.008836234919726849 at step 2655\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.2782479524612427 at step 2656\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.08785475045442581 at step 2657\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.0775812566280365 at step 2658\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.15728820860385895 at step 2659\n",
      "2 float32 float32 float32\n",
      "The loss is: 1.8541940450668335 at step 2660\n",
      "2 float32 float32 float32\n",
      "The loss is: 1.2715476751327515 at step 2661\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.15324348211288452 at step 2662\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.719188928604126 at step 2663\n",
      "14 float32 float32 float32\n",
      "The loss is: 1.4633233547210693 at step 2664\n",
      "18 float32 float32 float32\n",
      "The loss is: 1.184316635131836 at step 2665\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.17524248361587524 at step 2666\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.4590250253677368 at step 2667\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.08485521376132965 at step 2668\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.06972351670265198 at step 2669\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.04847811535000801 at step 2670\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.6604539155960083 at step 2671\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.16123276948928833 at step 2672\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.6881053447723389 at step 2673\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.08681556582450867 at step 2674\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.7248450517654419 at step 2675\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.062319185584783554 at step 2676\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.7853562831878662 at step 2677\n",
      "9 float32 float32 float32\n",
      "The loss is: 1.2910254001617432 at step 2678\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.5061486959457397 at step 2679\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.20726951956748962 at step 2680\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.171152263879776 at step 2681\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.48614516854286194 at step 2682\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.9873222708702087 at step 2683\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.18980102241039276 at step 2684\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.6840994358062744 at step 2685\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.37068185210227966 at step 2686\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.5979440212249756 at step 2687\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.47856372594833374 at step 2688\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.32552284002304077 at step 2689\n",
      "8 float32 float32 float32\n",
      "The loss is: 1.3153685331344604 at step 2690\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.9753116965293884 at step 2691\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.2049914300441742 at step 2692\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.033386457711458206 at step 2693\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.12372679263353348 at step 2694\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.4668411612510681 at step 2695\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.42589259147644043 at step 2696\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.40469133853912354 at step 2697\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.605553150177002 at step 2698\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.046585895121097565 at step 2699\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.6708799600601196 at step 2700\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.3027516305446625 at step 2701\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.549236536026001 at step 2702\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.2312958836555481 at step 2703\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.08151929080486298 at step 2704\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.02277662605047226 at step 2705\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.0264314413070679 at step 2706\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.29076454043388367 at step 2707\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.05134718492627144 at step 2708\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.12065599858760834 at step 2709\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.13758841156959534 at step 2710\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.49236181378364563 at step 2711\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.16217434406280518 at step 2712\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.23921076953411102 at step 2713\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.20406082272529602 at step 2714\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.09705998748540878 at step 2715\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.09675989300012589 at step 2716\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.6970038414001465 at step 2717\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.024328047409653664 at step 2718\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.19673718512058258 at step 2719\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.2837373614311218 at step 2720\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.08039213716983795 at step 2721\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.2445695698261261 at step 2722\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.39609768986701965 at step 2723\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.28486838936805725 at step 2724\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.18105274438858032 at step 2725\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.5021049976348877 at step 2726\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.29918205738067627 at step 2727\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.6229642033576965 at step 2728\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.11757539212703705 at step 2729\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.6802666783332825 at step 2730\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.023542465642094612 at step 2731\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.061451852321624756 at step 2732\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.047169484198093414 at step 2733\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.1661672592163086 at step 2734\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.16878342628479004 at step 2735\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.39706093072891235 at step 2736\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.11548050493001938 at step 2737\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.20170018076896667 at step 2738\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.13105621933937073 at step 2739\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.09177237004041672 at step 2740\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.032897770404815674 at step 2741\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.39078909158706665 at step 2742\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.14064928889274597 at step 2743\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.09486415982246399 at step 2744\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.06666919589042664 at step 2745\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.058248620480298996 at step 2746\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.47445568442344666 at step 2747\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.027517087757587433 at step 2748\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.11877952516078949 at step 2749\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.054059214890003204 at step 2750\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.070676788687706 at step 2751\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.030696813017129898 at step 2752\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.10413222759962082 at step 2753\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.017122648656368256 at step 2754\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.30952131748199463 at step 2755\n",
      "2 float32 float32 float32\n",
      "The loss is: 1.1503127813339233 at step 2756\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.4584452211856842 at step 2757\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.19534990191459656 at step 2758\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.4467371702194214 at step 2759\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.34309035539627075 at step 2760\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.1641634851694107 at step 2761\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.4280000925064087 at step 2762\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.33545711636543274 at step 2763\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.25517284870147705 at step 2764\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.07489287108182907 at step 2765\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.18304795026779175 at step 2766\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.3665263652801514 at step 2767\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.14683552086353302 at step 2768\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.07348019629716873 at step 2769\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.11289575695991516 at step 2770\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.11499985307455063 at step 2771\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.38735803961753845 at step 2772\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.5258901119232178 at step 2773\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.24566639959812164 at step 2774\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.12265963107347488 at step 2775\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.6244072914123535 at step 2776\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.04526294022798538 at step 2777\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.5296177864074707 at step 2778\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.12104637175798416 at step 2779\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.16760897636413574 at step 2780\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.18306830525398254 at step 2781\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.10757546871900558 at step 2782\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.08713990449905396 at step 2783\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.06997137516736984 at step 2784\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.633181095123291 at step 2785\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.2444876879453659 at step 2786\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.18695814907550812 at step 2787\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.1671973168849945 at step 2788\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.26846012473106384 at step 2789\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.23579981923103333 at step 2790\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.08685329556465149 at step 2791\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.02297854609787464 at step 2792\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.1823424994945526 at step 2793\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.2749326527118683 at step 2794\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.09152055531740189 at step 2795\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.5630806088447571 at step 2796\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.9859037399291992 at step 2797\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.13548235595226288 at step 2798\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.4766293168067932 at step 2799\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.6200076937675476 at step 2800\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.5103917717933655 at step 2801\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.05983242765069008 at step 2802\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.09710360318422318 at step 2803\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.07069046050310135 at step 2804\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.10287673771381378 at step 2805\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.3360159993171692 at step 2806\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.1166192814707756 at step 2807\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.3257964849472046 at step 2808\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.08091256022453308 at step 2809\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.8530457019805908 at step 2810\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.21733695268630981 at step 2811\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.2168409526348114 at step 2812\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.45447391271591187 at step 2813\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.3508501648902893 at step 2814\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.19764716923236847 at step 2815\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.07688313722610474 at step 2816\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.3438885509967804 at step 2817\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.30419009923934937 at step 2818\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.2321280837059021 at step 2819\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.3095114529132843 at step 2820\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.2658020257949829 at step 2821\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.8634982109069824 at step 2822\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.26367834210395813 at step 2823\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.39950069785118103 at step 2824\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.7762812376022339 at step 2825\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.3260148763656616 at step 2826\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.03565004840493202 at step 2827\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.10444578528404236 at step 2828\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.19553378224372864 at step 2829\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.52243971824646 at step 2830\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.3548852205276489 at step 2831\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.11572861671447754 at step 2832\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.0459122359752655 at step 2833\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.08225581794977188 at step 2834\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.26993077993392944 at step 2835\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.6369588375091553 at step 2836\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.5144786834716797 at step 2837\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.30670443177223206 at step 2838\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.1580536961555481 at step 2839\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.5296676754951477 at step 2840\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.25524139404296875 at step 2841\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.12484349310398102 at step 2842\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.16447104513645172 at step 2843\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.5849786400794983 at step 2844\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.5575605630874634 at step 2845\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.1487816423177719 at step 2846\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.20858514308929443 at step 2847\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.15379224717617035 at step 2848\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.2754494249820709 at step 2849\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.16656439006328583 at step 2850\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.2762605845928192 at step 2851\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.05675654113292694 at step 2852\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.0294988714158535 at step 2853\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.049324143677949905 at step 2854\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.17421354353427887 at step 2855\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.30456310510635376 at step 2856\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.2686847448348999 at step 2857\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.07587305456399918 at step 2858\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.09992051869630814 at step 2859\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.15869805216789246 at step 2860\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.19092883169651031 at step 2861\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.16493818163871765 at step 2862\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.08198370784521103 at step 2863\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.052281465381383896 at step 2864\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.6760026812553406 at step 2865\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.23700857162475586 at step 2866\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.30602559447288513 at step 2867\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.3862553834915161 at step 2868\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.4179622232913971 at step 2869\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.2777758836746216 at step 2870\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.5340624451637268 at step 2871\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.4120621979236603 at step 2872\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.4524606466293335 at step 2873\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.6016802191734314 at step 2874\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.22166292369365692 at step 2875\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.09484538435935974 at step 2876\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.041483983397483826 at step 2877\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.11734369397163391 at step 2878\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.9650275707244873 at step 2879\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.25687721371650696 at step 2880\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.18395712971687317 at step 2881\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.21732507646083832 at step 2882\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.25445419549942017 at step 2883\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.16989949345588684 at step 2884\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.35650330781936646 at step 2885\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.8102551698684692 at step 2886\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.07071882486343384 at step 2887\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.2757326662540436 at step 2888\n",
      "14 float32 float32 float32\n",
      "The loss is: 0.19474205374717712 at step 2889\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.04140523076057434 at step 2890\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.48464182019233704 at step 2891\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.4949948489665985 at step 2892\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.3895636796951294 at step 2893\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.15577088296413422 at step 2894\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.6612546443939209 at step 2895\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.23110252618789673 at step 2896\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.579017698764801 at step 2897\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.35077357292175293 at step 2898\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.6709606051445007 at step 2899\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.6150718331336975 at step 2900\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.009881939738988876 at step 2901\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.255582720041275 at step 2902\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.14962990581989288 at step 2903\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.04454806447029114 at step 2904\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.04634220898151398 at step 2905\n",
      "1 float32 float32 float32\n",
      "The loss is: 1.4526348114013672 at step 2906\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.8539656400680542 at step 2907\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.23005501925945282 at step 2908\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.21630436182022095 at step 2909\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.66340172290802 at step 2910\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.9186280369758606 at step 2911\n",
      "4 float32 float32 float32\n",
      "The loss is: 1.422114372253418 at step 2912\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.4998859763145447 at step 2913\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.4942711293697357 at step 2914\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.11097133159637451 at step 2915\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.20086313784122467 at step 2916\n",
      "15 float32 float32 float32\n",
      "The loss is: 1.1352018117904663 at step 2917\n",
      "4 float32 float32 float32\n",
      "The loss is: 1.3591840267181396 at step 2918\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.7082018852233887 at step 2919\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.1295221447944641 at step 2920\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.17302866280078888 at step 2921\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.5032061338424683 at step 2922\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.7853114604949951 at step 2923\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.6467867493629456 at step 2924\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.41460660099983215 at step 2925\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.4617805480957031 at step 2926\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.4941900670528412 at step 2927\n",
      "1 float32 float32 float32\n",
      "The loss is: 1.6258984804153442 at step 2928\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.43347683548927307 at step 2929\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.19572846591472626 at step 2930\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.28811025619506836 at step 2931\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.38874146342277527 at step 2932\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.5009921193122864 at step 2933\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.06256890296936035 at step 2934\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.46412816643714905 at step 2935\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.3397292196750641 at step 2936\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.3245314061641693 at step 2937\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.6403599977493286 at step 2938\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.06227608397603035 at step 2939\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.22572557628154755 at step 2940\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.2145526260137558 at step 2941\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.08507546782493591 at step 2942\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.02621699497103691 at step 2943\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.090382881462574 at step 2944\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.6640816330909729 at step 2945\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.737151026725769 at step 2946\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.2077203392982483 at step 2947\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.8747422695159912 at step 2948\n",
      "9 float32 float32 float32\n",
      "The loss is: 1.1355165243148804 at step 2949\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.04549364000558853 at step 2950\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.3816925883293152 at step 2951\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.1281457543373108 at step 2952\n",
      "10 float32 float32 float32\n",
      "The loss is: 0.06369716674089432 at step 2953\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.28514695167541504 at step 2954\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.3203349709510803 at step 2955\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.49998772144317627 at step 2956\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.5192843079566956 at step 2957\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.16019833087921143 at step 2958\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.2256118655204773 at step 2959\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.2820088565349579 at step 2960\n",
      "9 float32 float32 float32\n",
      "The loss is: 0.29548904299736023 at step 2961\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.4413298964500427 at step 2962\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.15840621292591095 at step 2963\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.0274383295327425 at step 2964\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.5430819392204285 at step 2965\n",
      "11 float32 float32 float32\n",
      "The loss is: 0.09395667910575867 at step 2966\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.2966820299625397 at step 2967\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.6409604549407959 at step 2968\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.4481220841407776 at step 2969\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.45647159218788147 at step 2970\n",
      "17 float32 float32 float32\n",
      "The loss is: 0.7001722455024719 at step 2971\n",
      "2 float32 float32 float32\n",
      "The loss is: 0.15214967727661133 at step 2972\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.5834015011787415 at step 2973\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.2826434373855591 at step 2974\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.13829021155834198 at step 2975\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.26939088106155396 at step 2976\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.11048862338066101 at step 2977\n",
      "3 float32 float32 float32\n",
      "The loss is: 1.2446664571762085 at step 2978\n",
      "16 float32 float32 float32\n",
      "The loss is: 0.5019251108169556 at step 2979\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.636549711227417 at step 2980\n",
      "7 float32 float32 float32\n",
      "The loss is: 0.06030373275279999 at step 2981\n",
      "13 float32 float32 float32\n",
      "The loss is: 0.17678916454315186 at step 2982\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.23912660777568817 at step 2983\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.11269603669643402 at step 2984\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.5675528049468994 at step 2985\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.4982108473777771 at step 2986\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.24975016713142395 at step 2987\n",
      "12 float32 float32 float32\n",
      "The loss is: 0.10159334540367126 at step 2988\n",
      "3 float32 float32 float32\n",
      "The loss is: 0.8344454765319824 at step 2989\n",
      "6 float32 float32 float32\n",
      "The loss is: 0.10342872142791748 at step 2990\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.2793557345867157 at step 2991\n",
      "0 float32 float32 float32\n",
      "The loss is: 0.6972650289535522 at step 2992\n",
      "15 float32 float32 float32\n",
      "The loss is: 0.17316891252994537 at step 2993\n",
      "5 float32 float32 float32\n",
      "The loss is: 0.13995075225830078 at step 2994\n",
      "4 float32 float32 float32\n",
      "The loss is: 0.19892005622386932 at step 2995\n",
      "1 float32 float32 float32\n",
      "The loss is: 0.0664919912815094 at step 2996\n",
      "8 float32 float32 float32\n",
      "The loss is: 0.6957048773765564 at step 2997\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.6842021942138672 at step 2998\n",
      "18 float32 float32 float32\n",
      "The loss is: 0.5153146386146545 at step 2999\n"
     ]
    }
   ],
   "source": [
    "func = NNODEF(2, 16, time_invariant=False)\n",
    "ode_trained = NeuralODE(func)\n",
    "conduct_experiment(X, ode_trained, 3000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b29a08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c577c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m1_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a3d2348bd11adea07e53a77f599ed493ed339edd258ad81087bea4cda1c36530"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
